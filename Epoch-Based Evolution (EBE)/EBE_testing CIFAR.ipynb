{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from epoch_based_evolution import SearchSpace, Generation\n",
    "import load_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class column is not numeric. Applying LabelEncoder.\n",
      "Data loaded successfully! as <class 'torch.Tensor'>\n",
      "Training data shape: torch.Size([384, 6])\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_val, y_val, X_test, y_test = load_data.load_openml_dataset(dataset_id=334, scaling=True, random_seed=None, return_as='tensor')\n",
    "input_size, output_size = load_data.get_tensor_sizes(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded succesfully! as <class 'torch.Tensor'>\n",
      "Training data shape: torch.Size([40000, 3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "# Load the CIFAR-10\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = load_data.load_cifar10_data(cifar_path='../CIFAR-10', return_as='tensor')\n",
    "input_size, output_size = load_data.get_tensor_sizes(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = SearchSpace(\n",
    "    input_size=input_size,\n",
    "    output_size=output_size,          \n",
    "    # min_layers=2,           # Minimum number of hidden layers\n",
    "    # max_layers=5,           # Maximum number of hidden layers\n",
    "    # min_neurons=16,         # Minimum neurons per layer\n",
    "    # max_neurons=256,        # Maximum neurons per layer\n",
    "    # activation_fns=[nn.ReLU, nn.LeakyReLU],  # Activation functions to sample\n",
    "    # dropout_rates=[0, 0.1, 0.2],             # Dropout rates to sample\n",
    "    # min_learning_rate=0.0001,                # Minimum learning rate\n",
    "    # max_learning_rate=0.01,                  # Maximum learning rate\n",
    "    # random_seeds=[42, 13, 2024],             # Random seeds for reproducibility\n",
    "    # min_batch_size=32,                       # Minimum batch size\n",
    "    # max_batch_size=512                       # Maximum batch size\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DynamicNN(\n",
      "  (network): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=123, bias=True)\n",
      "    (1): Sigmoid()\n",
      "    (2): Dropout(p=0.1, inplace=False)\n",
      "    (3): Linear(in_features=123, out_features=357, bias=True)\n",
      "    (4): Sigmoid()\n",
      "    (5): Dropout(p=0.1, inplace=False)\n",
      "    (6): Linear(in_features=357, out_features=246, bias=True)\n",
      "    (7): Sigmoid()\n",
      "    (8): Dropout(p=0.1, inplace=False)\n",
      "    (9): Linear(in_features=246, out_features=10, bias=True)\n",
      "  )\n",
      "  (criterion): CrossEntropyLoss()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "architecture = search_space.sample_architecture()\n",
    "batch_size = architecture['batch_size']\n",
    "model = search_space.create_model(architecture)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoaders\n",
    "train_dataset, train_loader = load_data.create_dataset_and_loader(X_train, y_train,\n",
    "                                                        batch_size=batch_size)\n",
    "val_dataset, val_loader = load_data.create_dataset_and_loader(X_val, y_val, \n",
    "                                                    batch_size=batch_size)\n",
    "test_dataset, test_loader = load_data.create_dataset_and_loader(X_test, y_test,\n",
    "                                                      batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.0328153898239134, 0.241425)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.oe_train(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the first generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_INDIVIDUALS = 50\n",
    "first_gen = Generation(search_space, n_individuals=N_INDIVIDUALS)\n",
    "# first_gen.generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN THE GEN\n",
    "first_gen.train_generation(train_loader, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_gen.validate_generation(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.1445950065612793"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_gen.generation[0]['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23, 3, 41, 34, 47, 11, 7]\n"
     ]
    }
   ],
   "source": [
    "first_gen.get_worst_individuals(percentile_drop=15)\n",
    "print(first_gen.worst_individuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_gen.drop_worst_individuals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(first_gen.generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from epoch_based_evolution import run_generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=3072, out_features=257, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=257, out_features=481, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=481, out_features=46, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=46, out_features=92, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=92, out_features=374, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=374, out_features=98, bias=True)\n",
       "      (16): ReLU()\n",
       "      (17): Dropout(p=0.5, inplace=False)\n",
       "      (18): Linear(in_features=98, out_features=462, bias=True)\n",
       "      (19): ReLU()\n",
       "      (20): Dropout(p=0.5, inplace=False)\n",
       "      (21): Linear(in_features=462, out_features=10, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [257, 481, 46, 92, 374, 98, 462],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.004062832099590926,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 2.2120033740997314,\n",
       "  'train_acc': 0.147175,\n",
       "  'val_loss': 2.1445950065612793,\n",
       "  'val_acc': 0.1815},\n",
       " 1: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=3072, out_features=268, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=268, out_features=360, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=360, out_features=10, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [268, 360],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0077542227161906336,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 2.2552117080688476,\n",
       "  'train_acc': 0.169925,\n",
       "  'val_loss': 2.1937326332092284,\n",
       "  'val_acc': 0.243},\n",
       " 2: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=3072, out_features=261, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=261, out_features=265, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=265, out_features=433, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=433, out_features=430, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=430, out_features=10, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [261, 265, 433, 430],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.007601546972825917,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 2.083553155326843,\n",
       "  'train_acc': 0.251075,\n",
       "  'val_loss': 1.833565993309021,\n",
       "  'val_acc': 0.3191},\n",
       " 3: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=3072, out_features=486, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=486, out_features=60, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=60, out_features=10, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [486, 60],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0028414044583598723,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 1.8815824766159057,\n",
       "  'train_acc': 0.3276,\n",
       "  'val_loss': 1.7078708953857422,\n",
       "  'val_acc': 0.392},\n",
       " 4: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=3072, out_features=28, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=28, out_features=145, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=145, out_features=85, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=85, out_features=472, bias=True)\n",
       "      (10): Sigmoid()\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=472, out_features=10, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [28, 145, 85, 472],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.006131803615306327,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 2.3140161586761474,\n",
       "  'train_acc': 0.099825,\n",
       "  'val_loss': 2.3035413261413575,\n",
       "  'val_acc': 0.1006},\n",
       " 5: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=3072, out_features=26, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=26, out_features=44, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=44, out_features=10, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [26, 44],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.006076327828155263,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 1.8924441349029542,\n",
       "  'train_acc': 0.322625,\n",
       "  'val_loss': 1.6818244075775146,\n",
       "  'val_acc': 0.4002},\n",
       " 6: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=3072, out_features=205, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=205, out_features=246, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=246, out_features=344, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=344, out_features=282, bias=True)\n",
       "      (10): Sigmoid()\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=282, out_features=455, bias=True)\n",
       "      (13): Sigmoid()\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=455, out_features=35, bias=True)\n",
       "      (16): Sigmoid()\n",
       "      (17): Dropout(p=0.5, inplace=False)\n",
       "      (18): Linear(in_features=35, out_features=329, bias=True)\n",
       "      (19): Sigmoid()\n",
       "      (20): Dropout(p=0.5, inplace=False)\n",
       "      (21): Linear(in_features=329, out_features=10, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [205, 246, 344, 282, 455, 35, 329],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.004076593050501272,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 2.354136835861206,\n",
       "  'train_acc': 0.1014,\n",
       "  'val_loss': 2.303038081741333,\n",
       "  'val_acc': 0.1015},\n",
       " 7: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=3072, out_features=189, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Linear(in_features=189, out_features=363, bias=True)\n",
       "      (3): Sigmoid()\n",
       "      (4): Linear(in_features=363, out_features=257, bias=True)\n",
       "      (5): Sigmoid()\n",
       "      (6): Linear(in_features=257, out_features=115, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Linear(in_features=115, out_features=429, bias=True)\n",
       "      (9): Sigmoid()\n",
       "      (10): Linear(in_features=429, out_features=10, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [189, 363, 257, 115, 429],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.006281830427258682,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 2.306427425765991,\n",
       "  'train_acc': 0.099725,\n",
       "  'val_loss': 2.302874301528931,\n",
       "  'val_acc': 0.1022},\n",
       " 8: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=3072, out_features=435, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=435, out_features=19, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=19, out_features=211, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=211, out_features=487, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=487, out_features=317, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.2, inplace=False)\n",
       "      (15): Linear(in_features=317, out_features=10, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [435, 19, 211, 487, 317],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.002836795214693956,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 1.9495159446716308,\n",
       "  'train_acc': 0.279275,\n",
       "  'val_loss': 1.7839841964721679,\n",
       "  'val_acc': 0.3531},\n",
       " 9: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=3072, out_features=437, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=437, out_features=189, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=189, out_features=416, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=416, out_features=297, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=297, out_features=504, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=504, out_features=10, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [437, 189, 416, 297, 504],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.006807885862675757,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 2.2834691120147705,\n",
       "  'train_acc': 0.1367,\n",
       "  'val_loss': 2.1626500331878664,\n",
       "  'val_acc': 0.1861},\n",
       " 10: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=3072, out_features=471, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=471, out_features=292, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=292, out_features=10, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [471, 292],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.005742634997102338,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 2.3466507705688477,\n",
       "  'train_acc': 0.10205,\n",
       "  'val_loss': 2.29960418548584,\n",
       "  'val_acc': 0.1351},\n",
       " 11: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=3072, out_features=251, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=251, out_features=390, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=390, out_features=81, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=81, out_features=443, bias=True)\n",
       "      (10): Sigmoid()\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=443, out_features=352, bias=True)\n",
       "      (13): Sigmoid()\n",
       "      (14): Dropout(p=0.1, inplace=False)\n",
       "      (15): Linear(in_features=352, out_features=437, bias=True)\n",
       "      (16): Sigmoid()\n",
       "      (17): Dropout(p=0.1, inplace=False)\n",
       "      (18): Linear(in_features=437, out_features=223, bias=True)\n",
       "      (19): Sigmoid()\n",
       "      (20): Dropout(p=0.1, inplace=False)\n",
       "      (21): Linear(in_features=223, out_features=10, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [251, 390, 81, 443, 352, 437, 223],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.002003082019967851,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 2.2600525470733643,\n",
       "  'train_acc': 0.123175,\n",
       "  'val_loss': 2.132008327865601,\n",
       "  'val_acc': 0.1772},\n",
       " 12: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=3072, out_features=256, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=256, out_features=218, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=218, out_features=178, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=178, out_features=70, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=70, out_features=359, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.2, inplace=False)\n",
       "      (15): Linear(in_features=359, out_features=481, bias=True)\n",
       "      (16): ReLU()\n",
       "      (17): Dropout(p=0.2, inplace=False)\n",
       "      (18): Linear(in_features=481, out_features=10, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [256, 218, 178, 70, 359, 481],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.007903497881435944,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 2.129585093307495,\n",
       "  'train_acc': 0.1856,\n",
       "  'val_loss': 1.9324311351776122,\n",
       "  'val_acc': 0.2437},\n",
       " 13: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=3072, out_features=413, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=413, out_features=486, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=486, out_features=10, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [413, 486],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.00947265371130306,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 3.8468873344421386,\n",
       "  'train_acc': 0.16405,\n",
       "  'val_loss': 2.1781515003204346,\n",
       "  'val_acc': 0.1938},\n",
       " 14: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=3072, out_features=214, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=214, out_features=291, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=291, out_features=125, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=125, out_features=10, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [214, 291, 125],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0011253282744555324,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 2.300373868560791,\n",
       "  'train_acc': 0.11775,\n",
       "  'val_loss': 2.299167544555664,\n",
       "  'val_acc': 0.1264},\n",
       " 15: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=3072, out_features=477, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Linear(in_features=477, out_features=244, bias=True)\n",
       "      (3): Sigmoid()\n",
       "      (4): Linear(in_features=244, out_features=35, bias=True)\n",
       "      (5): Sigmoid()\n",
       "      (6): Linear(in_features=35, out_features=251, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Linear(in_features=251, out_features=489, bias=True)\n",
       "      (9): Sigmoid()\n",
       "      (10): Linear(in_features=489, out_features=10, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [477, 244, 35, 251, 489],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.003288809266010137,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 2.305479818725586,\n",
       "  'train_acc': 0.098025,\n",
       "  'val_loss': 2.303255602645874,\n",
       "  'val_acc': 0.0943},\n",
       " 16: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=3072, out_features=103, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=103, out_features=453, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=453, out_features=393, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=393, out_features=10, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [103, 453, 393],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.007923456717800117,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 2.10442160282135,\n",
       "  'train_acc': 0.263725,\n",
       "  'val_loss': 1.7878811264038086,\n",
       "  'val_acc': 0.3373},\n",
       " 17: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=3072, out_features=109, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=109, out_features=173, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=173, out_features=452, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=452, out_features=15, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=15, out_features=10, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [109, 173, 452, 15],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.004173946240372153,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 2.0299942899703978,\n",
       "  'train_acc': 0.2595,\n",
       "  'val_loss': 1.7692898307800293,\n",
       "  'val_acc': 0.3659},\n",
       " 18: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=3072, out_features=410, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=410, out_features=420, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=420, out_features=10, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [410, 420],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.009239414579864505,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 1.9870859483718872,\n",
       "  'train_acc': 0.286075,\n",
       "  'val_loss': 1.7793296056747436,\n",
       "  'val_acc': 0.3611},\n",
       " 19: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=3072, out_features=77, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=77, out_features=132, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=132, out_features=206, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=206, out_features=331, bias=True)\n",
       "      (10): Sigmoid()\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=331, out_features=10, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [77, 132, 206, 331],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.006108564005564046,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 2.311742706680298,\n",
       "  'train_acc': 0.09885,\n",
       "  'val_loss': 2.304198234176636,\n",
       "  'val_acc': 0.1006},\n",
       " 20: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=3072, out_features=462, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=462, out_features=433, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=433, out_features=435, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=435, out_features=60, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=60, out_features=180, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=180, out_features=94, bias=True)\n",
       "      (16): ReLU()\n",
       "      (17): Dropout(p=0.5, inplace=False)\n",
       "      (18): Linear(in_features=94, out_features=60, bias=True)\n",
       "      (19): ReLU()\n",
       "      (20): Dropout(p=0.5, inplace=False)\n",
       "      (21): Linear(in_features=60, out_features=10, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [462, 433, 435, 60, 180, 94, 60],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0044168183737535865,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 2.3051007869720457,\n",
       "  'train_acc': 0.0977,\n",
       "  'val_loss': 2.3044186347961424,\n",
       "  'val_acc': 0.109},\n",
       " 21: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=3072, out_features=363, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=363, out_features=461, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=461, out_features=345, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=345, out_features=495, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=495, out_features=10, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [363, 461, 345, 495],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.008496498147564181,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 2.3014177810668945,\n",
       "  'train_acc': 0.21115,\n",
       "  'val_loss': 1.8506332502365113,\n",
       "  'val_acc': 0.3319},\n",
       " 22: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=3072, out_features=189, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=189, out_features=265, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=265, out_features=158, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=158, out_features=10, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [189, 265, 158],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0020366728206088216,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 1.813395383834839,\n",
       "  'train_acc': 0.3484,\n",
       "  'val_loss': 1.6358745599746705,\n",
       "  'val_acc': 0.4241},\n",
       " 23: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=3072, out_features=126, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Linear(in_features=126, out_features=509, bias=True)\n",
       "      (3): Sigmoid()\n",
       "      (4): Linear(in_features=509, out_features=486, bias=True)\n",
       "      (5): Sigmoid()\n",
       "      (6): Linear(in_features=486, out_features=458, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Linear(in_features=458, out_features=73, bias=True)\n",
       "      (9): Sigmoid()\n",
       "      (10): Linear(in_features=73, out_features=188, bias=True)\n",
       "      (11): Sigmoid()\n",
       "      (12): Linear(in_features=188, out_features=292, bias=True)\n",
       "      (13): Sigmoid()\n",
       "      (14): Linear(in_features=292, out_features=10, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [126, 509, 486, 458, 73, 188, 292],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.009197365694229884,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 2.305943519973755,\n",
       "  'train_acc': 0.09775,\n",
       "  'val_loss': 2.303771237945557,\n",
       "  'val_acc': 0.1015},\n",
       " 24: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=3072, out_features=61, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=61, out_features=127, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=127, out_features=33, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=33, out_features=188, bias=True)\n",
       "      (10): Sigmoid()\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=188, out_features=260, bias=True)\n",
       "      (13): Sigmoid()\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=260, out_features=354, bias=True)\n",
       "      (16): Sigmoid()\n",
       "      (17): Dropout(p=0.5, inplace=False)\n",
       "      (18): Linear(in_features=354, out_features=10, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [61, 127, 33, 188, 260, 354],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0022061019013560777,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 2.3218102458953855,\n",
       "  'train_acc': 0.099925,\n",
       "  'val_loss': 2.30327094039917,\n",
       "  'val_acc': 0.1007},\n",
       " 25: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=3072, out_features=299, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=299, out_features=380, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=380, out_features=51, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=51, out_features=466, bias=True)\n",
       "      (10): Sigmoid()\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=466, out_features=195, bias=True)\n",
       "      (13): Sigmoid()\n",
       "      (14): Dropout(p=0.2, inplace=False)\n",
       "      (15): Linear(in_features=195, out_features=200, bias=True)\n",
       "      (16): Sigmoid()\n",
       "      (17): Dropout(p=0.2, inplace=False)\n",
       "      (18): Linear(in_features=200, out_features=56, bias=True)\n",
       "      (19): Sigmoid()\n",
       "      (20): Dropout(p=0.2, inplace=False)\n",
       "      (21): Linear(in_features=56, out_features=10, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [299, 380, 51, 466, 195, 200, 56],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0072119318162631825,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 2.301710117340088,\n",
       "  'train_acc': 0.1107,\n",
       "  'val_loss': 2.215397771835327,\n",
       "  'val_acc': 0.1779},\n",
       " 26: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=3072, out_features=246, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=246, out_features=35, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=35, out_features=10, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [246, 35],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.006211720328134114,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 2.276970009613037,\n",
       "  'train_acc': 0.148675,\n",
       "  'val_loss': 2.230903077697754,\n",
       "  'val_acc': 0.1962},\n",
       " 27: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=3072, out_features=391, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=391, out_features=433, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=433, out_features=294, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=294, out_features=10, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [391, 433, 294],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.009991456370787574,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 2.6170559036254883,\n",
       "  'train_acc': 0.17985,\n",
       "  'val_loss': 1.9369989391326905,\n",
       "  'val_acc': 0.238},\n",
       " 28: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=3072, out_features=167, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=167, out_features=258, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=258, out_features=229, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=229, out_features=467, bias=True)\n",
       "      (10): Sigmoid()\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=467, out_features=10, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [167, 258, 229, 467],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.007737399533191295,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 2.346058977508545,\n",
       "  'train_acc': 0.098975,\n",
       "  'val_loss': 2.3033210357666016,\n",
       "  'val_acc': 0.1046},\n",
       " 29: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=3072, out_features=295, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=295, out_features=396, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=396, out_features=286, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=286, out_features=390, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=390, out_features=10, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [295, 396, 286, 390],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.009679622050994936,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 2.1989887794494627,\n",
       "  'train_acc': 0.218175,\n",
       "  'val_loss': 1.8907009334564209,\n",
       "  'val_acc': 0.3076},\n",
       " 30: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=3072, out_features=97, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=97, out_features=329, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=329, out_features=10, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [97, 329],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.006407504949177196,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 1.9411336938858033,\n",
       "  'train_acc': 0.3031,\n",
       "  'val_loss': 1.794465358352661,\n",
       "  'val_acc': 0.3538},\n",
       " 31: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=3072, out_features=67, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=67, out_features=253, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=253, out_features=443, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=443, out_features=230, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=230, out_features=303, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=303, out_features=259, bias=True)\n",
       "      (16): LeakyReLU(negative_slope=0.01)\n",
       "      (17): Dropout(p=0.5, inplace=False)\n",
       "      (18): Linear(in_features=259, out_features=493, bias=True)\n",
       "      (19): LeakyReLU(negative_slope=0.01)\n",
       "      (20): Dropout(p=0.5, inplace=False)\n",
       "      (21): Linear(in_features=493, out_features=10, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [67, 253, 443, 230, 303, 259, 493],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.007036678394209981,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 2.2079952976226807,\n",
       "  'train_acc': 0.151025,\n",
       "  'val_loss': 2.169453121948242,\n",
       "  'val_acc': 0.1362},\n",
       " 32: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=3072, out_features=470, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Linear(in_features=470, out_features=32, bias=True)\n",
       "      (3): Sigmoid()\n",
       "      (4): Linear(in_features=32, out_features=397, bias=True)\n",
       "      (5): Sigmoid()\n",
       "      (6): Linear(in_features=397, out_features=361, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Linear(in_features=361, out_features=10, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [470, 32, 397, 361],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.007484293779250586,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 2.219051488876343,\n",
       "  'train_acc': 0.152625,\n",
       "  'val_loss': 2.039368003463745,\n",
       "  'val_acc': 0.2082},\n",
       " 33: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=3072, out_features=302, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=302, out_features=227, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=227, out_features=10, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [302, 227],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.002314453282917142,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 1.7681300378799438,\n",
       "  'train_acc': 0.377075,\n",
       "  'val_loss': 1.59908983001709,\n",
       "  'val_acc': 0.4284},\n",
       " 34: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=3072, out_features=65, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=65, out_features=199, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=199, out_features=180, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=180, out_features=144, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=144, out_features=10, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [65, 199, 180, 144],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.005069874555287546,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 2.3032127418518065,\n",
       "  'train_acc': 0.10725,\n",
       "  'val_loss': 2.302277010726929,\n",
       "  'val_acc': 0.1056},\n",
       " 35: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=3072, out_features=186, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=186, out_features=387, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=387, out_features=319, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=319, out_features=382, bias=True)\n",
       "      (10): Sigmoid()\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=382, out_features=404, bias=True)\n",
       "      (13): Sigmoid()\n",
       "      (14): Dropout(p=0.2, inplace=False)\n",
       "      (15): Linear(in_features=404, out_features=353, bias=True)\n",
       "      (16): Sigmoid()\n",
       "      (17): Dropout(p=0.2, inplace=False)\n",
       "      (18): Linear(in_features=353, out_features=10, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [186, 387, 319, 382, 404, 353],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.008185975211999288,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 2.3500202533721923,\n",
       "  'train_acc': 0.099425,\n",
       "  'val_loss': 2.3031468841552734,\n",
       "  'val_acc': 0.0955},\n",
       " 36: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=3072, out_features=375, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=375, out_features=178, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=178, out_features=466, bias=True)\n",
       "      (5): ReLU()\n",
       "      (6): Linear(in_features=466, out_features=392, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Linear(in_features=392, out_features=10, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [375, 178, 466, 392],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0013809914348688578,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 2.3024892013549803,\n",
       "  'train_acc': 0.090825,\n",
       "  'val_loss': 2.302852351760864,\n",
       "  'val_acc': 0.0963},\n",
       " 37: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=3072, out_features=231, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=231, out_features=499, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=499, out_features=491, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=491, out_features=351, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=351, out_features=252, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.2, inplace=False)\n",
       "      (15): Linear(in_features=252, out_features=201, bias=True)\n",
       "      (16): LeakyReLU(negative_slope=0.01)\n",
       "      (17): Dropout(p=0.2, inplace=False)\n",
       "      (18): Linear(in_features=201, out_features=212, bias=True)\n",
       "      (19): LeakyReLU(negative_slope=0.01)\n",
       "      (20): Dropout(p=0.2, inplace=False)\n",
       "      (21): Linear(in_features=212, out_features=10, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [231, 499, 491, 351, 252, 201, 212],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.007270966463269171,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 2.104233876991272,\n",
       "  'train_acc': 0.194875,\n",
       "  'val_loss': 1.9033189224243163,\n",
       "  'val_acc': 0.2639},\n",
       " 38: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=3072, out_features=253, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=253, out_features=18, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=18, out_features=373, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=373, out_features=122, bias=True)\n",
       "      (10): Sigmoid()\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=122, out_features=10, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [253, 18, 373, 122],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.006442530222731255,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 2.1199904579162596,\n",
       "  'train_acc': 0.187525,\n",
       "  'val_loss': 1.9357967336654662,\n",
       "  'val_acc': 0.2634},\n",
       " 39: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=3072, out_features=509, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Linear(in_features=509, out_features=135, bias=True)\n",
       "      (3): Sigmoid()\n",
       "      (4): Linear(in_features=135, out_features=83, bias=True)\n",
       "      (5): Sigmoid()\n",
       "      (6): Linear(in_features=83, out_features=270, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Linear(in_features=270, out_features=303, bias=True)\n",
       "      (9): Sigmoid()\n",
       "      (10): Linear(in_features=303, out_features=351, bias=True)\n",
       "      (11): Sigmoid()\n",
       "      (12): Linear(in_features=351, out_features=10, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [509, 135, 83, 270, 303, 351],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.004187200215019011,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 2.3039149826049803,\n",
       "  'train_acc': 0.09785,\n",
       "  'val_loss': 2.3029902935028077,\n",
       "  'val_acc': 0.0943},\n",
       " 40: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=3072, out_features=340, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=340, out_features=176, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=176, out_features=296, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=296, out_features=294, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=294, out_features=17, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.1, inplace=False)\n",
       "      (15): Linear(in_features=17, out_features=252, bias=True)\n",
       "      (16): LeakyReLU(negative_slope=0.01)\n",
       "      (17): Dropout(p=0.1, inplace=False)\n",
       "      (18): Linear(in_features=252, out_features=10, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [340, 176, 296, 294, 17, 252],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.005278484918382835,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 1.983644203186035,\n",
       "  'train_acc': 0.247425,\n",
       "  'val_loss': 1.8366308359146117,\n",
       "  'val_acc': 0.3251},\n",
       " 41: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=3072, out_features=150, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=150, out_features=394, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=394, out_features=165, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=165, out_features=10, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [150, 394, 165],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.003440782200344164,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 1.793475777053833,\n",
       "  'train_acc': 0.35885,\n",
       "  'val_loss': 1.6021691076278686,\n",
       "  'val_acc': 0.4286},\n",
       " 42: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=3072, out_features=138, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=138, out_features=234, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=234, out_features=100, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=100, out_features=459, bias=True)\n",
       "      (10): Sigmoid()\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=459, out_features=42, bias=True)\n",
       "      (13): Sigmoid()\n",
       "      (14): Dropout(p=0.1, inplace=False)\n",
       "      (15): Linear(in_features=42, out_features=378, bias=True)\n",
       "      (16): Sigmoid()\n",
       "      (17): Dropout(p=0.1, inplace=False)\n",
       "      (18): Linear(in_features=378, out_features=293, bias=True)\n",
       "      (19): Sigmoid()\n",
       "      (20): Dropout(p=0.1, inplace=False)\n",
       "      (21): Linear(in_features=293, out_features=10, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [138, 234, 100, 459, 42, 378, 293],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0024215380471444324,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 2.260920728302002,\n",
       "  'train_acc': 0.127625,\n",
       "  'val_loss': 2.1109754978179933,\n",
       "  'val_acc': 0.1812}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_gen.generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-Epoch: 0\n",
      "Mean val_loss: 2.0908623748823647\n",
      "Mean val_acc: 0.21348604651162792\n",
      "Survivor models: 43\n",
      "\n",
      "-Epoch: 1\n",
      "Mean val_loss: 1.9850710687740427\n",
      "Mean val_acc: 0.26521081081081077\n",
      "Survivor models: 37\n",
      "\n",
      "-Epoch: 2\n",
      "Mean val_loss: 1.8977173089325432\n",
      "Mean val_acc: 0.31438437499999994\n",
      "Survivor models: 32\n",
      "\n",
      "-Epoch: 3\n",
      "Mean val_loss: 1.79371523364612\n",
      "Mean val_acc: 0.34435000000000004\n",
      "Survivor models: 28\n",
      "\n",
      "-Epoch: 4\n",
      "Mean val_loss: 1.7183056588649757\n",
      "Mean val_acc: 0.3704708333333333\n",
      "Survivor models: 24\n",
      "\n",
      "-Epoch: 5\n",
      "Mean val_loss: 1.654283877617972\n",
      "Mean val_acc: 0.40369047619047616\n",
      "Survivor models: 21\n",
      "\n",
      "-Epoch: 6\n",
      "Mean val_loss: 1.600517815981971\n",
      "Mean val_acc: 0.4250777777777778\n",
      "Survivor models: 18\n",
      "\n",
      "-Epoch: 7\n",
      "Mean val_loss: 1.5580468045830729\n",
      "Mean val_acc: 0.44279374999999993\n",
      "Survivor models: 16\n",
      "\n",
      "-Epoch: 8\n",
      "Mean val_loss: 1.532706580339159\n",
      "Mean val_acc: 0.456\n",
      "Survivor models: 14\n",
      "\n",
      "-Epoch: 9\n",
      "Mean val_loss: 1.507398098866145\n",
      "Mean val_acc: 0.469325\n",
      "Survivor models: 12\n",
      "\n",
      "-Epoch: 10\n",
      "Mean val_loss: 1.485136853339455\n",
      "Mean val_acc: 0.4818818181818182\n",
      "Survivor models: 11\n",
      "\n",
      "-Epoch: 11\n",
      "Mean val_loss: 1.4560432760238646\n",
      "Mean val_acc: 0.49180999999999997\n",
      "Survivor models: 10\n",
      "\n",
      "-Epoch: 12\n",
      "Mean val_loss: 1.4662154604805842\n",
      "Mean val_acc: 0.4890555555555555\n",
      "Survivor models: 9\n",
      "\n",
      "-Epoch: 13\n",
      "Mean val_loss: 1.4569751585483548\n",
      "Mean val_acc: 0.4889625\n",
      "Survivor models: 8\n",
      "\n",
      "-Epoch: 14\n",
      "Mean val_loss: 1.473757835660662\n",
      "Mean val_acc: 0.48494285714285706\n",
      "Survivor models: 7\n",
      "\n",
      "-Epoch: 15\n",
      "Mean val_loss: 1.4523177501678468\n",
      "Mean val_acc: 0.4853\n",
      "Survivor models: 6\n",
      "\n",
      "-Epoch: 16\n",
      "Mean val_loss: 1.42126456363678\n",
      "Mean val_acc: 0.49935999999999997\n",
      "Survivor models: 5\n",
      "\n",
      "-Epoch: 17\n",
      "Mean val_loss: 1.4157673014163972\n",
      "Mean val_acc: 0.501775\n",
      "Survivor models: 4\n",
      "\n",
      "-Epoch: 18\n",
      "Mean val_loss: 1.4029694677352904\n",
      "Mean val_acc: 0.5054\n",
      "Survivor models: 3\n",
      "\n",
      "-Epoch: 19\n",
      "Mean val_loss: 1.3862183598518372\n",
      "Mean val_acc: 0.51815\n",
      "Survivor models: 2\n",
      "\n",
      "-Epoch: 20\n",
      "Mean val_loss: 1.3295165924072265\n",
      "Mean val_acc: 0.5341\n",
      "Survivor models: 1\n"
     ]
    }
   ],
   "source": [
    "number_of_epochs = 20\n",
    "# create a new gen\n",
    "generation = Generation(search_space, N_INDIVIDUALS)\n",
    "for n_epoch in range(number_of_epochs + 1):\n",
    "    print('\\n-Epoch:', n_epoch)\n",
    "    final_gen = run_generation(generation, train_loader, val_loader)\n",
    "    # Extract val_loss values\n",
    "    val_losses = [final_gen.generation[gen]['val_loss'] for gen in final_gen.generation]\n",
    "\n",
    "    # Calculate the mean val_loss\n",
    "    mean_val_loss = sum(val_losses) / len(val_losses)\n",
    "    # Print the mean val_loss\n",
    "    print(\"Mean val_loss:\", mean_val_loss)\n",
    "\n",
    "    # Extract val_Accuracy values\n",
    "    val_accuracies = [final_gen.generation[gen]['val_acc'] for gen in final_gen.generation]\n",
    "\n",
    "    # Calculate the mean val_loss\n",
    "    mean_val_acc = sum(val_accuracies) / len(val_accuracies)\n",
    "    # Print the mean val_loss\n",
    "    print(\"Mean val_acc:\", mean_val_acc)\n",
    "    \n",
    "    print('Survivor models:', len(final_gen.generation))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AutoML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
