{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steps\n",
    "\n",
    "I want to create an **efficient, but simple** way for random neurons to be tested, and compared, taking into account that the less amount of training time tends to imply lower final performance.\n",
    "\n",
    "Up until now, I have tested the OE strategy as the key strategy to achieve such a goal. Nevertheless, my results show that this can be used as a early discarding technique, rather than a top model selection one. \n",
    "\n",
    "The threshold for the prune (per epoch) proposed based on the experiments is 15%. \n",
    "\n",
    "It appears that my project is leaning towards an overly simplified evolutionary algorithm, Naive if I may.\n",
    "\n",
    "Previously I've tested for early predictors of the final canonical performance of a Neural Network in the first epochs. Not so many good things there, beyond the threshold but...\n",
    "\n",
    "My current focus in this moment is to develop the NAS module. That is:\n",
    " - A library that builds neural network architectures *-based on a search space?*\n",
    " - Allows them to be trained by an arg number of epochs. \n",
    " - Measures their performance, epoch by epoch. \n",
    " - Discards those neurons that correspond to the lowest 15% of all the architectures tested, for an arg number of epochs. \n",
    " - Continues testing the previously selected neurons, up until a condition is met. *-e.g when only 10 candidates remain, pick and return the best model*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Also:\n",
    "\n",
    "- Let's test for classification problems versus other models.\n",
    "- Let's test using the optimal stopping problem solution."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
