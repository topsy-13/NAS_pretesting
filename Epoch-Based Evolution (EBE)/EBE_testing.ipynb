{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from epoch_based_evolution import SearchSpace, Generation\n",
    "import load_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class column is not numeric. Applying LabelEncoder.\n",
      "Data loaded successfully! as <class 'torch.Tensor'>\n",
      "Training data shape: torch.Size([384, 6])\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_val, y_val, X_test, y_test = load_data.load_openml_dataset(dataset_id=334, scaling=True, random_seed=None, return_as='tensor')\n",
    "input_size, output_size = load_data.get_tensor_sizes(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = SearchSpace(\n",
    "    input_size=input_size,\n",
    "    output_size=output_size,          \n",
    "    # min_layers=2,           # Minimum number of hidden layers\n",
    "    # max_layers=5,           # Maximum number of hidden layers\n",
    "    # min_neurons=16,         # Minimum neurons per layer\n",
    "    # max_neurons=256,        # Maximum neurons per layer\n",
    "    # activation_fns=[nn.ReLU, nn.LeakyReLU],  # Activation functions to sample\n",
    "    # dropout_rates=[0, 0.1, 0.2],             # Dropout rates to sample\n",
    "    # min_learning_rate=0.0001,                # Minimum learning rate\n",
    "    # max_learning_rate=0.01,                  # Maximum learning rate\n",
    "    # random_seeds=[42, 13, 2024],             # Random seeds for reproducibility\n",
    "    # min_batch_size=32,                       # Minimum batch size\n",
    "    # max_batch_size=512                       # Maximum batch size\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DynamicNN(\n",
      "  (network): Sequential(\n",
      "    (0): Linear(in_features=6, out_features=15, bias=True)\n",
      "    (1): Sigmoid()\n",
      "    (2): Dropout(p=0.2, inplace=False)\n",
      "    (3): Linear(in_features=15, out_features=288, bias=True)\n",
      "    (4): Sigmoid()\n",
      "    (5): Dropout(p=0.2, inplace=False)\n",
      "    (6): Linear(in_features=288, out_features=146, bias=True)\n",
      "    (7): Sigmoid()\n",
      "    (8): Dropout(p=0.2, inplace=False)\n",
      "    (9): Linear(in_features=146, out_features=356, bias=True)\n",
      "    (10): Sigmoid()\n",
      "    (11): Dropout(p=0.2, inplace=False)\n",
      "    (12): Linear(in_features=356, out_features=238, bias=True)\n",
      "    (13): Sigmoid()\n",
      "    (14): Dropout(p=0.2, inplace=False)\n",
      "    (15): Linear(in_features=238, out_features=301, bias=True)\n",
      "    (16): Sigmoid()\n",
      "    (17): Dropout(p=0.2, inplace=False)\n",
      "    (18): Linear(in_features=301, out_features=15, bias=True)\n",
      "    (19): Sigmoid()\n",
      "    (20): Dropout(p=0.2, inplace=False)\n",
      "    (21): Linear(in_features=15, out_features=2, bias=True)\n",
      "  )\n",
      "  (criterion): CrossEntropyLoss()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "architecture = search_space.sample_architecture()\n",
    "batch_size = architecture['batch_size']\n",
    "model = search_space.create_model(architecture)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoaders\n",
    "train_dataset, train_loader = load_data.create_dataset_and_loader(X_train, y_train,\n",
    "                                                        batch_size=batch_size)\n",
    "val_dataset, val_loader = load_data.create_dataset_and_loader(X_val, y_val, \n",
    "                                                    batch_size=batch_size)\n",
    "test_dataset, test_loader = load_data.create_dataset_and_loader(X_test, y_test,\n",
    "                                                      batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0275837182998657, 0.3411458333333333)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.oe_train(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the first generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_INDIVIDUALS = 1000\n",
    "first_gen = Generation(search_space, n_individuals=N_INDIVIDUALS)\n",
    "# first_gen.generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN THE GEN\n",
    "first_gen.train_generation(train_loader, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_gen.validate_generation(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6365823745727539"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_gen.generation[0]['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[265, 761, 387, 370, 832, 662, 273, 816, 396, 989, 436, 855, 794, 409, 181, 997, 84, 999, 995, 454, 690, 162, 216, 778, 399, 535, 671, 906, 12, 652, 51, 785, 472, 112, 840, 242, 888, 144, 745, 517, 543, 404, 324, 302, 874, 806, 542, 747, 431, 780, 674, 808, 95, 791, 653, 885, 132, 884, 197, 860, 239, 200, 576, 277, 833, 93, 919, 136, 812, 16, 67, 866, 871, 672, 457, 421, 42, 28, 604, 223, 17, 464, 818, 687, 238, 434, 27, 37, 254, 6, 612, 773, 524, 527, 477, 156, 752, 921, 526, 380, 834, 724, 213, 439, 151, 363, 642, 717, 63, 167, 886, 290, 751, 809, 734, 868, 633, 83, 106, 425, 483, 824, 720, 157, 820, 221, 649, 476, 546, 29, 96, 467, 755, 625, 199, 248, 661, 131, 171, 344, 732, 78, 575, 366, 583, 728, 539, 336, 963, 881]\n"
     ]
    }
   ],
   "source": [
    "first_gen.get_worst_individuals(percentile_drop=15)\n",
    "print(first_gen.worst_individuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_gen.drop_worst_individuals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "850"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(first_gen.generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from epoch_based_evolution import run_generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=251, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=251, out_features=229, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=229, out_features=128, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=128, out_features=389, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=389, out_features=233, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.1, inplace=False)\n",
       "      (15): Linear(in_features=233, out_features=489, bias=True)\n",
       "      (16): LeakyReLU(negative_slope=0.01)\n",
       "      (17): Dropout(p=0.1, inplace=False)\n",
       "      (18): Linear(in_features=489, out_features=83, bias=True)\n",
       "      (19): LeakyReLU(negative_slope=0.01)\n",
       "      (20): Dropout(p=0.1, inplace=False)\n",
       "      (21): Linear(in_features=83, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [251, 229, 128, 389, 233, 489, 83],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.004995090870006855,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.6882950663566589,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.6365823745727539,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 1: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=164, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=164, out_features=21, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=21, out_features=188, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=188, out_features=158, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=158, out_features=436, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=436, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [164, 21, 188, 158, 436],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0050905285292256915,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.6914188861846924,\n",
       "  'train_acc': 0.4921875,\n",
       "  'val_loss': 0.6364597678184509,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 2: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=443, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=443, out_features=326, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=326, out_features=349, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=349, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [443, 326, 349],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.006435098436769071,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.6793724894523621,\n",
       "  'train_acc': 0.5989583333333334,\n",
       "  'val_loss': 0.6756393313407898,\n",
       "  'val_acc': 0.65625},\n",
       " 3: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=486, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=486, out_features=296, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=296, out_features=88, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=88, out_features=381, bias=True)\n",
       "      (10): Sigmoid()\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=381, out_features=208, bias=True)\n",
       "      (13): Sigmoid()\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=208, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [486, 296, 88, 381, 208],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.004425970320634492,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.9851140975952148,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.8822535872459412,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 4: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=368, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=368, out_features=33, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=33, out_features=57, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=57, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [368, 33, 57],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0012837115332981635,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.6575940847396851,\n",
       "  'train_acc': 0.6614583333333334,\n",
       "  'val_loss': 0.6532886624336243,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 5: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=126, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=126, out_features=238, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=238, out_features=305, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=305, out_features=330, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=330, out_features=488, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.2, inplace=False)\n",
       "      (15): Linear(in_features=488, out_features=55, bias=True)\n",
       "      (16): LeakyReLU(negative_slope=0.01)\n",
       "      (17): Dropout(p=0.2, inplace=False)\n",
       "      (18): Linear(in_features=55, out_features=205, bias=True)\n",
       "      (19): LeakyReLU(negative_slope=0.01)\n",
       "      (20): Dropout(p=0.2, inplace=False)\n",
       "      (21): Linear(in_features=205, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [126, 238, 305, 330, 488, 55, 205],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.008532907430593444,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.6982836723327637,\n",
       "  'train_acc': 0.390625,\n",
       "  'val_loss': 0.6985788941383362,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 6: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=473, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Linear(in_features=473, out_features=413, bias=True)\n",
       "      (3): Sigmoid()\n",
       "      (4): Linear(in_features=413, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [473, 413],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0021267845477836193,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.6430311799049377,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.630723774433136,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 7: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=62, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Linear(in_features=62, out_features=244, bias=True)\n",
       "      (3): Sigmoid()\n",
       "      (4): Linear(in_features=244, out_features=491, bias=True)\n",
       "      (5): Sigmoid()\n",
       "      (6): Linear(in_features=491, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [62, 244, 491],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0010805543547178435,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.6421166062355042,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.7665690779685974,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 8: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=255, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=255, out_features=102, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=102, out_features=387, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=387, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [255, 102, 387],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.006192510394892843,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.694508969783783,\n",
       "  'train_acc': 0.5260416666666666,\n",
       "  'val_loss': 0.6301823258399963,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 9: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=441, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=441, out_features=437, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=437, out_features=37, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=37, out_features=433, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=433, out_features=372, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.2, inplace=False)\n",
       "      (15): Linear(in_features=372, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [441, 437, 37, 433, 372],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.008349845264352344,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.6899699568748474,\n",
       "  'train_acc': 0.5859375,\n",
       "  'val_loss': 0.6887087225914001,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 10: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=339, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=339, out_features=269, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=269, out_features=321, bias=True)\n",
       "      (5): ReLU()\n",
       "      (6): Linear(in_features=321, out_features=486, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Linear(in_features=486, out_features=178, bias=True)\n",
       "      (9): ReLU()\n",
       "      (10): Linear(in_features=178, out_features=114, bias=True)\n",
       "      (11): ReLU()\n",
       "      (12): Linear(in_features=114, out_features=417, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Linear(in_features=417, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [339, 269, 321, 486, 178, 114, 417],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.007443533657195202,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.6953570246696472,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.6947169303894043,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 11: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=451, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=451, out_features=148, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=148, out_features=436, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=436, out_features=294, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=294, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [451, 148, 436, 294],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0011219079943918498,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.6945666670799255,\n",
       "  'train_acc': 0.4401041666666667,\n",
       "  'val_loss': 0.6938793063163757,\n",
       "  'val_acc': 0.4375},\n",
       " 12: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=426, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=426, out_features=64, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=64, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [426, 64],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.001997960536817312,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.6843934655189514,\n",
       "  'train_acc': 0.6276041666666666,\n",
       "  'val_loss': 0.6362360119819641,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 13: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=129, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=129, out_features=278, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=278, out_features=248, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=248, out_features=346, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=346, out_features=392, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=392, out_features=486, bias=True)\n",
       "      (16): ReLU()\n",
       "      (17): Dropout(p=0.5, inplace=False)\n",
       "      (18): Linear(in_features=486, out_features=131, bias=True)\n",
       "      (19): ReLU()\n",
       "      (20): Dropout(p=0.5, inplace=False)\n",
       "      (21): Linear(in_features=131, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [129, 278, 248, 346, 392, 486, 131],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0016660749274460653,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.6865831017494202,\n",
       "  'train_acc': 0.6536458333333334,\n",
       "  'val_loss': 0.6856701374053955,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 14: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=197, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=197, out_features=286, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=286, out_features=94, bias=True)\n",
       "      (5): ReLU()\n",
       "      (6): Linear(in_features=94, out_features=383, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Linear(in_features=383, out_features=140, bias=True)\n",
       "      (9): ReLU()\n",
       "      (10): Linear(in_features=140, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [197, 286, 94, 383, 140],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.00752805751983519,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.6718104481697083,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.8302814960479736,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 15: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=323, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=323, out_features=22, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=22, out_features=179, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=179, out_features=298, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=298, out_features=253, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.2, inplace=False)\n",
       "      (15): Linear(in_features=253, out_features=66, bias=True)\n",
       "      (16): ReLU()\n",
       "      (17): Dropout(p=0.2, inplace=False)\n",
       "      (18): Linear(in_features=66, out_features=350, bias=True)\n",
       "      (19): ReLU()\n",
       "      (20): Dropout(p=0.2, inplace=False)\n",
       "      (21): Linear(in_features=350, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [323, 22, 179, 298, 253, 66, 350],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0054462655169941155,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.6882838606834412,\n",
       "  'train_acc': 0.625,\n",
       "  'val_loss': 0.6352759003639221,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 16: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=150, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=150, out_features=358, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=358, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [150, 358],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.005478583615285308,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.689164936542511,\n",
       "  'train_acc': 0.5416666666666666,\n",
       "  'val_loss': 0.7495503425598145,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 17: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=162, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=162, out_features=347, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=347, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [162, 347],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0028929239952135578,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.6838435530662537,\n",
       "  'train_acc': 0.5598958333333334,\n",
       "  'val_loss': 0.6474857330322266,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 18: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=376, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=376, out_features=316, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=316, out_features=108, bias=True)\n",
       "      (5): LeakyReLU(negative_slope=0.01)\n",
       "      (6): Linear(in_features=108, out_features=285, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Linear(in_features=285, out_features=205, bias=True)\n",
       "      (9): LeakyReLU(negative_slope=0.01)\n",
       "      (10): Linear(in_features=205, out_features=20, bias=True)\n",
       "      (11): LeakyReLU(negative_slope=0.01)\n",
       "      (12): Linear(in_features=20, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [376, 316, 108, 285, 205, 20],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.00939806740740887,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.6975624561309814,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.8321590423583984,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 19: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=250, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=250, out_features=329, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=329, out_features=103, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=103, out_features=124, bias=True)\n",
       "      (10): Sigmoid()\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=124, out_features=360, bias=True)\n",
       "      (13): Sigmoid()\n",
       "      (14): Dropout(p=0.1, inplace=False)\n",
       "      (15): Linear(in_features=360, out_features=237, bias=True)\n",
       "      (16): Sigmoid()\n",
       "      (17): Dropout(p=0.1, inplace=False)\n",
       "      (18): Linear(in_features=237, out_features=214, bias=True)\n",
       "      (19): Sigmoid()\n",
       "      (20): Dropout(p=0.1, inplace=False)\n",
       "      (21): Linear(in_features=214, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [250, 329, 103, 124, 360, 237, 214],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0023249508369271475,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.6708361506462097,\n",
       "  'train_acc': 0.6328125,\n",
       "  'val_loss': 0.6668970584869385,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 20: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=41, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Linear(in_features=41, out_features=107, bias=True)\n",
       "      (3): Sigmoid()\n",
       "      (4): Linear(in_features=107, out_features=199, bias=True)\n",
       "      (5): Sigmoid()\n",
       "      (6): Linear(in_features=199, out_features=99, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Linear(in_features=99, out_features=106, bias=True)\n",
       "      (9): Sigmoid()\n",
       "      (10): Linear(in_features=106, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [41, 107, 199, 99, 106],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.004852597570556441,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.6428037285804749,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.6290540099143982,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 21: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=480, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=480, out_features=48, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=48, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [480, 48],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.005484354688066022,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.6756095886230469,\n",
       "  'train_acc': 0.6302083333333334,\n",
       "  'val_loss': 0.673899233341217,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 22: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=482, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=482, out_features=508, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=508, out_features=477, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=477, out_features=31, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=31, out_features=252, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.1, inplace=False)\n",
       "      (15): Linear(in_features=252, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [482, 508, 477, 31, 252],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.004495712631269512,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.6998209953308105,\n",
       "  'train_acc': 0.3489583333333333,\n",
       "  'val_loss': 0.6430049538612366,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 23: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=80, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=80, out_features=490, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=490, out_features=371, bias=True)\n",
       "      (5): ReLU()\n",
       "      (6): Linear(in_features=371, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [80, 490, 371],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0037647947606641186,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.6779183745384216,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.7346876263618469,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 24: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=195, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=195, out_features=252, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=252, out_features=270, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=270, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [195, 252, 270],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.005492257149622053,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.7004513144493103,\n",
       "  'train_acc': 0.3984375,\n",
       "  'val_loss': 0.6749157309532166,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 25: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=23, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=23, out_features=387, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=387, out_features=144, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=144, out_features=479, bias=True)\n",
       "      (10): Sigmoid()\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=479, out_features=235, bias=True)\n",
       "      (13): Sigmoid()\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=235, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [23, 387, 144, 479, 235],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0011574441786614113,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.6948340535163879,\n",
       "  'train_acc': 0.5442708333333334,\n",
       "  'val_loss': 0.6651745438575745,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 26: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=360, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=360, out_features=466, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=466, out_features=261, bias=True)\n",
       "      (5): ReLU()\n",
       "      (6): Linear(in_features=261, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [360, 466, 261],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0035545969794660254,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.7030496001243591,\n",
       "  'train_acc': 0.3567708333333333,\n",
       "  'val_loss': 0.7274196147918701,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 27: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=378, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=378, out_features=332, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=332, out_features=113, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=113, out_features=141, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=141, out_features=333, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=333, out_features=115, bias=True)\n",
       "      (16): ReLU()\n",
       "      (17): Dropout(p=0.5, inplace=False)\n",
       "      (18): Linear(in_features=115, out_features=509, bias=True)\n",
       "      (19): ReLU()\n",
       "      (20): Dropout(p=0.5, inplace=False)\n",
       "      (21): Linear(in_features=509, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [378, 332, 113, 141, 333, 115, 509],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0032179171923470196,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.685190737247467,\n",
       "  'train_acc': 0.640625,\n",
       "  'val_loss': 0.6836954951286316,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 28: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=127, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=127, out_features=413, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=413, out_features=417, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=417, out_features=150, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=150, out_features=107, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.2, inplace=False)\n",
       "      (15): Linear(in_features=107, out_features=56, bias=True)\n",
       "      (16): LeakyReLU(negative_slope=0.01)\n",
       "      (17): Dropout(p=0.2, inplace=False)\n",
       "      (18): Linear(in_features=56, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [127, 413, 417, 150, 107, 56],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.005765895050628369,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.6888622641563416,\n",
       "  'train_acc': 0.65625,\n",
       "  'val_loss': 0.6474735140800476,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 29: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=283, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=283, out_features=50, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=50, out_features=424, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=424, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [283, 50, 424],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.003913355743478996,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.8185710310935974,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.6919344067573547,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 30: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=17, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=17, out_features=346, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=346, out_features=391, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=391, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [17, 346, 391],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0011904008138237988,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.7056946754455566,\n",
       "  'train_acc': 0.3984375,\n",
       "  'val_loss': 0.708853542804718,\n",
       "  'val_acc': 0.3958333333333333},\n",
       " 31: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=247, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=247, out_features=93, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=93, out_features=41, bias=True)\n",
       "      (5): LeakyReLU(negative_slope=0.01)\n",
       "      (6): Linear(in_features=41, out_features=330, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Linear(in_features=330, out_features=284, bias=True)\n",
       "      (9): LeakyReLU(negative_slope=0.01)\n",
       "      (10): Linear(in_features=284, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [247, 93, 41, 330, 284],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0013287172052857323,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.7169968485832214,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.6870763301849365,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 32: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=478, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=478, out_features=87, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=87, out_features=423, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=423, out_features=372, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=372, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [478, 87, 423, 372],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.007482532513621572,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.7010822892189026,\n",
       "  'train_acc': 0.359375,\n",
       "  'val_loss': 0.6992605328559875,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 33: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=456, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=456, out_features=164, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=164, out_features=61, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=61, out_features=339, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=339, out_features=170, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.1, inplace=False)\n",
       "      (15): Linear(in_features=170, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [456, 164, 61, 339, 170],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.00858880797753562,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.6958029866218567,\n",
       "  'train_acc': 0.3567708333333333,\n",
       "  'val_loss': 0.6956461071968079,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 34: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=342, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=342, out_features=481, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=481, out_features=381, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=381, out_features=171, bias=True)\n",
       "      (10): Sigmoid()\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=171, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [342, 481, 381, 171],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.009448711352555598,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.7252938747406006,\n",
       "  'train_acc': 0.4973958333333333,\n",
       "  'val_loss': 0.6777269244194031,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 35: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=336, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=336, out_features=390, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=390, out_features=223, bias=True)\n",
       "      (5): ReLU()\n",
       "      (6): Linear(in_features=223, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [336, 390, 223],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0023465102422602874,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.7017499804496765,\n",
       "  'train_acc': 0.3463541666666667,\n",
       "  'val_loss': 0.6257609724998474,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 36: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=278, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=278, out_features=271, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=271, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [278, 271],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.004692205412344439,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.7314005494117737,\n",
       "  'train_acc': 0.3463541666666667,\n",
       "  'val_loss': 0.7083936333656311,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 37: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=126, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=126, out_features=147, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=147, out_features=33, bias=True)\n",
       "      (5): LeakyReLU(negative_slope=0.01)\n",
       "      (6): Linear(in_features=33, out_features=476, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Linear(in_features=476, out_features=496, bias=True)\n",
       "      (9): LeakyReLU(negative_slope=0.01)\n",
       "      (10): Linear(in_features=496, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [126, 147, 33, 476, 496],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.008768029173740808,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.6945622563362122,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.69370037317276,\n",
       "  'val_acc': 0.4270833333333333},\n",
       " 38: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=205, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=205, out_features=418, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=418, out_features=449, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=449, out_features=469, bias=True)\n",
       "      (10): Sigmoid()\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=469, out_features=90, bias=True)\n",
       "      (13): Sigmoid()\n",
       "      (14): Dropout(p=0.1, inplace=False)\n",
       "      (15): Linear(in_features=90, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [205, 418, 449, 469, 90],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.00521493653541164,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.6779806017875671,\n",
       "  'train_acc': 0.5963541666666666,\n",
       "  'val_loss': 0.9026079177856445,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 39: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=84, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=84, out_features=493, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=493, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [84, 493],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.008419635286268889,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.7117113471031189,\n",
       "  'train_acc': 0.4973958333333333,\n",
       "  'val_loss': 0.6943836808204651,\n",
       "  'val_acc': 0.5},\n",
       " 40: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=151, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Linear(in_features=151, out_features=446, bias=True)\n",
       "      (3): Sigmoid()\n",
       "      (4): Linear(in_features=446, out_features=287, bias=True)\n",
       "      (5): Sigmoid()\n",
       "      (6): Linear(in_features=287, out_features=36, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Linear(in_features=36, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [151, 446, 287, 36],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.009978940635338617,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.6660643219947815,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.8503645062446594,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 41: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=145, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=145, out_features=232, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=232, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [145, 232],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.005473081728897913,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.7077935338020325,\n",
       "  'train_acc': 0.4453125,\n",
       "  'val_loss': 0.7108200192451477,\n",
       "  'val_acc': 0.3645833333333333},\n",
       " 42: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=122, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=122, out_features=44, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=44, out_features=95, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=95, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [122, 44, 95],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0046949658663998,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.6728265881538391,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.6447134017944336,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 43: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=277, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=277, out_features=20, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=20, out_features=19, bias=True)\n",
       "      (5): ReLU()\n",
       "      (6): Linear(in_features=19, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [277, 20, 19],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.008806427792313207,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.7188065052032471,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.72018963098526,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 44: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=46, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Linear(in_features=46, out_features=129, bias=True)\n",
       "      (3): Sigmoid()\n",
       "      (4): Linear(in_features=129, out_features=15, bias=True)\n",
       "      (5): Sigmoid()\n",
       "      (6): Linear(in_features=15, out_features=24, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Linear(in_features=24, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [46, 129, 15, 24],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0069522302528725955,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.6445128321647644,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.6295814514160156,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 45: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=501, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=501, out_features=311, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=311, out_features=204, bias=True)\n",
       "      (5): LeakyReLU(negative_slope=0.01)\n",
       "      (6): Linear(in_features=204, out_features=351, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Linear(in_features=351, out_features=106, bias=True)\n",
       "      (9): LeakyReLU(negative_slope=0.01)\n",
       "      (10): Linear(in_features=106, out_features=266, bias=True)\n",
       "      (11): LeakyReLU(negative_slope=0.01)\n",
       "      (12): Linear(in_features=266, out_features=27, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Linear(in_features=27, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [501, 311, 204, 351, 106, 266, 27],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0028571863783308053,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.7009508013725281,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.6799187064170837,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 46: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=211, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=211, out_features=290, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=290, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [211, 290],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.005967926178056812,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.6902346611022949,\n",
       "  'train_acc': 0.5416666666666666,\n",
       "  'val_loss': 0.8687498569488525,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 47: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=175, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=175, out_features=109, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=109, out_features=156, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=156, out_features=456, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=456, out_features=312, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.1, inplace=False)\n",
       "      (15): Linear(in_features=312, out_features=126, bias=True)\n",
       "      (16): LeakyReLU(negative_slope=0.01)\n",
       "      (17): Dropout(p=0.1, inplace=False)\n",
       "      (18): Linear(in_features=126, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [175, 109, 156, 456, 312, 126],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.002406612146214258,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.6986871361732483,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.6722111105918884,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 48: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=373, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=373, out_features=213, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=213, out_features=360, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=360, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [373, 213, 360],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.008551929143468648,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.7183959484100342,\n",
       "  'train_acc': 0.3958333333333333,\n",
       "  'val_loss': 0.7029375433921814,\n",
       "  'val_acc': 0.3125},\n",
       " 49: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=45, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Linear(in_features=45, out_features=346, bias=True)\n",
       "      (3): Sigmoid()\n",
       "      (4): Linear(in_features=346, out_features=253, bias=True)\n",
       "      (5): Sigmoid()\n",
       "      (6): Linear(in_features=253, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [45, 346, 253],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.009605052517762547,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.6987645030021667,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.6659290194511414,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 50: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=136, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=136, out_features=450, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=450, out_features=397, bias=True)\n",
       "      (5): LeakyReLU(negative_slope=0.01)\n",
       "      (6): Linear(in_features=397, out_features=80, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Linear(in_features=80, out_features=414, bias=True)\n",
       "      (9): LeakyReLU(negative_slope=0.01)\n",
       "      (10): Linear(in_features=414, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [136, 450, 397, 80, 414],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.00247714509547024,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.6941132545471191,\n",
       "  'train_acc': 0.3723958333333333,\n",
       "  'val_loss': 0.6940763592720032,\n",
       "  'val_acc': 0.3541666666666667},\n",
       " 51: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=236, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=236, out_features=23, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=23, out_features=63, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=63, out_features=389, bias=True)\n",
       "      (10): Sigmoid()\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=389, out_features=360, bias=True)\n",
       "      (13): Sigmoid()\n",
       "      (14): Dropout(p=0.1, inplace=False)\n",
       "      (15): Linear(in_features=360, out_features=56, bias=True)\n",
       "      (16): Sigmoid()\n",
       "      (17): Dropout(p=0.1, inplace=False)\n",
       "      (18): Linear(in_features=56, out_features=351, bias=True)\n",
       "      (19): Sigmoid()\n",
       "      (20): Dropout(p=0.1, inplace=False)\n",
       "      (21): Linear(in_features=351, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [236, 23, 63, 389, 360, 56, 351],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0021057373892138078,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.6538711786270142,\n",
       "  'train_acc': 0.6692708333333334,\n",
       "  'val_loss': 0.6459293961524963,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 52: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=221, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=221, out_features=326, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=326, out_features=435, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=435, out_features=354, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=354, out_features=440, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.2, inplace=False)\n",
       "      (15): Linear(in_features=440, out_features=112, bias=True)\n",
       "      (16): ReLU()\n",
       "      (17): Dropout(p=0.2, inplace=False)\n",
       "      (18): Linear(in_features=112, out_features=506, bias=True)\n",
       "      (19): ReLU()\n",
       "      (20): Dropout(p=0.2, inplace=False)\n",
       "      (21): Linear(in_features=506, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [221, 326, 435, 354, 440, 112, 506],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.002167529683666335,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.6972203254699707,\n",
       "  'train_acc': 0.3671875,\n",
       "  'val_loss': 0.6709232330322266,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 53: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=486, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=486, out_features=134, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=134, out_features=100, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=100, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [486, 134, 100],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.009084902100963587,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.7112297415733337,\n",
       "  'train_acc': 0.5364583333333334,\n",
       "  'val_loss': 0.6813532710075378,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 54: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=282, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=282, out_features=295, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=295, out_features=437, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=437, out_features=108, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=108, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [282, 295, 437, 108],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.006013430880103058,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.7104738354682922,\n",
       "  'train_acc': 0.34375,\n",
       "  'val_loss': 0.7127133011817932,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 55: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=26, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=26, out_features=314, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=314, out_features=223, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=223, out_features=44, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=44, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [26, 314, 223, 44],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.004826789777153803,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.6921632289886475,\n",
       "  'train_acc': 0.5260416666666666,\n",
       "  'val_loss': 0.6385195851325989,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 56: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=271, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=271, out_features=299, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=299, out_features=491, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=491, out_features=212, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=212, out_features=509, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.1, inplace=False)\n",
       "      (15): Linear(in_features=509, out_features=70, bias=True)\n",
       "      (16): ReLU()\n",
       "      (17): Dropout(p=0.1, inplace=False)\n",
       "      (18): Linear(in_features=70, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [271, 299, 491, 212, 509, 70],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0045040116323585375,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.7106066346168518,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.7120916843414307,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 57: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=135, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=135, out_features=276, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=276, out_features=496, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=496, out_features=192, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=192, out_features=387, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=387, out_features=196, bias=True)\n",
       "      (16): ReLU()\n",
       "      (17): Dropout(p=0.5, inplace=False)\n",
       "      (18): Linear(in_features=196, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [135, 276, 496, 192, 387, 196],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0011004572689073666,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.6933059692382812,\n",
       "  'train_acc': 0.5052083333333334,\n",
       "  'val_loss': 0.6939510703086853,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 58: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=302, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=302, out_features=425, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=425, out_features=317, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=317, out_features=291, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=291, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [302, 425, 317, 291],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.005536477680469582,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.6901171803474426,\n",
       "  'train_acc': 0.5286458333333334,\n",
       "  'val_loss': 0.696453332901001,\n",
       "  'val_acc': 0.3958333333333333},\n",
       " 59: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=469, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Linear(in_features=469, out_features=497, bias=True)\n",
       "      (3): Sigmoid()\n",
       "      (4): Linear(in_features=497, out_features=485, bias=True)\n",
       "      (5): Sigmoid()\n",
       "      (6): Linear(in_features=485, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [469, 497, 485],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0032967562562680516,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.6518082618713379,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.6405366659164429,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 60: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=118, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=118, out_features=200, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=200, out_features=265, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=265, out_features=221, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=221, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [118, 200, 265, 221],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.007521891059715589,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.691628634929657,\n",
       "  'train_acc': 0.5598958333333334,\n",
       "  'val_loss': 0.7975571751594543,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 61: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=106, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=106, out_features=151, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=151, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [106, 151],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.004916424970603399,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.6997606754302979,\n",
       "  'train_acc': 0.4635416666666667,\n",
       "  'val_loss': 0.6337776184082031,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 62: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=310, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=310, out_features=150, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=150, out_features=332, bias=True)\n",
       "      (5): LeakyReLU(negative_slope=0.01)\n",
       "      (6): Linear(in_features=332, out_features=56, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Linear(in_features=56, out_features=279, bias=True)\n",
       "      (9): LeakyReLU(negative_slope=0.01)\n",
       "      (10): Linear(in_features=279, out_features=88, bias=True)\n",
       "      (11): LeakyReLU(negative_slope=0.01)\n",
       "      (12): Linear(in_features=88, out_features=130, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Linear(in_features=130, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [310, 150, 332, 56, 279, 88, 130],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0017374706816362688,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.6968243718147278,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.6861355304718018,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 63: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=102, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=102, out_features=374, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=374, out_features=407, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=407, out_features=430, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=430, out_features=92, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=92, out_features=259, bias=True)\n",
       "      (16): LeakyReLU(negative_slope=0.01)\n",
       "      (17): Dropout(p=0.5, inplace=False)\n",
       "      (18): Linear(in_features=259, out_features=287, bias=True)\n",
       "      (19): LeakyReLU(negative_slope=0.01)\n",
       "      (20): Dropout(p=0.5, inplace=False)\n",
       "      (21): Linear(in_features=287, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [102, 374, 407, 430, 92, 259, 287],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.004042206428011374,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.7053852677345276,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.6618375778198242,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 64: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=141, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=141, out_features=285, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=285, out_features=233, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=233, out_features=309, bias=True)\n",
       "      (10): Sigmoid()\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=309, out_features=494, bias=True)\n",
       "      (13): Sigmoid()\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=494, out_features=201, bias=True)\n",
       "      (16): Sigmoid()\n",
       "      (17): Dropout(p=0.5, inplace=False)\n",
       "      (18): Linear(in_features=201, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [141, 285, 233, 309, 494, 201],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.008936697234190952,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.656782865524292,\n",
       "  'train_acc': 0.6432291666666666,\n",
       "  'val_loss': 0.629520833492279,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 65: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=274, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=274, out_features=37, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=37, out_features=327, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=327, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [274, 37, 327],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.005412271700604883,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.6960896849632263,\n",
       "  'train_acc': 0.4557291666666667,\n",
       "  'val_loss': 0.6955215930938721,\n",
       "  'val_acc': 0.5},\n",
       " 66: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=38, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=38, out_features=437, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=437, out_features=54, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=54, out_features=77, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=77, out_features=439, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.2, inplace=False)\n",
       "      (15): Linear(in_features=439, out_features=98, bias=True)\n",
       "      (16): LeakyReLU(negative_slope=0.01)\n",
       "      (17): Dropout(p=0.2, inplace=False)\n",
       "      (18): Linear(in_features=98, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [38, 437, 54, 77, 439, 98],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.008684414244158702,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.7181403040885925,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.6321126818656921,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 67: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=465, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=465, out_features=115, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=115, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [465, 115],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.008666754874557694,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.7863354682922363,\n",
       "  'train_acc': 0.3854166666666667,\n",
       "  'val_loss': 0.9416993260383606,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 68: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=351, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=351, out_features=496, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=496, out_features=251, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=251, out_features=187, bias=True)\n",
       "      (10): Sigmoid()\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=187, out_features=462, bias=True)\n",
       "      (13): Sigmoid()\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=462, out_features=87, bias=True)\n",
       "      (16): Sigmoid()\n",
       "      (17): Dropout(p=0.5, inplace=False)\n",
       "      (18): Linear(in_features=87, out_features=28, bias=True)\n",
       "      (19): Sigmoid()\n",
       "      (20): Dropout(p=0.5, inplace=False)\n",
       "      (21): Linear(in_features=28, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [351, 496, 251, 187, 462, 87, 28],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0035676786225719566,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.6696255207061768,\n",
       "  'train_acc': 0.609375,\n",
       "  'val_loss': 0.6568281650543213,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 69: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=254, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=254, out_features=100, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=100, out_features=329, bias=True)\n",
       "      (5): ReLU()\n",
       "      (6): Linear(in_features=329, out_features=16, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Linear(in_features=16, out_features=315, bias=True)\n",
       "      (9): ReLU()\n",
       "      (10): Linear(in_features=315, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [254, 100, 329, 16, 315],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.005391177227576941,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.6677877306938171,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.6262425780296326,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 70: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=50, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=50, out_features=431, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=431, out_features=114, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=114, out_features=490, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=490, out_features=281, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=281, out_features=349, bias=True)\n",
       "      (16): LeakyReLU(negative_slope=0.01)\n",
       "      (17): Dropout(p=0.5, inplace=False)\n",
       "      (18): Linear(in_features=349, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [50, 431, 114, 490, 281, 349],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.005318684676276489,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.6890654563903809,\n",
       "  'train_acc': 0.5677083333333334,\n",
       "  'val_loss': 0.6249271631240845,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 71: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=444, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=444, out_features=257, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=257, out_features=168, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=168, out_features=95, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=95, out_features=162, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=162, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [444, 257, 168, 95, 162],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0075564411859296255,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.686320960521698,\n",
       "  'train_acc': 0.59375,\n",
       "  'val_loss': 0.6241397857666016,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 72: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=41, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=41, out_features=413, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=413, out_features=73, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=73, out_features=87, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=87, out_features=270, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=270, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [41, 413, 73, 87, 270],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.00952410611427202,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.7010723948478699,\n",
       "  'train_acc': 0.3984375,\n",
       "  'val_loss': 0.6232995986938477,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 73: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=397, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=397, out_features=346, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=346, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [397, 346],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0029553156459114637,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.6795980930328369,\n",
       "  'train_acc': 0.6119791666666666,\n",
       "  'val_loss': 0.6712625026702881,\n",
       "  'val_acc': 0.6354166666666666},\n",
       " 74: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=69, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=69, out_features=67, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=67, out_features=174, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=174, out_features=421, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=421, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [69, 67, 174, 421],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.005405323520812711,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.6959505677223206,\n",
       "  'train_acc': 0.4869791666666667,\n",
       "  'val_loss': 0.6335701942443848,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 75: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=454, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=454, out_features=97, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=97, out_features=433, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=433, out_features=192, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=192, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [454, 97, 433, 192],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.004014337856315066,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.6862810254096985,\n",
       "  'train_acc': 0.640625,\n",
       "  'val_loss': 0.659243643283844,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 76: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=477, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=477, out_features=80, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=80, out_features=294, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=294, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [477, 80, 294],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.005146764863791854,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.6822649836540222,\n",
       "  'train_acc': 0.640625,\n",
       "  'val_loss': 0.6568402647972107,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 77: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=70, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=70, out_features=74, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=74, out_features=496, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=496, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [70, 74, 496],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.00793090532887291,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.7020835280418396,\n",
       "  'train_acc': 0.4921875,\n",
       "  'val_loss': 0.6506896615028381,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 78: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=436, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=436, out_features=166, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=166, out_features=499, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=499, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [436, 166, 499],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0022777670747085588,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.6986700892448425,\n",
       "  'train_acc': 0.4270833333333333,\n",
       "  'val_loss': 0.6290724873542786,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 79: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=505, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=505, out_features=85, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=85, out_features=204, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=204, out_features=96, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=96, out_features=428, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=428, out_features=87, bias=True)\n",
       "      (16): ReLU()\n",
       "      (17): Dropout(p=0.5, inplace=False)\n",
       "      (18): Linear(in_features=87, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [505, 85, 204, 96, 428, 87],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.005121044798012718,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.6947324872016907,\n",
       "  'train_acc': 0.484375,\n",
       "  'val_loss': 0.6412482261657715,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 80: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=169, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=169, out_features=210, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=210, out_features=87, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=87, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [169, 210, 87],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0030125558666707275,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.6798614859580994,\n",
       "  'train_acc': 0.5703125,\n",
       "  'val_loss': 0.6419656872749329,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 81: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=80, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=80, out_features=438, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=438, out_features=367, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=367, out_features=305, bias=True)\n",
       "      (10): Sigmoid()\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=305, out_features=81, bias=True)\n",
       "      (13): Sigmoid()\n",
       "      (14): Dropout(p=0.2, inplace=False)\n",
       "      (15): Linear(in_features=81, out_features=311, bias=True)\n",
       "      (16): Sigmoid()\n",
       "      (17): Dropout(p=0.2, inplace=False)\n",
       "      (18): Linear(in_features=311, out_features=421, bias=True)\n",
       "      (19): Sigmoid()\n",
       "      (20): Dropout(p=0.2, inplace=False)\n",
       "      (21): Linear(in_features=421, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [80, 438, 367, 305, 81, 311, 421],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0026460768463661107,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.774472713470459,\n",
       "  'train_acc': 0.375,\n",
       "  'val_loss': 0.7973935008049011,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 82: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=249, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=249, out_features=431, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=431, out_features=464, bias=True)\n",
       "      (5): ReLU()\n",
       "      (6): Linear(in_features=464, out_features=264, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Linear(in_features=264, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [249, 431, 464, 264],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.009465784462715853,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.7010371088981628,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.700767993927002,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 83: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=345, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=345, out_features=381, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=381, out_features=214, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=214, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [345, 381, 214],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.001933208013866327,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.6912376284599304,\n",
       "  'train_acc': 0.546875,\n",
       "  'val_loss': 0.6880093216896057,\n",
       "  'val_acc': 0.65625},\n",
       " 84: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=471, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Linear(in_features=471, out_features=446, bias=True)\n",
       "      (3): Sigmoid()\n",
       "      (4): Linear(in_features=446, out_features=503, bias=True)\n",
       "      (5): Sigmoid()\n",
       "      (6): Linear(in_features=503, out_features=430, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Linear(in_features=430, out_features=311, bias=True)\n",
       "      (9): Sigmoid()\n",
       "      (10): Linear(in_features=311, out_features=62, bias=True)\n",
       "      (11): Sigmoid()\n",
       "      (12): Linear(in_features=62, out_features=21, bias=True)\n",
       "      (13): Sigmoid()\n",
       "      (14): Linear(in_features=21, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [471, 446, 503, 430, 311, 62, 21],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0038567623457458683,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.6806568503379822,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.677974283695221,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 85: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=58, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=58, out_features=224, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=224, out_features=502, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=502, out_features=402, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=402, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [58, 224, 502, 402],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.002147728285648373,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.669597864151001,\n",
       "  'train_acc': 0.6484375,\n",
       "  'val_loss': 0.6759852766990662,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 86: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=267, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=267, out_features=338, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=338, out_features=326, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=326, out_features=334, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=334, out_features=111, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.1, inplace=False)\n",
       "      (15): Linear(in_features=111, out_features=508, bias=True)\n",
       "      (16): ReLU()\n",
       "      (17): Dropout(p=0.1, inplace=False)\n",
       "      (18): Linear(in_features=508, out_features=20, bias=True)\n",
       "      (19): ReLU()\n",
       "      (20): Dropout(p=0.1, inplace=False)\n",
       "      (21): Linear(in_features=20, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [267, 338, 326, 334, 111, 508, 20],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.004519445119638803,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.6791069507598877,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.677243173122406,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 87: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=47, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=47, out_features=429, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=429, out_features=432, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=432, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [47, 429, 432],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0010875881527619518,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.6911624073982239,\n",
       "  'train_acc': 0.5130208333333334,\n",
       "  'val_loss': 0.6336912512779236,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 88: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=49, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=49, out_features=176, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=176, out_features=262, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=262, out_features=500, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=500, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [49, 176, 262, 500],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.004972506388740738,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.7018720507621765,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.6268712878227234,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 89: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=474, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=474, out_features=264, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=264, out_features=324, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=324, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [474, 264, 324],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0030860815187745937,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.6775188446044922,\n",
       "  'train_acc': 0.6666666666666666,\n",
       "  'val_loss': 0.6677517294883728,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 90: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=442, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=442, out_features=305, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=305, out_features=499, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=499, out_features=18, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=18, out_features=117, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=117, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [442, 305, 499, 18, 117],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.005817244182718015,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.6823540329933167,\n",
       "  'train_acc': 0.59375,\n",
       "  'val_loss': 0.6243099570274353,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 91: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=392, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=392, out_features=405, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=405, out_features=503, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=503, out_features=38, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=38, out_features=342, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.2, inplace=False)\n",
       "      (15): Linear(in_features=342, out_features=437, bias=True)\n",
       "      (16): LeakyReLU(negative_slope=0.01)\n",
       "      (17): Dropout(p=0.2, inplace=False)\n",
       "      (18): Linear(in_features=437, out_features=250, bias=True)\n",
       "      (19): LeakyReLU(negative_slope=0.01)\n",
       "      (20): Dropout(p=0.2, inplace=False)\n",
       "      (21): Linear(in_features=250, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [392, 405, 503, 38, 342, 437, 250],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.006367443843477937,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.6902549266815186,\n",
       "  'train_acc': 0.6067708333333334,\n",
       "  'val_loss': 0.6897168755531311,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 92: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=17, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=17, out_features=361, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=361, out_features=240, bias=True)\n",
       "      (5): LeakyReLU(negative_slope=0.01)\n",
       "      (6): Linear(in_features=240, out_features=225, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Linear(in_features=225, out_features=18, bias=True)\n",
       "      (9): LeakyReLU(negative_slope=0.01)\n",
       "      (10): Linear(in_features=18, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [17, 361, 240, 225, 18],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.004251339902990786,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.6635324358940125,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.6591112017631531,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 93: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=88, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=88, out_features=417, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=417, out_features=387, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=387, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [88, 417, 387],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.00830083313992859,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.807296097278595,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.6970807909965515,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 94: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=103, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=103, out_features=108, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=108, out_features=38, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=38, out_features=427, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=427, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [103, 108, 38, 427],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.005387446945258353,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.6974021792411804,\n",
       "  'train_acc': 0.4192708333333333,\n",
       "  'val_loss': 0.6947188377380371,\n",
       "  'val_acc': 0.375},\n",
       " 95: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=118, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=118, out_features=332, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=332, out_features=88, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=88, out_features=511, bias=True)\n",
       "      (10): Sigmoid()\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=511, out_features=41, bias=True)\n",
       "      (13): Sigmoid()\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=41, out_features=240, bias=True)\n",
       "      (16): Sigmoid()\n",
       "      (17): Dropout(p=0.5, inplace=False)\n",
       "      (18): Linear(in_features=240, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [118, 332, 88, 511, 41, 240],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0015414693967891208,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.7679479718208313,\n",
       "  'train_acc': 0.4088541666666667,\n",
       "  'val_loss': 0.6635251641273499,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 96: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=79, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=79, out_features=291, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=291, out_features=28, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=28, out_features=67, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=67, out_features=458, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.1, inplace=False)\n",
       "      (15): Linear(in_features=458, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [79, 291, 28, 67, 458],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0016614246084094386,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.6928096413612366,\n",
       "  'train_acc': 0.5130208333333334,\n",
       "  'val_loss': 0.6931970715522766,\n",
       "  'val_acc': 0.5729166666666666},\n",
       " 97: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=96, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=96, out_features=346, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=346, out_features=464, bias=True)\n",
       "      (5): LeakyReLU(negative_slope=0.01)\n",
       "      (6): Linear(in_features=464, out_features=173, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Linear(in_features=173, out_features=220, bias=True)\n",
       "      (9): LeakyReLU(negative_slope=0.01)\n",
       "      (10): Linear(in_features=220, out_features=211, bias=True)\n",
       "      (11): LeakyReLU(negative_slope=0.01)\n",
       "      (12): Linear(in_features=211, out_features=25, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Linear(in_features=25, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [96, 346, 464, 173, 220, 211, 25],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0019817216820373473,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.6767120361328125,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.6673367619514465,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 98: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=149, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=149, out_features=415, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=415, out_features=490, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=490, out_features=133, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=133, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [149, 415, 490, 133],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0015816899945836904,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.6796863675117493,\n",
       "  'train_acc': 0.6119791666666666,\n",
       "  'val_loss': 0.6812875270843506,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 99: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=326, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=326, out_features=506, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=506, out_features=466, bias=True)\n",
       "      (5): ReLU()\n",
       "      (6): Linear(in_features=466, out_features=64, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Linear(in_features=64, out_features=45, bias=True)\n",
       "      (9): ReLU()\n",
       "      (10): Linear(in_features=45, out_features=265, bias=True)\n",
       "      (11): ReLU()\n",
       "      (12): Linear(in_features=265, out_features=270, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Linear(in_features=270, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [326, 506, 466, 64, 45, 265, 270],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0031379490078894227,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.6834843158721924,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.6439609527587891,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 100: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=386, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=386, out_features=465, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=465, out_features=315, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=315, out_features=331, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=331, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [386, 465, 315, 331],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.009138083612102013,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.6760165095329285,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.6731135845184326,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 101: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=137, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=137, out_features=511, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=511, out_features=171, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=171, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [137, 511, 171],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.002255082179746946,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.6931822299957275,\n",
       "  'train_acc': 0.5234375,\n",
       "  'val_loss': 0.6806188225746155,\n",
       "  'val_acc': 0.6666666666666666},\n",
       " 102: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=473, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=473, out_features=242, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=242, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [473, 242],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.005535715749187379,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.6970656514167786,\n",
       "  'train_acc': 0.5026041666666666,\n",
       "  'val_loss': 0.689469575881958,\n",
       "  'val_acc': 0.5416666666666666},\n",
       " 103: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=174, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=174, out_features=507, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=507, out_features=112, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=112, out_features=196, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=196, out_features=158, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.2, inplace=False)\n",
       "      (15): Linear(in_features=158, out_features=489, bias=True)\n",
       "      (16): ReLU()\n",
       "      (17): Dropout(p=0.2, inplace=False)\n",
       "      (18): Linear(in_features=489, out_features=253, bias=True)\n",
       "      (19): ReLU()\n",
       "      (20): Dropout(p=0.2, inplace=False)\n",
       "      (21): Linear(in_features=253, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [174, 507, 112, 196, 158, 489, 253],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.008572995671084282,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.6851621270179749,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.8737916350364685,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 104: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=481, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=481, out_features=27, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=27, out_features=111, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=111, out_features=429, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=429, out_features=416, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=416, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [481, 27, 111, 429, 416],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.002140242948075277,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.6888084411621094,\n",
       "  'train_acc': 0.5729166666666666,\n",
       "  'val_loss': 0.6899916529655457,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 105: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=324, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=324, out_features=205, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=205, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [324, 205],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.004581314237505447,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.6989675164222717,\n",
       "  'train_acc': 0.4765625,\n",
       "  'val_loss': 0.7917437553405762,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 106: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=164, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=164, out_features=147, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=147, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [164, 147],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.00244666780721573,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.6478983759880066,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.622852087020874,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 107: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=414, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=414, out_features=51, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=51, out_features=200, bias=True)\n",
       "      (5): LeakyReLU(negative_slope=0.01)\n",
       "      (6): Linear(in_features=200, out_features=461, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Linear(in_features=461, out_features=468, bias=True)\n",
       "      (9): LeakyReLU(negative_slope=0.01)\n",
       "      (10): Linear(in_features=468, out_features=443, bias=True)\n",
       "      (11): LeakyReLU(negative_slope=0.01)\n",
       "      (12): Linear(in_features=443, out_features=431, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Linear(in_features=431, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [414, 51, 200, 461, 468, 443, 431],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.004950181413136672,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.6907454133033752,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.6363697648048401,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 108: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=100, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=100, out_features=203, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=203, out_features=26, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=26, out_features=275, bias=True)\n",
       "      (10): Sigmoid()\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=275, out_features=406, bias=True)\n",
       "      (13): Sigmoid()\n",
       "      (14): Dropout(p=0.1, inplace=False)\n",
       "      (15): Linear(in_features=406, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [100, 203, 26, 275, 406],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0015178886977677266,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.7320807576179504,\n",
       "  'train_acc': 0.3697916666666667,\n",
       "  'val_loss': 0.7180215716362,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 109: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=176, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=176, out_features=146, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=146, out_features=152, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=152, out_features=218, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=218, out_features=421, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=421, out_features=193, bias=True)\n",
       "      (16): LeakyReLU(negative_slope=0.01)\n",
       "      (17): Dropout(p=0.5, inplace=False)\n",
       "      (18): Linear(in_features=193, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [176, 146, 152, 218, 421, 193],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.002194920119579421,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.6937479972839355,\n",
       "  'train_acc': 0.46875,\n",
       "  'val_loss': 0.6950397491455078,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 110: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=511, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=511, out_features=258, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=258, out_features=120, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=120, out_features=493, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=493, out_features=484, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=484, out_features=157, bias=True)\n",
       "      (16): LeakyReLU(negative_slope=0.01)\n",
       "      (17): Dropout(p=0.5, inplace=False)\n",
       "      (18): Linear(in_features=157, out_features=408, bias=True)\n",
       "      (19): LeakyReLU(negative_slope=0.01)\n",
       "      (20): Dropout(p=0.5, inplace=False)\n",
       "      (21): Linear(in_features=408, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [511, 258, 120, 493, 484, 157, 408],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.008458544125822285,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.6887831687927246,\n",
       "  'train_acc': 0.6171875,\n",
       "  'val_loss': 0.687175452709198,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 111: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=92, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=92, out_features=268, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=268, out_features=333, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=333, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [92, 268, 333],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0020103324529596265,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.6985651850700378,\n",
       "  'train_acc': 0.4401041666666667,\n",
       "  'val_loss': 0.6942432522773743,\n",
       "  'val_acc': 0.46875},\n",
       " 112: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=150, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=150, out_features=28, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=28, out_features=226, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=226, out_features=52, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=52, out_features=80, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.2, inplace=False)\n",
       "      (15): Linear(in_features=80, out_features=213, bias=True)\n",
       "      (16): ReLU()\n",
       "      (17): Dropout(p=0.2, inplace=False)\n",
       "      (18): Linear(in_features=213, out_features=103, bias=True)\n",
       "      (19): ReLU()\n",
       "      (20): Dropout(p=0.2, inplace=False)\n",
       "      (21): Linear(in_features=103, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [150, 28, 226, 52, 80, 213, 103],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.003470025538728146,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.6911461353302002,\n",
       "  'train_acc': 0.5625,\n",
       "  'val_loss': 0.6690108180046082,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 113: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=140, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=140, out_features=386, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=386, out_features=478, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=478, out_features=437, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=437, out_features=424, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.1, inplace=False)\n",
       "      (15): Linear(in_features=424, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [140, 386, 478, 437, 424],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.002582852595830292,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.6962019801139832,\n",
       "  'train_acc': 0.3619791666666667,\n",
       "  'val_loss': 0.6365888118743896,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 114: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=185, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Linear(in_features=185, out_features=121, bias=True)\n",
       "      (3): Sigmoid()\n",
       "      (4): Linear(in_features=121, out_features=363, bias=True)\n",
       "      (5): Sigmoid()\n",
       "      (6): Linear(in_features=363, out_features=245, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Linear(in_features=245, out_features=487, bias=True)\n",
       "      (9): Sigmoid()\n",
       "      (10): Linear(in_features=487, out_features=178, bias=True)\n",
       "      (11): Sigmoid()\n",
       "      (12): Linear(in_features=178, out_features=290, bias=True)\n",
       "      (13): Sigmoid()\n",
       "      (14): Linear(in_features=290, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [185, 121, 363, 245, 487, 178, 290],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0081365828395424,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.6610562801361084,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.6443093419075012,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 115: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=299, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=299, out_features=362, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=362, out_features=24, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=24, out_features=315, bias=True)\n",
       "      (10): Sigmoid()\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=315, out_features=180, bias=True)\n",
       "      (13): Sigmoid()\n",
       "      (14): Dropout(p=0.2, inplace=False)\n",
       "      (15): Linear(in_features=180, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [299, 362, 24, 315, 180],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.007010855640308512,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.6974847912788391,\n",
       "  'train_acc': 0.4895833333333333,\n",
       "  'val_loss': 0.675637423992157,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 116: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=124, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=124, out_features=37, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=37, out_features=64, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=64, out_features=38, bias=True)\n",
       "      (10): Sigmoid()\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=38, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [124, 37, 64, 38],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0031701985108202667,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.7723861336708069,\n",
       "  'train_acc': 0.4036458333333333,\n",
       "  'val_loss': 0.7269122004508972,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 117: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=488, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=488, out_features=388, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=388, out_features=423, bias=True)\n",
       "      (5): ReLU()\n",
       "      (6): Linear(in_features=423, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [488, 388, 423],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.00534178896617853,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.6895200610160828,\n",
       "  'train_acc': 0.5572916666666666,\n",
       "  'val_loss': 0.6877695918083191,\n",
       "  'val_acc': 0.5625},\n",
       " 118: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=450, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=450, out_features=43, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=43, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [450, 43],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.009219399814085542,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.8303773999214172,\n",
       "  'train_acc': 0.3385416666666667,\n",
       "  'val_loss': 0.8192641139030457,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 119: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=59, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=59, out_features=208, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=208, out_features=304, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=304, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [59, 208, 304],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.004223379510251158,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.7252007126808167,\n",
       "  'train_acc': 0.3723958333333333,\n",
       "  'val_loss': 0.6279464960098267,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 120: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=157, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=157, out_features=102, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=102, out_features=202, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=202, out_features=73, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=73, out_features=469, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=469, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [157, 102, 202, 73, 469],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0049381775561678455,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.712608814239502,\n",
       "  'train_acc': 0.3671875,\n",
       "  'val_loss': 0.6580100655555725,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 121: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=361, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=361, out_features=501, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=501, out_features=23, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=23, out_features=456, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=456, out_features=348, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.2, inplace=False)\n",
       "      (15): Linear(in_features=348, out_features=53, bias=True)\n",
       "      (16): LeakyReLU(negative_slope=0.01)\n",
       "      (17): Dropout(p=0.2, inplace=False)\n",
       "      (18): Linear(in_features=53, out_features=160, bias=True)\n",
       "      (19): LeakyReLU(negative_slope=0.01)\n",
       "      (20): Dropout(p=0.2, inplace=False)\n",
       "      (21): Linear(in_features=160, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [361, 501, 23, 456, 348, 53, 160],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.004865869106319608,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.6915569305419922,\n",
       "  'train_acc': 0.5703125,\n",
       "  'val_loss': 0.650452196598053,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 122: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=25, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=25, out_features=100, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=100, out_features=152, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=152, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [25, 100, 152],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.003698522584476034,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.699371337890625,\n",
       "  'train_acc': 0.515625,\n",
       "  'val_loss': 0.636080801486969,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 123: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=150, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=150, out_features=334, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=334, out_features=176, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=176, out_features=28, bias=True)\n",
       "      (10): Sigmoid()\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=28, out_features=274, bias=True)\n",
       "      (13): Sigmoid()\n",
       "      (14): Dropout(p=0.2, inplace=False)\n",
       "      (15): Linear(in_features=274, out_features=70, bias=True)\n",
       "      (16): Sigmoid()\n",
       "      (17): Dropout(p=0.2, inplace=False)\n",
       "      (18): Linear(in_features=70, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [150, 334, 176, 28, 274, 70],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.005527567065349782,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.643983781337738,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.6327056288719177,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 124: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=220, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=220, out_features=169, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=169, out_features=276, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=276, out_features=80, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=80, out_features=381, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.1, inplace=False)\n",
       "      (15): Linear(in_features=381, out_features=442, bias=True)\n",
       "      (16): LeakyReLU(negative_slope=0.01)\n",
       "      (17): Dropout(p=0.1, inplace=False)\n",
       "      (18): Linear(in_features=442, out_features=67, bias=True)\n",
       "      (19): LeakyReLU(negative_slope=0.01)\n",
       "      (20): Dropout(p=0.1, inplace=False)\n",
       "      (21): Linear(in_features=67, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [220, 169, 276, 80, 381, 442, 67],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.00502783895595007,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.685753583908081,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.6844890117645264,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 125: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=482, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=482, out_features=443, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=443, out_features=429, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=429, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [482, 443, 429],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.009640047466306603,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.6871206164360046,\n",
       "  'train_acc': 0.625,\n",
       "  'val_loss': 0.682543933391571,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 126: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=257, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=257, out_features=351, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=351, out_features=347, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=347, out_features=270, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=270, out_features=379, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.2, inplace=False)\n",
       "      (15): Linear(in_features=379, out_features=258, bias=True)\n",
       "      (16): LeakyReLU(negative_slope=0.01)\n",
       "      (17): Dropout(p=0.2, inplace=False)\n",
       "      (18): Linear(in_features=258, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [257, 351, 347, 270, 379, 258],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.004875192733812615,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.6987130045890808,\n",
       "  'train_acc': 0.3385416666666667,\n",
       "  'val_loss': 0.6989485621452332,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 127: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=112, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=112, out_features=364, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=364, out_features=25, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=25, out_features=503, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=503, out_features=502, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.2, inplace=False)\n",
       "      (15): Linear(in_features=502, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [112, 364, 25, 503, 502],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0064032093275886715,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.6980727314949036,\n",
       "  'train_acc': 0.34375,\n",
       "  'val_loss': 0.8374547958374023,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 128: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=69, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=69, out_features=101, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=101, out_features=306, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=306, out_features=396, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=396, out_features=125, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=125, out_features=333, bias=True)\n",
       "      (16): ReLU()\n",
       "      (17): Dropout(p=0.5, inplace=False)\n",
       "      (18): Linear(in_features=333, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [69, 101, 306, 396, 125, 333],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.00998699650056286,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.698416531085968,\n",
       "  'train_acc': 0.4479166666666667,\n",
       "  'val_loss': 0.694023609161377,\n",
       "  'val_acc': 0.34375},\n",
       " 129: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=115, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=115, out_features=135, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=135, out_features=251, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=251, out_features=255, bias=True)\n",
       "      (10): Sigmoid()\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=255, out_features=472, bias=True)\n",
       "      (13): Sigmoid()\n",
       "      (14): Dropout(p=0.2, inplace=False)\n",
       "      (15): Linear(in_features=472, out_features=252, bias=True)\n",
       "      (16): Sigmoid()\n",
       "      (17): Dropout(p=0.2, inplace=False)\n",
       "      (18): Linear(in_features=252, out_features=427, bias=True)\n",
       "      (19): Sigmoid()\n",
       "      (20): Dropout(p=0.2, inplace=False)\n",
       "      (21): Linear(in_features=427, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [115, 135, 251, 255, 472, 252, 427],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.004755949355505956,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.8250308036804199,\n",
       "  'train_acc': 0.34375,\n",
       "  'val_loss': 0.7485992908477783,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 130: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=83, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=83, out_features=178, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=178, out_features=301, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=301, out_features=486, bias=True)\n",
       "      (10): Sigmoid()\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=486, out_features=15, bias=True)\n",
       "      (13): Sigmoid()\n",
       "      (14): Dropout(p=0.1, inplace=False)\n",
       "      (15): Linear(in_features=15, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [83, 178, 301, 486, 15],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.004474698875215325,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.6838420033454895,\n",
       "  'train_acc': 0.5677083333333334,\n",
       "  'val_loss': 0.6780462861061096,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 131: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=277, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=277, out_features=237, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=237, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [277, 237],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.004848607485629371,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.6594840884208679,\n",
       "  'train_acc': 0.5989583333333334,\n",
       "  'val_loss': 0.7438478469848633,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 132: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=90, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=90, out_features=97, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=97, out_features=497, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=497, out_features=189, bias=True)\n",
       "      (10): Sigmoid()\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=189, out_features=323, bias=True)\n",
       "      (13): Sigmoid()\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=323, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [90, 97, 497, 189, 323],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.003345170658129344,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.6763787865638733,\n",
       "  'train_acc': 0.5859375,\n",
       "  'val_loss': 0.6350958347320557,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 133: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=130, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=130, out_features=212, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=212, out_features=240, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=240, out_features=435, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=435, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [130, 212, 240, 435],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.004592864457653567,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.6819450855255127,\n",
       "  'train_acc': 0.6197916666666666,\n",
       "  'val_loss': 0.6861080527305603,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 134: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=150, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=150, out_features=391, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=391, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [150, 391],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.007967740579841115,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.6971846222877502,\n",
       "  'train_acc': 0.5182291666666666,\n",
       "  'val_loss': 0.6564800143241882,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 135: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=450, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=450, out_features=100, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=100, out_features=101, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=101, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [450, 100, 101],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.009564203210662117,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.6693610548973083,\n",
       "  'train_acc': 0.6276041666666666,\n",
       "  'val_loss': 0.6631888747215271,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 136: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=177, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=177, out_features=279, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=279, out_features=21, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=21, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [177, 279, 21],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.00801634237548179,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.7112329602241516,\n",
       "  'train_acc': 0.3541666666666667,\n",
       "  'val_loss': 0.7011691927909851,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 137: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=311, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=311, out_features=400, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=400, out_features=155, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=155, out_features=156, bias=True)\n",
       "      (10): Sigmoid()\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=156, out_features=230, bias=True)\n",
       "      (13): Sigmoid()\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=230, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [311, 400, 155, 156, 230],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.003516388705825657,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.6741805076599121,\n",
       "  'train_acc': 0.6302083333333334,\n",
       "  'val_loss': 0.6323723793029785,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 138: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=503, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Linear(in_features=503, out_features=192, bias=True)\n",
       "      (3): Sigmoid()\n",
       "      (4): Linear(in_features=192, out_features=393, bias=True)\n",
       "      (5): Sigmoid()\n",
       "      (6): Linear(in_features=393, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [503, 192, 393],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.008354777448360856,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.9108911156654358,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.7384303212165833,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 139: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=393, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=393, out_features=282, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=282, out_features=54, bias=True)\n",
       "      (5): LeakyReLU(negative_slope=0.01)\n",
       "      (6): Linear(in_features=54, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [393, 282, 54],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.002742069262788639,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.6988556385040283,\n",
       "  'train_acc': 0.3671875,\n",
       "  'val_loss': 0.6241683959960938,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 140: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=78, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=78, out_features=275, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=275, out_features=257, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=257, out_features=260, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=260, out_features=477, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.1, inplace=False)\n",
       "      (15): Linear(in_features=477, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [78, 275, 257, 260, 477],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.009809740496144099,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.6887515187263489,\n",
       "  'train_acc': 0.6536458333333334,\n",
       "  'val_loss': 0.6887468695640564,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 141: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=62, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=62, out_features=480, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=480, out_features=302, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=302, out_features=175, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=175, out_features=423, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=423, out_features=81, bias=True)\n",
       "      (16): ReLU()\n",
       "      (17): Dropout(p=0.5, inplace=False)\n",
       "      (18): Linear(in_features=81, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [62, 480, 302, 175, 423, 81],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.006175322034070062,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.6913039684295654,\n",
       "  'train_acc': 0.5494791666666666,\n",
       "  'val_loss': 0.6417478919029236,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 142: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=185, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=185, out_features=382, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=382, out_features=436, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=436, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [185, 382, 436],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0021383213602770464,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.6864898204803467,\n",
       "  'train_acc': 0.609375,\n",
       "  'val_loss': 0.625026524066925,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 143: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=115, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=115, out_features=45, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=45, out_features=490, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=490, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [115, 45, 490],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.006035010067383824,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.7014550566673279,\n",
       "  'train_acc': 0.4557291666666667,\n",
       "  'val_loss': 0.6585445404052734,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 144: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=375, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=375, out_features=173, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=173, out_features=264, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=264, out_features=483, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=483, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [375, 173, 264, 483],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.008700942967682174,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.6877471804618835,\n",
       "  'train_acc': 0.6432291666666666,\n",
       "  'val_loss': 0.6862571239471436,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 145: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=132, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=132, out_features=75, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=75, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [132, 75],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.005849702053541121,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.6954626441001892,\n",
       "  'train_acc': 0.5390625,\n",
       "  'val_loss': 0.6920523047447205,\n",
       "  'val_acc': 0.5520833333333334},\n",
       " 146: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=470, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=470, out_features=434, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=434, out_features=275, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=275, out_features=297, bias=True)\n",
       "      (10): Sigmoid()\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=297, out_features=445, bias=True)\n",
       "      (13): Sigmoid()\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=445, out_features=480, bias=True)\n",
       "      (16): Sigmoid()\n",
       "      (17): Dropout(p=0.5, inplace=False)\n",
       "      (18): Linear(in_features=480, out_features=380, bias=True)\n",
       "      (19): Sigmoid()\n",
       "      (20): Dropout(p=0.5, inplace=False)\n",
       "      (21): Linear(in_features=380, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [470, 434, 275, 297, 445, 480, 380],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.00925447458886108,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.6718769669532776,\n",
       "  'train_acc': 0.6484375,\n",
       "  'val_loss': 0.630025327205658,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 147: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=484, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=484, out_features=449, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=449, out_features=260, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=260, out_features=264, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=264, out_features=120, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.1, inplace=False)\n",
       "      (15): Linear(in_features=120, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [484, 449, 260, 264, 120],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.005502166171148087,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.6867634654045105,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.6854574084281921,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 148: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=195, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=195, out_features=438, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=438, out_features=67, bias=True)\n",
       "      (5): ReLU()\n",
       "      (6): Linear(in_features=67, out_features=61, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Linear(in_features=61, out_features=42, bias=True)\n",
       "      (9): ReLU()\n",
       "      (10): Linear(in_features=42, out_features=508, bias=True)\n",
       "      (11): ReLU()\n",
       "      (12): Linear(in_features=508, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [195, 438, 67, 61, 42, 508],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.005737080945180394,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.6869701743125916,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.685196578502655,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 149: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=44, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=44, out_features=337, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=337, out_features=127, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=127, out_features=244, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=244, out_features=292, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.2, inplace=False)\n",
       "      (15): Linear(in_features=292, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [44, 337, 127, 244, 292],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.007218527074993156,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.6926533579826355,\n",
       "  'train_acc': 0.5052083333333334,\n",
       "  'val_loss': 0.6410738825798035,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 150: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=289, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=289, out_features=208, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=208, out_features=225, bias=True)\n",
       "      (5): ReLU()\n",
       "      (6): Linear(in_features=225, out_features=116, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Linear(in_features=116, out_features=473, bias=True)\n",
       "      (9): ReLU()\n",
       "      (10): Linear(in_features=473, out_features=360, bias=True)\n",
       "      (11): ReLU()\n",
       "      (12): Linear(in_features=360, out_features=299, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Linear(in_features=299, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [289, 208, 225, 116, 473, 360, 299],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0033814834345240003,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.6940779089927673,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.6538391709327698,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 151: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=202, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=202, out_features=26, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=26, out_features=480, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=480, out_features=231, bias=True)\n",
       "      (10): Sigmoid()\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=231, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [202, 26, 480, 231],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0015997025112783124,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.7973288893699646,\n",
       "  'train_acc': 0.3359375,\n",
       "  'val_loss': 0.7831705212593079,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 152: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=466, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=466, out_features=412, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=412, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [466, 412],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.005915786813408522,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.6842274069786072,\n",
       "  'train_acc': 0.6041666666666666,\n",
       "  'val_loss': 0.6849842071533203,\n",
       "  'val_acc': 0.5833333333333334},\n",
       " 153: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=254, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=254, out_features=242, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=242, out_features=91, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=91, out_features=402, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=402, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [254, 242, 91, 402],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.007580092836600523,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.6890807151794434,\n",
       "  'train_acc': 0.5364583333333334,\n",
       "  'val_loss': 0.6549519896507263,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 154: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=113, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=113, out_features=304, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=304, out_features=372, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=372, out_features=129, bias=True)\n",
       "      (10): Sigmoid()\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=129, out_features=426, bias=True)\n",
       "      (13): Sigmoid()\n",
       "      (14): Dropout(p=0.1, inplace=False)\n",
       "      (15): Linear(in_features=426, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [113, 304, 372, 129, 426],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0034735551936720434,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.706968367099762,\n",
       "  'train_acc': 0.4375,\n",
       "  'val_loss': 0.6805972456932068,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 155: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=106, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=106, out_features=426, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=426, out_features=270, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=270, out_features=306, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=306, out_features=367, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=367, out_features=445, bias=True)\n",
       "      (16): ReLU()\n",
       "      (17): Dropout(p=0.5, inplace=False)\n",
       "      (18): Linear(in_features=445, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [106, 426, 270, 306, 367, 445],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0027464366983847984,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.6918606758117676,\n",
       "  'train_acc': 0.546875,\n",
       "  'val_loss': 0.6920939087867737,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 156: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=304, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=304, out_features=464, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=464, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [304, 464],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.005232976642203841,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.7114594578742981,\n",
       "  'train_acc': 0.4453125,\n",
       "  'val_loss': 0.7045595645904541,\n",
       "  'val_acc': 0.4895833333333333},\n",
       " 157: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=41, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=41, out_features=389, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=389, out_features=458, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=458, out_features=209, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=209, out_features=209, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=209, out_features=265, bias=True)\n",
       "      (16): LeakyReLU(negative_slope=0.01)\n",
       "      (17): Dropout(p=0.5, inplace=False)\n",
       "      (18): Linear(in_features=265, out_features=466, bias=True)\n",
       "      (19): LeakyReLU(negative_slope=0.01)\n",
       "      (20): Dropout(p=0.5, inplace=False)\n",
       "      (21): Linear(in_features=466, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [41, 389, 458, 209, 209, 265, 466],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0010866755167796224,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.6858100295066833,\n",
       "  'train_acc': 0.6458333333333334,\n",
       "  'val_loss': 0.6755016446113586,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 158: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=337, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=337, out_features=104, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=104, out_features=305, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=305, out_features=225, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=225, out_features=395, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=395, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [337, 104, 305, 225, 395],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.005652656772977239,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.6940138936042786,\n",
       "  'train_acc': 0.5078125,\n",
       "  'val_loss': 0.6366578340530396,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 159: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=255, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=255, out_features=66, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=66, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [255, 66],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.009745581434577207,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.6937641501426697,\n",
       "  'train_acc': 0.4947916666666667,\n",
       "  'val_loss': 0.6952941417694092,\n",
       "  'val_acc': 0.5},\n",
       " 160: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=348, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=348, out_features=52, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=52, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [348, 52],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0083897296924094,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.687077522277832,\n",
       "  'train_acc': 0.5807291666666666,\n",
       "  'val_loss': 0.805091917514801,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 161: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=66, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=66, out_features=436, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=436, out_features=260, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=260, out_features=466, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=466, out_features=477, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.1, inplace=False)\n",
       "      (15): Linear(in_features=477, out_features=382, bias=True)\n",
       "      (16): ReLU()\n",
       "      (17): Dropout(p=0.1, inplace=False)\n",
       "      (18): Linear(in_features=382, out_features=435, bias=True)\n",
       "      (19): ReLU()\n",
       "      (20): Dropout(p=0.1, inplace=False)\n",
       "      (21): Linear(in_features=435, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [66, 436, 260, 466, 477, 382, 435],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.004137719167819543,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.6825992465019226,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.6807005405426025,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 162: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=30, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=30, out_features=139, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=139, out_features=184, bias=True)\n",
       "      (5): LeakyReLU(negative_slope=0.01)\n",
       "      (6): Linear(in_features=184, out_features=353, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Linear(in_features=353, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [30, 139, 184, 353],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.00533400982429362,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.6973531246185303,\n",
       "  'train_acc': 0.3541666666666667,\n",
       "  'val_loss': 0.6957635879516602,\n",
       "  'val_acc': 0.375},\n",
       " 163: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=171, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=171, out_features=36, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=36, out_features=95, bias=True)\n",
       "      (5): LeakyReLU(negative_slope=0.01)\n",
       "      (6): Linear(in_features=95, out_features=406, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Linear(in_features=406, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [171, 36, 95, 406],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.006311816238965348,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.6837100386619568,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.6816174983978271,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 164: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=231, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=231, out_features=92, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=92, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [231, 92],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.004356889511750955,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.7136106491088867,\n",
       "  'train_acc': 0.4505208333333333,\n",
       "  'val_loss': 0.6318180561065674,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 165: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=269, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=269, out_features=62, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=62, out_features=228, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=228, out_features=144, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=144, out_features=311, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.1, inplace=False)\n",
       "      (15): Linear(in_features=311, out_features=91, bias=True)\n",
       "      (16): LeakyReLU(negative_slope=0.01)\n",
       "      (17): Dropout(p=0.1, inplace=False)\n",
       "      (18): Linear(in_features=91, out_features=419, bias=True)\n",
       "      (19): LeakyReLU(negative_slope=0.01)\n",
       "      (20): Dropout(p=0.1, inplace=False)\n",
       "      (21): Linear(in_features=419, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [269, 62, 228, 144, 311, 91, 419],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.009426628615022262,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.6872318387031555,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.6859651207923889,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 166: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=324, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=324, out_features=43, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=43, out_features=104, bias=True)\n",
       "      (5): LeakyReLU(negative_slope=0.01)\n",
       "      (6): Linear(in_features=104, out_features=437, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Linear(in_features=437, out_features=37, bias=True)\n",
       "      (9): LeakyReLU(negative_slope=0.01)\n",
       "      (10): Linear(in_features=37, out_features=506, bias=True)\n",
       "      (11): LeakyReLU(negative_slope=0.01)\n",
       "      (12): Linear(in_features=506, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [324, 43, 104, 437, 37, 506],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.006829079838964216,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.6875471472740173,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.6857566833496094,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 167: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=202, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=202, out_features=234, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=234, out_features=17, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=17, out_features=118, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=118, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [202, 234, 17, 118],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.005727592868450631,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.7529765963554382,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.6990411877632141,\n",
       "  'val_acc': 0.3333333333333333},\n",
       " 168: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=232, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=232, out_features=458, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=458, out_features=467, bias=True)\n",
       "      (5): ReLU()\n",
       "      (6): Linear(in_features=467, out_features=500, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Linear(in_features=500, out_features=67, bias=True)\n",
       "      (9): ReLU()\n",
       "      (10): Linear(in_features=67, out_features=410, bias=True)\n",
       "      (11): ReLU()\n",
       "      (12): Linear(in_features=410, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [232, 458, 467, 500, 67, 410],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.005782586892565506,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.701801598072052,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.6497048735618591,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 169: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=486, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=486, out_features=434, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=434, out_features=382, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=382, out_features=452, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=452, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [486, 434, 382, 452],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.008327538236407559,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.6798765063285828,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.6780838370323181,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 170: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=232, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=232, out_features=216, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=216, out_features=423, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=423, out_features=147, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=147, out_features=348, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=348, out_features=283, bias=True)\n",
       "      (16): ReLU()\n",
       "      (17): Dropout(p=0.5, inplace=False)\n",
       "      (18): Linear(in_features=283, out_features=164, bias=True)\n",
       "      (19): ReLU()\n",
       "      (20): Dropout(p=0.5, inplace=False)\n",
       "      (21): Linear(in_features=164, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [232, 216, 423, 147, 348, 283, 164],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.006583765486564885,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.7103597521781921,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.7118873000144958,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 171: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=177, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=177, out_features=339, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=339, out_features=69, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=69, out_features=392, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=392, out_features=424, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.2, inplace=False)\n",
       "      (15): Linear(in_features=424, out_features=348, bias=True)\n",
       "      (16): LeakyReLU(negative_slope=0.01)\n",
       "      (17): Dropout(p=0.2, inplace=False)\n",
       "      (18): Linear(in_features=348, out_features=142, bias=True)\n",
       "      (19): LeakyReLU(negative_slope=0.01)\n",
       "      (20): Dropout(p=0.2, inplace=False)\n",
       "      (21): Linear(in_features=142, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [177, 339, 69, 392, 424, 348, 142],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.00936470181736939,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.6927892565727234,\n",
       "  'train_acc': 0.5364583333333334,\n",
       "  'val_loss': 0.6921112537384033,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 172: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=455, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=455, out_features=503, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=503, out_features=153, bias=True)\n",
       "      (5): ReLU()\n",
       "      (6): Linear(in_features=153, out_features=93, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Linear(in_features=93, out_features=466, bias=True)\n",
       "      (9): ReLU()\n",
       "      (10): Linear(in_features=466, out_features=293, bias=True)\n",
       "      (11): ReLU()\n",
       "      (12): Linear(in_features=293, out_features=363, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Linear(in_features=363, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [455, 503, 153, 93, 466, 293, 363],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.002600582557626368,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.6930456757545471,\n",
       "  'train_acc': 0.5677083333333334,\n",
       "  'val_loss': 0.6594322323799133,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 173: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=405, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=405, out_features=234, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=234, out_features=156, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=156, out_features=251, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=251, out_features=282, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.2, inplace=False)\n",
       "      (15): Linear(in_features=282, out_features=332, bias=True)\n",
       "      (16): ReLU()\n",
       "      (17): Dropout(p=0.2, inplace=False)\n",
       "      (18): Linear(in_features=332, out_features=317, bias=True)\n",
       "      (19): ReLU()\n",
       "      (20): Dropout(p=0.2, inplace=False)\n",
       "      (21): Linear(in_features=317, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [405, 234, 156, 251, 282, 332, 317],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.006053482853893482,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.6894369721412659,\n",
       "  'train_acc': 0.6458333333333334,\n",
       "  'val_loss': 0.6887014508247375,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 174: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=221, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=221, out_features=358, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=358, out_features=497, bias=True)\n",
       "      (5): LeakyReLU(negative_slope=0.01)\n",
       "      (6): Linear(in_features=497, out_features=329, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Linear(in_features=329, out_features=278, bias=True)\n",
       "      (9): LeakyReLU(negative_slope=0.01)\n",
       "      (10): Linear(in_features=278, out_features=362, bias=True)\n",
       "      (11): LeakyReLU(negative_slope=0.01)\n",
       "      (12): Linear(in_features=362, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [221, 358, 497, 329, 278, 362],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.009903683147676569,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.6884699463844299,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.6871157288551331,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 175: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=323, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=323, out_features=38, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=38, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [323, 38],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.008364213489286534,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.684476375579834,\n",
       "  'train_acc': 0.5651041666666666,\n",
       "  'val_loss': 0.6834962368011475,\n",
       "  'val_acc': 0.4791666666666667},\n",
       " 176: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=298, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=298, out_features=273, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=273, out_features=50, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=50, out_features=118, bias=True)\n",
       "      (10): Sigmoid()\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=118, out_features=167, bias=True)\n",
       "      (13): Sigmoid()\n",
       "      (14): Dropout(p=0.1, inplace=False)\n",
       "      (15): Linear(in_features=167, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [298, 273, 50, 118, 167],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.004297170406686262,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.6737980842590332,\n",
       "  'train_acc': 0.6119791666666666,\n",
       "  'val_loss': 0.682811439037323,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 177: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=266, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=266, out_features=333, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=333, out_features=349, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=349, out_features=479, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=479, out_features=404, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.1, inplace=False)\n",
       "      (15): Linear(in_features=404, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [266, 333, 349, 479, 404],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.003416539317019513,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.7060319781303406,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.6240056753158569,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 178: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=23, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=23, out_features=157, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=157, out_features=72, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=72, out_features=103, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=103, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [23, 157, 72, 103],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.009213655412420453,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.7118911147117615,\n",
       "  'train_acc': 0.3854166666666667,\n",
       "  'val_loss': 0.6651029586791992,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 179: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=279, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=279, out_features=113, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=113, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [279, 113],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.007462108446880072,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.7667967677116394,\n",
       "  'train_acc': 0.3671875,\n",
       "  'val_loss': 0.7420695424079895,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 180: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=388, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Linear(in_features=388, out_features=210, bias=True)\n",
       "      (3): Sigmoid()\n",
       "      (4): Linear(in_features=210, out_features=177, bias=True)\n",
       "      (5): Sigmoid()\n",
       "      (6): Linear(in_features=177, out_features=177, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Linear(in_features=177, out_features=435, bias=True)\n",
       "      (9): Sigmoid()\n",
       "      (10): Linear(in_features=435, out_features=279, bias=True)\n",
       "      (11): Sigmoid()\n",
       "      (12): Linear(in_features=279, out_features=380, bias=True)\n",
       "      (13): Sigmoid()\n",
       "      (14): Linear(in_features=380, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [388, 210, 177, 177, 435, 279, 380],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.002499470955809811,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.7245734333992004,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.7981827855110168,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 181: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=423, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=423, out_features=15, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=15, out_features=41, bias=True)\n",
       "      (5): LeakyReLU(negative_slope=0.01)\n",
       "      (6): Linear(in_features=41, out_features=20, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Linear(in_features=20, out_features=151, bias=True)\n",
       "      (9): LeakyReLU(negative_slope=0.01)\n",
       "      (10): Linear(in_features=151, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [423, 15, 41, 20, 151],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.002169823026481342,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.6882221698760986,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.6760819554328918,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 182: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=306, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Linear(in_features=306, out_features=48, bias=True)\n",
       "      (3): Sigmoid()\n",
       "      (4): Linear(in_features=48, out_features=77, bias=True)\n",
       "      (5): Sigmoid()\n",
       "      (6): Linear(in_features=77, out_features=490, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Linear(in_features=490, out_features=100, bias=True)\n",
       "      (9): Sigmoid()\n",
       "      (10): Linear(in_features=100, out_features=434, bias=True)\n",
       "      (11): Sigmoid()\n",
       "      (12): Linear(in_features=434, out_features=84, bias=True)\n",
       "      (13): Sigmoid()\n",
       "      (14): Linear(in_features=84, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [306, 48, 77, 490, 100, 434, 84],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.007522215859340214,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.7491126656532288,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.8762012124061584,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 183: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=131, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=131, out_features=291, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=291, out_features=187, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=187, out_features=508, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=508, out_features=295, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.1, inplace=False)\n",
       "      (15): Linear(in_features=295, out_features=280, bias=True)\n",
       "      (16): LeakyReLU(negative_slope=0.01)\n",
       "      (17): Dropout(p=0.1, inplace=False)\n",
       "      (18): Linear(in_features=280, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [131, 291, 187, 508, 295, 280],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.008790919171337872,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.6831154227256775,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.6810466647148132,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 184: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=391, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=391, out_features=122, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=122, out_features=254, bias=True)\n",
       "      (5): ReLU()\n",
       "      (6): Linear(in_features=254, out_features=18, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Linear(in_features=18, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [391, 122, 254, 18],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.008755308149402452,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.6820668578147888,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.6798873543739319,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 185: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=134, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Linear(in_features=134, out_features=138, bias=True)\n",
       "      (3): Sigmoid()\n",
       "      (4): Linear(in_features=138, out_features=56, bias=True)\n",
       "      (5): Sigmoid()\n",
       "      (6): Linear(in_features=56, out_features=145, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Linear(in_features=145, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [134, 138, 56, 145],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0025843195301503757,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.6695457100868225,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.629075825214386,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 186: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=350, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=350, out_features=64, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=64, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [350, 64],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0018522433696193364,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.7001521587371826,\n",
       "  'train_acc': 0.5,\n",
       "  'val_loss': 0.6420314908027649,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 187: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=292, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=292, out_features=258, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=258, out_features=164, bias=True)\n",
       "      (5): ReLU()\n",
       "      (6): Linear(in_features=164, out_features=338, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Linear(in_features=338, out_features=138, bias=True)\n",
       "      (9): ReLU()\n",
       "      (10): Linear(in_features=138, out_features=174, bias=True)\n",
       "      (11): ReLU()\n",
       "      (12): Linear(in_features=174, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [292, 258, 164, 338, 138, 174],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.001790795036997497,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.6967645287513733,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.6796525120735168,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 188: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=439, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=439, out_features=474, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=474, out_features=510, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=510, out_features=13, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=13, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [439, 474, 510, 13],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0020065266697512946,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.7452369332313538,\n",
       "  'train_acc': 0.3385416666666667,\n",
       "  'val_loss': 0.7508414387702942,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 189: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=68, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=68, out_features=364, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=364, out_features=387, bias=True)\n",
       "      (5): ReLU()\n",
       "      (6): Linear(in_features=387, out_features=295, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Linear(in_features=295, out_features=366, bias=True)\n",
       "      (9): ReLU()\n",
       "      (10): Linear(in_features=366, out_features=66, bias=True)\n",
       "      (11): ReLU()\n",
       "      (12): Linear(in_features=66, out_features=268, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Linear(in_features=268, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [68, 364, 387, 295, 366, 66, 268],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.004103019425613885,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.6928578019142151,\n",
       "  'train_acc': 0.640625,\n",
       "  'val_loss': 0.6492441296577454,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 190: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=40, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=40, out_features=90, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=90, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [40, 90],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.00837865852027809,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.6624296307563782,\n",
       "  'train_acc': 0.65625,\n",
       "  'val_loss': 0.6248899102210999,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 191: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=201, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=201, out_features=448, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=448, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [201, 448],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0035093611901973326,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.6802157759666443,\n",
       "  'train_acc': 0.6067708333333334,\n",
       "  'val_loss': 0.6628136038780212,\n",
       "  'val_acc': 0.625},\n",
       " 192: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=420, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=420, out_features=452, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=452, out_features=194, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=194, out_features=97, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=97, out_features=454, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.1, inplace=False)\n",
       "      (15): Linear(in_features=454, out_features=232, bias=True)\n",
       "      (16): LeakyReLU(negative_slope=0.01)\n",
       "      (17): Dropout(p=0.1, inplace=False)\n",
       "      (18): Linear(in_features=232, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [420, 452, 194, 97, 454, 232],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0059202668921401105,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.7059158682823181,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.698863685131073,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 193: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=298, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=298, out_features=187, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=187, out_features=366, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=366, out_features=465, bias=True)\n",
       "      (10): Sigmoid()\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=465, out_features=479, bias=True)\n",
       "      (13): Sigmoid()\n",
       "      (14): Dropout(p=0.1, inplace=False)\n",
       "      (15): Linear(in_features=479, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [298, 187, 366, 465, 479],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0013529901265083623,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.6584611535072327,\n",
       "  'train_acc': 0.6536458333333334,\n",
       "  'val_loss': 0.8509246706962585,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 194: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=138, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=138, out_features=490, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=490, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [138, 490],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0070978197437777555,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.6761326193809509,\n",
       "  'train_acc': 0.6119791666666666,\n",
       "  'val_loss': 0.8717315196990967,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 195: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=315, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=315, out_features=272, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=272, out_features=388, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=388, out_features=250, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=250, out_features=322, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.1, inplace=False)\n",
       "      (15): Linear(in_features=322, out_features=293, bias=True)\n",
       "      (16): LeakyReLU(negative_slope=0.01)\n",
       "      (17): Dropout(p=0.1, inplace=False)\n",
       "      (18): Linear(in_features=293, out_features=31, bias=True)\n",
       "      (19): LeakyReLU(negative_slope=0.01)\n",
       "      (20): Dropout(p=0.1, inplace=False)\n",
       "      (21): Linear(in_features=31, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [315, 272, 388, 250, 322, 293, 31],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.001678531562750195,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.6678154468536377,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.6640636324882507,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 196: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=20, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=20, out_features=378, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=378, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [20, 378],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.006981347236662518,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.699029266834259,\n",
       "  'train_acc': 0.4713541666666667,\n",
       "  'val_loss': 0.6360702514648438,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 197: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=351, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=351, out_features=317, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=317, out_features=432, bias=True)\n",
       "      (5): LeakyReLU(negative_slope=0.01)\n",
       "      (6): Linear(in_features=432, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [351, 317, 432],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.004682551296871652,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.6857894062995911,\n",
       "  'train_acc': 0.6666666666666666,\n",
       "  'val_loss': 0.8971543908119202,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 198: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=419, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=419, out_features=71, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=71, out_features=13, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=13, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [419, 71, 13],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0013245357127878445,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.6795775294303894,\n",
       "  'train_acc': 0.6015625,\n",
       "  'val_loss': 0.6658595204353333,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 199: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=230, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=230, out_features=404, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=404, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [230, 404],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0037452359637586783,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.6684151291847229,\n",
       "  'train_acc': 0.6328125,\n",
       "  'val_loss': 0.6505776047706604,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 200: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=144, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=144, out_features=23, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=23, out_features=470, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=470, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [144, 23, 470],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0019110297775601975,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.7018820643424988,\n",
       "  'train_acc': 0.3697916666666667,\n",
       "  'val_loss': 0.7021593451499939,\n",
       "  'val_acc': 0.3333333333333333},\n",
       " 201: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=125, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=125, out_features=225, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=225, out_features=232, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=232, out_features=187, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=187, out_features=283, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=283, out_features=160, bias=True)\n",
       "      (16): LeakyReLU(negative_slope=0.01)\n",
       "      (17): Dropout(p=0.5, inplace=False)\n",
       "      (18): Linear(in_features=160, out_features=207, bias=True)\n",
       "      (19): LeakyReLU(negative_slope=0.01)\n",
       "      (20): Dropout(p=0.5, inplace=False)\n",
       "      (21): Linear(in_features=207, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [125, 225, 232, 187, 283, 160, 207],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.005623809378730665,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.6915929317474365,\n",
       "  'train_acc': 0.5182291666666666,\n",
       "  'val_loss': 0.6918160319328308,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 202: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=499, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=499, out_features=216, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=216, out_features=172, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=172, out_features=73, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=73, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [499, 216, 172, 73],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.005418628937166823,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.728327751159668,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.7316307425498962,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 203: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=467, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=467, out_features=471, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=471, out_features=305, bias=True)\n",
       "      (5): ReLU()\n",
       "      (6): Linear(in_features=305, out_features=459, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Linear(in_features=459, out_features=336, bias=True)\n",
       "      (9): ReLU()\n",
       "      (10): Linear(in_features=336, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [467, 471, 305, 459, 336],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.003510753352048386,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.6879674792289734,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.6871281266212463,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 204: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=109, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=109, out_features=251, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=251, out_features=69, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=69, out_features=58, bias=True)\n",
       "      (10): Sigmoid()\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=58, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [109, 251, 69, 58],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.008397169957204015,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.979408323764801,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.6919684410095215,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 205: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=33, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=33, out_features=431, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=431, out_features=67, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=67, out_features=230, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=230, out_features=255, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=255, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [33, 431, 67, 230, 255],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0096133480018631,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.7049381732940674,\n",
       "  'train_acc': 0.3776041666666667,\n",
       "  'val_loss': 0.6358192563056946,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 206: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=366, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=366, out_features=199, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=199, out_features=53, bias=True)\n",
       "      (5): LeakyReLU(negative_slope=0.01)\n",
       "      (6): Linear(in_features=53, out_features=188, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Linear(in_features=188, out_features=360, bias=True)\n",
       "      (9): LeakyReLU(negative_slope=0.01)\n",
       "      (10): Linear(in_features=360, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [366, 199, 53, 188, 360],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0021228093053409156,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.6946529746055603,\n",
       "  'train_acc': 0.3541666666666667,\n",
       "  'val_loss': 0.6588897109031677,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 207: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=361, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=361, out_features=18, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=18, out_features=369, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=369, out_features=508, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=508, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [361, 18, 369, 508],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.002274222576267314,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.6925859451293945,\n",
       "  'train_acc': 0.5338541666666666,\n",
       "  'val_loss': 0.6323043704032898,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 208: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=154, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Linear(in_features=154, out_features=370, bias=True)\n",
       "      (3): Sigmoid()\n",
       "      (4): Linear(in_features=370, out_features=308, bias=True)\n",
       "      (5): Sigmoid()\n",
       "      (6): Linear(in_features=308, out_features=227, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Linear(in_features=227, out_features=179, bias=True)\n",
       "      (9): Sigmoid()\n",
       "      (10): Linear(in_features=179, out_features=417, bias=True)\n",
       "      (11): Sigmoid()\n",
       "      (12): Linear(in_features=417, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [154, 370, 308, 227, 179, 417],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.002940467560571175,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.7467789649963379,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.7566431164741516,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 209: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=112, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=112, out_features=262, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=262, out_features=170, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=170, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [112, 262, 170],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.00718837201653004,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.6862549185752869,\n",
       "  'train_acc': 0.5911458333333334,\n",
       "  'val_loss': 0.684912383556366,\n",
       "  'val_acc': 0.6354166666666666},\n",
       " 210: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=162, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=162, out_features=475, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=475, out_features=352, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=352, out_features=351, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=351, out_features=45, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=45, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [162, 475, 352, 351, 45],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.004306478885241464,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.6827850341796875,\n",
       "  'train_acc': 0.6302083333333334,\n",
       "  'val_loss': 0.6828286051750183,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 211: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=152, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=152, out_features=57, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=57, out_features=232, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=232, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [152, 57, 232],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.009870931190456903,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.7037103772163391,\n",
       "  'train_acc': 0.3489583333333333,\n",
       "  'val_loss': 0.6494287848472595,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 212: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=262, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=262, out_features=244, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=244, out_features=441, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=441, out_features=231, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=231, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [262, 244, 441, 231],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.003236396571328092,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.6989443898200989,\n",
       "  'train_acc': 0.3671875,\n",
       "  'val_loss': 0.625090479850769,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 213: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=96, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=96, out_features=429, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=429, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [96, 429],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.003962586681165397,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.6999943852424622,\n",
       "  'train_acc': 0.4088541666666667,\n",
       "  'val_loss': 0.6954278945922852,\n",
       "  'val_acc': 0.5},\n",
       " 214: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=420, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=420, out_features=102, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=102, out_features=327, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=327, out_features=81, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=81, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [420, 102, 327, 81],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0074304838096299905,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.6973794102668762,\n",
       "  'train_acc': 0.3854166666666667,\n",
       "  'val_loss': 0.7248682975769043,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 215: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=91, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=91, out_features=489, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=489, out_features=165, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=165, out_features=397, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=397, out_features=413, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.1, inplace=False)\n",
       "      (15): Linear(in_features=413, out_features=327, bias=True)\n",
       "      (16): LeakyReLU(negative_slope=0.01)\n",
       "      (17): Dropout(p=0.1, inplace=False)\n",
       "      (18): Linear(in_features=327, out_features=61, bias=True)\n",
       "      (19): LeakyReLU(negative_slope=0.01)\n",
       "      (20): Dropout(p=0.1, inplace=False)\n",
       "      (21): Linear(in_features=61, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [91, 489, 165, 397, 413, 327, 61],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.006485183810555589,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.6870841383934021,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.6859301924705505,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 216: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=312, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=312, out_features=397, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=397, out_features=73, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=73, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [312, 397, 73],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0036819568381992584,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.690978467464447,\n",
       "  'train_acc': 0.5052083333333334,\n",
       "  'val_loss': 0.6270918846130371,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 217: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=363, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=363, out_features=283, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=283, out_features=293, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=293, out_features=210, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=210, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [363, 283, 293, 210],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.004509110064138696,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.689359724521637,\n",
       "  'train_acc': 0.5364583333333334,\n",
       "  'val_loss': 0.6266602873802185,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 218: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=274, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=274, out_features=108, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=108, out_features=92, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=92, out_features=357, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=357, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [274, 108, 92, 357],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.00791599634966084,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.6993775963783264,\n",
       "  'train_acc': 0.3619791666666667,\n",
       "  'val_loss': 0.6679487228393555,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 219: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=295, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Linear(in_features=295, out_features=192, bias=True)\n",
       "      (3): Sigmoid()\n",
       "      (4): Linear(in_features=192, out_features=333, bias=True)\n",
       "      (5): Sigmoid()\n",
       "      (6): Linear(in_features=333, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [295, 192, 333],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.004096355119908255,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.7402899265289307,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.7105453610420227,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 220: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=357, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=357, out_features=107, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=107, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [357, 107],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.005459177932281974,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.6801609992980957,\n",
       "  'train_acc': 0.5651041666666666,\n",
       "  'val_loss': 0.7107441425323486,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 221: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=27, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=27, out_features=325, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=325, out_features=445, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=445, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [27, 325, 445],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.00330820895721484,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.6765458583831787,\n",
       "  'train_acc': 0.5677083333333334,\n",
       "  'val_loss': 0.68873530626297,\n",
       "  'val_acc': 0.59375},\n",
       " 222: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=33, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=33, out_features=211, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=211, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [33, 211],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.003391212044940573,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.7416942119598389,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.7420204281806946,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 223: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=107, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=107, out_features=29, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=29, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [107, 29],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.007297341972553584,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.7189445495605469,\n",
       "  'train_acc': 0.4791666666666667,\n",
       "  'val_loss': 0.6404532194137573,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 224: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=377, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=377, out_features=390, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=390, out_features=509, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=509, out_features=484, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=484, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [377, 390, 509, 484],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0037681378281598727,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.6864438056945801,\n",
       "  'train_acc': 0.6302083333333334,\n",
       "  'val_loss': 0.6854079365730286,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 225: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=171, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=171, out_features=330, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=330, out_features=112, bias=True)\n",
       "      (5): LeakyReLU(negative_slope=0.01)\n",
       "      (6): Linear(in_features=112, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [171, 330, 112],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.005847281704400934,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.6940906643867493,\n",
       "  'train_acc': 0.5026041666666666,\n",
       "  'val_loss': 0.6916389465332031,\n",
       "  'val_acc': 0.46875},\n",
       " 226: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=36, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=36, out_features=115, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=115, out_features=418, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=418, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [36, 115, 418],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0029474790095742366,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.6891107559204102,\n",
       "  'train_acc': 0.5729166666666666,\n",
       "  'val_loss': 0.7729976177215576,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 227: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=307, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=307, out_features=398, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=398, out_features=326, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=326, out_features=238, bias=True)\n",
       "      (10): Sigmoid()\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=238, out_features=116, bias=True)\n",
       "      (13): Sigmoid()\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=116, out_features=83, bias=True)\n",
       "      (16): Sigmoid()\n",
       "      (17): Dropout(p=0.5, inplace=False)\n",
       "      (18): Linear(in_features=83, out_features=446, bias=True)\n",
       "      (19): Sigmoid()\n",
       "      (20): Dropout(p=0.5, inplace=False)\n",
       "      (21): Linear(in_features=446, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [307, 398, 326, 238, 116, 83, 446],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.006165508617446127,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.6736790537834167,\n",
       "  'train_acc': 0.578125,\n",
       "  'val_loss': 0.6396574974060059,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 228: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=208, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Linear(in_features=208, out_features=197, bias=True)\n",
       "      (3): Sigmoid()\n",
       "      (4): Linear(in_features=197, out_features=234, bias=True)\n",
       "      (5): Sigmoid()\n",
       "      (6): Linear(in_features=234, out_features=139, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Linear(in_features=139, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [208, 197, 234, 139],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.006306762504128246,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.7811668515205383,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.7911109924316406,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 229: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=422, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Linear(in_features=422, out_features=223, bias=True)\n",
       "      (3): Sigmoid()\n",
       "      (4): Linear(in_features=223, out_features=384, bias=True)\n",
       "      (5): Sigmoid()\n",
       "      (6): Linear(in_features=384, out_features=190, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Linear(in_features=190, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [422, 223, 384, 190],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0021672849598480468,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.8916944861412048,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.8785853385925293,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 230: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=17, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=17, out_features=344, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=344, out_features=182, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=182, out_features=291, bias=True)\n",
       "      (10): Sigmoid()\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=291, out_features=509, bias=True)\n",
       "      (13): Sigmoid()\n",
       "      (14): Dropout(p=0.2, inplace=False)\n",
       "      (15): Linear(in_features=509, out_features=81, bias=True)\n",
       "      (16): Sigmoid()\n",
       "      (17): Dropout(p=0.2, inplace=False)\n",
       "      (18): Linear(in_features=81, out_features=65, bias=True)\n",
       "      (19): Sigmoid()\n",
       "      (20): Dropout(p=0.2, inplace=False)\n",
       "      (21): Linear(in_features=65, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [17, 344, 182, 291, 509, 81, 65],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.009628073350010532,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.7136287093162537,\n",
       "  'train_acc': 0.46875,\n",
       "  'val_loss': 0.6950728297233582,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 231: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=240, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=240, out_features=350, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=350, out_features=448, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=448, out_features=191, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=191, out_features=354, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=354, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [240, 350, 448, 191, 354],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0028272285847323114,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.6870575547218323,\n",
       "  'train_acc': 0.5755208333333334,\n",
       "  'val_loss': 0.6441807746887207,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 232: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=229, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=229, out_features=391, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=391, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [229, 391],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.007907827434759263,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.7195011973381042,\n",
       "  'train_acc': 0.3776041666666667,\n",
       "  'val_loss': 0.7113139629364014,\n",
       "  'val_acc': 0.4583333333333333},\n",
       " 233: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=186, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=186, out_features=71, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=71, out_features=143, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=143, out_features=248, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=248, out_features=364, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.1, inplace=False)\n",
       "      (15): Linear(in_features=364, out_features=439, bias=True)\n",
       "      (16): LeakyReLU(negative_slope=0.01)\n",
       "      (17): Dropout(p=0.1, inplace=False)\n",
       "      (18): Linear(in_features=439, out_features=175, bias=True)\n",
       "      (19): LeakyReLU(negative_slope=0.01)\n",
       "      (20): Dropout(p=0.1, inplace=False)\n",
       "      (21): Linear(in_features=175, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [186, 71, 143, 248, 364, 439, 175],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.007165600283328481,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.6993956565856934,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.6996117234230042,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 234: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=107, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=107, out_features=316, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=316, out_features=127, bias=True)\n",
       "      (5): LeakyReLU(negative_slope=0.01)\n",
       "      (6): Linear(in_features=127, out_features=212, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Linear(in_features=212, out_features=463, bias=True)\n",
       "      (9): LeakyReLU(negative_slope=0.01)\n",
       "      (10): Linear(in_features=463, out_features=46, bias=True)\n",
       "      (11): LeakyReLU(negative_slope=0.01)\n",
       "      (12): Linear(in_features=46, out_features=413, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Linear(in_features=413, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [107, 316, 127, 212, 463, 46, 413],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.006350650806980816,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.6928285956382751,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.6918993592262268,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 235: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=106, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=106, out_features=118, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=118, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [106, 118],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.004566596490193201,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.6770055294036865,\n",
       "  'train_acc': 0.6458333333333334,\n",
       "  'val_loss': 0.6770800948143005,\n",
       "  'val_acc': 0.65625},\n",
       " 236: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=426, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=426, out_features=494, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=494, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [426, 494],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0029169346521074006,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.707269012928009,\n",
       "  'train_acc': 0.5,\n",
       "  'val_loss': 0.8489961624145508,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 237: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=473, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=473, out_features=27, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=27, out_features=297, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=297, out_features=37, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=37, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [473, 27, 297, 37],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.00919754686892224,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.6988043189048767,\n",
       "  'train_acc': 0.4973958333333333,\n",
       "  'val_loss': 0.7037973999977112,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 238: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=217, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=217, out_features=149, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=149, out_features=380, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=380, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [217, 149, 380],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.004437459888071517,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.7024090886116028,\n",
       "  'train_acc': 0.3854166666666667,\n",
       "  'val_loss': 0.639289379119873,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 239: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=356, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=356, out_features=500, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=500, out_features=427, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=427, out_features=343, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=343, out_features=472, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.1, inplace=False)\n",
       "      (15): Linear(in_features=472, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [356, 500, 427, 343, 472],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0031526780389777346,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.6971113681793213,\n",
       "  'train_acc': 0.3515625,\n",
       "  'val_loss': 0.696314811706543,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 240: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=129, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=129, out_features=326, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=326, out_features=475, bias=True)\n",
       "      (5): ReLU()\n",
       "      (6): Linear(in_features=475, out_features=24, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Linear(in_features=24, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [129, 326, 475, 24],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.009042710836945557,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.7129262089729309,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.713585376739502,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 241: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=64, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=64, out_features=298, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=298, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [64, 298],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0050558498615462496,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.6899588108062744,\n",
       "  'train_acc': 0.515625,\n",
       "  'val_loss': 0.6203894019126892,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 242: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=149, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=149, out_features=354, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=354, out_features=212, bias=True)\n",
       "      (5): ReLU()\n",
       "      (6): Linear(in_features=212, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [149, 354, 212],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.001748284768708913,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.7225246429443359,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.7222025394439697,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 243: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=25, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=25, out_features=266, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=266, out_features=129, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=129, out_features=475, bias=True)\n",
       "      (10): Sigmoid()\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=475, out_features=224, bias=True)\n",
       "      (13): Sigmoid()\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=224, out_features=155, bias=True)\n",
       "      (16): Sigmoid()\n",
       "      (17): Dropout(p=0.5, inplace=False)\n",
       "      (18): Linear(in_features=155, out_features=62, bias=True)\n",
       "      (19): Sigmoid()\n",
       "      (20): Dropout(p=0.5, inplace=False)\n",
       "      (21): Linear(in_features=62, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [25, 266, 129, 475, 224, 155, 62],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.009102408628216901,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.6953964829444885,\n",
       "  'train_acc': 0.5520833333333334,\n",
       "  'val_loss': 0.7128989100456238,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 244: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=372, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=372, out_features=82, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=82, out_features=232, bias=True)\n",
       "      (5): LeakyReLU(negative_slope=0.01)\n",
       "      (6): Linear(in_features=232, out_features=340, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Linear(in_features=340, out_features=335, bias=True)\n",
       "      (9): LeakyReLU(negative_slope=0.01)\n",
       "      (10): Linear(in_features=335, out_features=373, bias=True)\n",
       "      (11): LeakyReLU(negative_slope=0.01)\n",
       "      (12): Linear(in_features=373, out_features=385, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Linear(in_features=385, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [372, 82, 232, 340, 335, 373, 385],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.008396514361085766,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.7076000571250916,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.7083337306976318,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 245: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=494, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=494, out_features=470, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=470, out_features=29, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=29, out_features=446, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=446, out_features=480, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.1, inplace=False)\n",
       "      (15): Linear(in_features=480, out_features=415, bias=True)\n",
       "      (16): ReLU()\n",
       "      (17): Dropout(p=0.1, inplace=False)\n",
       "      (18): Linear(in_features=415, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [494, 470, 29, 446, 480, 415],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.007067695616036953,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.7013737559318542,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.7010908126831055,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 246: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=251, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=251, out_features=289, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=289, out_features=95, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=95, out_features=256, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=256, out_features=284, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.2, inplace=False)\n",
       "      (15): Linear(in_features=284, out_features=471, bias=True)\n",
       "      (16): ReLU()\n",
       "      (17): Dropout(p=0.2, inplace=False)\n",
       "      (18): Linear(in_features=471, out_features=353, bias=True)\n",
       "      (19): ReLU()\n",
       "      (20): Dropout(p=0.2, inplace=False)\n",
       "      (21): Linear(in_features=353, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [251, 289, 95, 256, 284, 471, 353],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0031478804663884405,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.6977791786193848,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.697916567325592,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 247: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=120, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=120, out_features=252, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=252, out_features=176, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=176, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [120, 252, 176],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0026289272376899585,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.6865713000297546,\n",
       "  'train_acc': 0.5963541666666666,\n",
       "  'val_loss': 0.635601818561554,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 248: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=316, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=316, out_features=500, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=500, out_features=487, bias=True)\n",
       "      (5): ReLU()\n",
       "      (6): Linear(in_features=487, out_features=131, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Linear(in_features=131, out_features=40, bias=True)\n",
       "      (9): ReLU()\n",
       "      (10): Linear(in_features=40, out_features=83, bias=True)\n",
       "      (11): ReLU()\n",
       "      (12): Linear(in_features=83, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [316, 500, 487, 131, 40, 83],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.005821146871949613,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.6979365944862366,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.6976919770240784,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 249: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=318, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=318, out_features=54, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=54, out_features=359, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=359, out_features=127, bias=True)\n",
       "      (10): Sigmoid()\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=127, out_features=87, bias=True)\n",
       "      (13): Sigmoid()\n",
       "      (14): Dropout(p=0.2, inplace=False)\n",
       "      (15): Linear(in_features=87, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [318, 54, 359, 127, 87],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0031828144655003314,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.673239529132843,\n",
       "  'train_acc': 0.5833333333333334,\n",
       "  'val_loss': 0.6293948292732239,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 250: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=270, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Linear(in_features=270, out_features=194, bias=True)\n",
       "      (3): Sigmoid()\n",
       "      (4): Linear(in_features=194, out_features=146, bias=True)\n",
       "      (5): Sigmoid()\n",
       "      (6): Linear(in_features=146, out_features=320, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Linear(in_features=320, out_features=137, bias=True)\n",
       "      (9): Sigmoid()\n",
       "      (10): Linear(in_features=137, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [270, 194, 146, 320, 137],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.008071842049311533,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.643119752407074,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.632474958896637,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 251: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=458, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=458, out_features=506, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=506, out_features=45, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=45, out_features=201, bias=True)\n",
       "      (10): Sigmoid()\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=201, out_features=61, bias=True)\n",
       "      (13): Sigmoid()\n",
       "      (14): Dropout(p=0.2, inplace=False)\n",
       "      (15): Linear(in_features=61, out_features=49, bias=True)\n",
       "      (16): Sigmoid()\n",
       "      (17): Dropout(p=0.2, inplace=False)\n",
       "      (18): Linear(in_features=49, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [458, 506, 45, 201, 61, 49],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.006110246511924483,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.6809328198432922,\n",
       "  'train_acc': 0.5729166666666666,\n",
       "  'val_loss': 0.6299080848693848,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 252: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=72, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=72, out_features=351, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=351, out_features=175, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=175, out_features=393, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=393, out_features=34, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.1, inplace=False)\n",
       "      (15): Linear(in_features=34, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [72, 351, 175, 393, 34],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.008581462561119595,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.6996532082557678,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.7000536322593689,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 253: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=74, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=74, out_features=143, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=143, out_features=27, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=27, out_features=62, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=62, out_features=73, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.1, inplace=False)\n",
       "      (15): Linear(in_features=73, out_features=100, bias=True)\n",
       "      (16): LeakyReLU(negative_slope=0.01)\n",
       "      (17): Dropout(p=0.1, inplace=False)\n",
       "      (18): Linear(in_features=100, out_features=305, bias=True)\n",
       "      (19): LeakyReLU(negative_slope=0.01)\n",
       "      (20): Dropout(p=0.1, inplace=False)\n",
       "      (21): Linear(in_features=305, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [74, 143, 27, 62, 73, 100, 305],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.009340486579894738,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.6898701786994934,\n",
       "  'train_acc': 0.6432291666666666,\n",
       "  'val_loss': 0.6886442303657532,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 254: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=117, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=117, out_features=121, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=121, out_features=31, bias=True)\n",
       "      (5): LeakyReLU(negative_slope=0.01)\n",
       "      (6): Linear(in_features=31, out_features=175, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Linear(in_features=175, out_features=451, bias=True)\n",
       "      (9): LeakyReLU(negative_slope=0.01)\n",
       "      (10): Linear(in_features=451, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [117, 121, 31, 175, 451],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0075400031822625245,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.7094116806983948,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.634483814239502,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 255: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=229, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=229, out_features=103, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=103, out_features=193, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=193, out_features=84, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=84, out_features=487, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.2, inplace=False)\n",
       "      (15): Linear(in_features=487, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [229, 103, 193, 84, 487],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0034155086687625933,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.6917784214019775,\n",
       "  'train_acc': 0.5859375,\n",
       "  'val_loss': 0.6917087435722351,\n",
       "  'val_acc': 0.6458333333333334},\n",
       " 256: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=33, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=33, out_features=440, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=440, out_features=429, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=429, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [33, 440, 429],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.006017484049221278,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.6855695843696594,\n",
       "  'train_acc': 0.5625,\n",
       "  'val_loss': 0.81388920545578,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 257: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=119, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=119, out_features=412, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=412, out_features=488, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=488, out_features=226, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=226, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [119, 412, 488, 226],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0033872887827903573,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.6934793591499329,\n",
       "  'train_acc': 0.4635416666666667,\n",
       "  'val_loss': 0.6323055624961853,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 258: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=383, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=383, out_features=226, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=226, out_features=161, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=161, out_features=363, bias=True)\n",
       "      (10): Sigmoid()\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=363, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [383, 226, 161, 363],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0017637284519111513,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.6923161149024963,\n",
       "  'train_acc': 0.53125,\n",
       "  'val_loss': 0.6480020880699158,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 259: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=406, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=406, out_features=77, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=77, out_features=443, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=443, out_features=66, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=66, out_features=474, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.2, inplace=False)\n",
       "      (15): Linear(in_features=474, out_features=376, bias=True)\n",
       "      (16): LeakyReLU(negative_slope=0.01)\n",
       "      (17): Dropout(p=0.2, inplace=False)\n",
       "      (18): Linear(in_features=376, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [406, 77, 443, 66, 474, 376],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0026536764983650287,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.6877216696739197,\n",
       "  'train_acc': 0.6536458333333334,\n",
       "  'val_loss': 0.6862959861755371,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 260: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=48, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=48, out_features=241, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=241, out_features=395, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=395, out_features=151, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=151, out_features=277, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.2, inplace=False)\n",
       "      (15): Linear(in_features=277, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [48, 241, 395, 151, 277],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0026202285662574845,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.7059418559074402,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.6637976169586182,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 261: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=162, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=162, out_features=66, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=66, out_features=223, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=223, out_features=290, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=290, out_features=302, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.1, inplace=False)\n",
       "      (15): Linear(in_features=302, out_features=24, bias=True)\n",
       "      (16): LeakyReLU(negative_slope=0.01)\n",
       "      (17): Dropout(p=0.1, inplace=False)\n",
       "      (18): Linear(in_features=24, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [162, 66, 223, 290, 302, 24],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.005583564193442133,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.6826410889625549,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.6812030673027039,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 262: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=28, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=28, out_features=137, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=137, out_features=100, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=100, out_features=96, bias=True)\n",
       "      (10): Sigmoid()\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=96, out_features=358, bias=True)\n",
       "      (13): Sigmoid()\n",
       "      (14): Dropout(p=0.1, inplace=False)\n",
       "      (15): Linear(in_features=358, out_features=308, bias=True)\n",
       "      (16): Sigmoid()\n",
       "      (17): Dropout(p=0.1, inplace=False)\n",
       "      (18): Linear(in_features=308, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [28, 137, 100, 96, 358, 308],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.008548677077937604,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.7127150893211365,\n",
       "  'train_acc': 0.4166666666666667,\n",
       "  'val_loss': 0.6665048599243164,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 263: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=479, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=479, out_features=214, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=214, out_features=35, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=35, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [479, 214, 35],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.009721449679704917,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.6533634066581726,\n",
       "  'train_acc': 0.6432291666666666,\n",
       "  'val_loss': 0.6462724804878235,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 264: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=214, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=214, out_features=264, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=264, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [214, 264],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.00532227603537159,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.7097339034080505,\n",
       "  'train_acc': 0.4505208333333333,\n",
       "  'val_loss': 0.714555561542511,\n",
       "  'val_acc': 0.3541666666666667},\n",
       " 265: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=271, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=271, out_features=96, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=96, out_features=449, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=449, out_features=445, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=445, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [271, 96, 449, 445],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0020580869150555775,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.7227072715759277,\n",
       "  'train_acc': 0.3515625,\n",
       "  'val_loss': 0.7132270336151123,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 266: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=161, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=161, out_features=212, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=212, out_features=60, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=60, out_features=73, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=73, out_features=147, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=147, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [161, 212, 60, 73, 147],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.005978167800130528,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.6735795140266418,\n",
       "  'train_acc': 0.625,\n",
       "  'val_loss': 0.64173424243927,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 267: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=353, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=353, out_features=454, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=454, out_features=406, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=406, out_features=45, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=45, out_features=209, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=209, out_features=299, bias=True)\n",
       "      (16): ReLU()\n",
       "      (17): Dropout(p=0.5, inplace=False)\n",
       "      (18): Linear(in_features=299, out_features=125, bias=True)\n",
       "      (19): ReLU()\n",
       "      (20): Dropout(p=0.5, inplace=False)\n",
       "      (21): Linear(in_features=125, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [353, 454, 406, 45, 209, 299, 125],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.005120118890403484,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.7109348773956299,\n",
       "  'train_acc': 0.34375,\n",
       "  'val_loss': 0.712806224822998,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 268: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=209, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=209, out_features=36, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=36, out_features=179, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=179, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [209, 36, 179],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.005741511173218366,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.6839801669120789,\n",
       "  'train_acc': 0.6640625,\n",
       "  'val_loss': 0.6835684776306152,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 269: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=435, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=435, out_features=41, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=41, out_features=35, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=35, out_features=144, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=144, out_features=470, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.2, inplace=False)\n",
       "      (15): Linear(in_features=470, out_features=478, bias=True)\n",
       "      (16): ReLU()\n",
       "      (17): Dropout(p=0.2, inplace=False)\n",
       "      (18): Linear(in_features=478, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [435, 41, 35, 144, 470, 478],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0035519319380263314,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.6952154636383057,\n",
       "  'train_acc': 0.3932291666666667,\n",
       "  'val_loss': 0.6353474259376526,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 270: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=110, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=110, out_features=180, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=180, out_features=332, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=332, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [110, 180, 332],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0059733011019186,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.6838131546974182,\n",
       "  'train_acc': 0.5963541666666666,\n",
       "  'val_loss': 0.6815642714500427,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 271: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=325, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=325, out_features=409, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=409, out_features=446, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=446, out_features=307, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=307, out_features=99, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=99, out_features=106, bias=True)\n",
       "      (16): ReLU()\n",
       "      (17): Dropout(p=0.5, inplace=False)\n",
       "      (18): Linear(in_features=106, out_features=458, bias=True)\n",
       "      (19): ReLU()\n",
       "      (20): Dropout(p=0.5, inplace=False)\n",
       "      (21): Linear(in_features=458, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [325, 409, 446, 307, 99, 106, 458],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0063242629640184326,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.6998257040977478,\n",
       "  'train_acc': 0.40625,\n",
       "  'val_loss': 0.6396372318267822,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 272: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=239, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=239, out_features=276, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=276, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [239, 276],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.006395118541744018,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.7225988507270813,\n",
       "  'train_acc': 0.3671875,\n",
       "  'val_loss': 0.8253487944602966,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 273: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=401, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=401, out_features=109, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=109, out_features=184, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=184, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [401, 109, 184],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.009282432962837768,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.709713876247406,\n",
       "  'train_acc': 0.3723958333333333,\n",
       "  'val_loss': 0.7089100480079651,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 274: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=115, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=115, out_features=91, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=91, out_features=500, bias=True)\n",
       "      (5): ReLU()\n",
       "      (6): Linear(in_features=500, out_features=378, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Linear(in_features=378, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [115, 91, 500, 378],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0024979867875385728,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.6896046996116638,\n",
       "  'train_acc': 0.6145833333333334,\n",
       "  'val_loss': 0.6886585354804993,\n",
       "  'val_acc': 0.6145833333333334},\n",
       " 275: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=355, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=355, out_features=290, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=290, out_features=232, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=232, out_features=333, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=333, out_features=354, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.2, inplace=False)\n",
       "      (15): Linear(in_features=354, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [355, 290, 232, 333, 354],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.007817152362302827,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.6930915713310242,\n",
       "  'train_acc': 0.4869791666666667,\n",
       "  'val_loss': 0.6920711398124695,\n",
       "  'val_acc': 0.6875},\n",
       " 276: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=22, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=22, out_features=37, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=37, out_features=53, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=53, out_features=483, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=483, out_features=506, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.2, inplace=False)\n",
       "      (15): Linear(in_features=506, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [22, 37, 53, 483, 506],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.00840374641457261,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.6959086060523987,\n",
       "  'train_acc': 0.4140625,\n",
       "  'val_loss': 0.6944445967674255,\n",
       "  'val_acc': 0.3541666666666667},\n",
       " 277: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=511, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=511, out_features=279, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=279, out_features=206, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=206, out_features=483, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=483, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [511, 279, 206, 483],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.009541581973825847,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.6907675266265869,\n",
       "  'train_acc': 0.5572916666666666,\n",
       "  'val_loss': 0.6895008087158203,\n",
       "  'val_acc': 0.6041666666666666},\n",
       " 278: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=178, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=178, out_features=91, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=91, out_features=429, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=429, out_features=462, bias=True)\n",
       "      (10): Sigmoid()\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=462, out_features=16, bias=True)\n",
       "      (13): Sigmoid()\n",
       "      (14): Dropout(p=0.2, inplace=False)\n",
       "      (15): Linear(in_features=16, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [178, 91, 429, 462, 16],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.008352290622988484,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.8200461268424988,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.808062732219696,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 279: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=478, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=478, out_features=399, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=399, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [478, 399],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0017301453098438099,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.7573801875114441,\n",
       "  'train_acc': 0.3385416666666667,\n",
       "  'val_loss': 0.6546509861946106,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 280: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=41, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=41, out_features=74, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=74, out_features=278, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=278, out_features=39, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=39, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [41, 74, 278, 39],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.004651316595410763,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.7181313633918762,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.7190527319908142,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 281: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=95, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=95, out_features=274, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=274, out_features=434, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=434, out_features=407, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=407, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [95, 274, 434, 407],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.00127404492153179,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.6953495144844055,\n",
       "  'train_acc': 0.5,\n",
       "  'val_loss': 0.6995339393615723,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 282: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=116, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=116, out_features=493, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=493, out_features=61, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=61, out_features=260, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=260, out_features=98, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.1, inplace=False)\n",
       "      (15): Linear(in_features=98, out_features=71, bias=True)\n",
       "      (16): LeakyReLU(negative_slope=0.01)\n",
       "      (17): Dropout(p=0.1, inplace=False)\n",
       "      (18): Linear(in_features=71, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [116, 493, 61, 260, 98, 71],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.007284875192521943,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.7105262279510498,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.6651647090911865,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 283: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=127, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=127, out_features=441, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=441, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [127, 441],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.006197996386547433,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.7296339869499207,\n",
       "  'train_acc': 0.3463541666666667,\n",
       "  'val_loss': 0.7234184145927429,\n",
       "  'val_acc': 0.3645833333333333},\n",
       " 284: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=117, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=117, out_features=343, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=343, out_features=142, bias=True)\n",
       "      (5): ReLU()\n",
       "      (6): Linear(in_features=142, out_features=220, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Linear(in_features=220, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [117, 343, 142, 220],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.008955867795040894,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.6863407492637634,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.6956049799919128,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 285: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=412, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=412, out_features=381, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=381, out_features=316, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=316, out_features=189, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=189, out_features=265, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=265, out_features=390, bias=True)\n",
       "      (16): LeakyReLU(negative_slope=0.01)\n",
       "      (17): Dropout(p=0.5, inplace=False)\n",
       "      (18): Linear(in_features=390, out_features=18, bias=True)\n",
       "      (19): LeakyReLU(negative_slope=0.01)\n",
       "      (20): Dropout(p=0.5, inplace=False)\n",
       "      (21): Linear(in_features=18, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [412, 381, 316, 189, 265, 390, 18],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0015106696821339178,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.7829927802085876,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.7901940941810608,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 286: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=26, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=26, out_features=147, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=147, out_features=418, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=418, out_features=320, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=320, out_features=137, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.1, inplace=False)\n",
       "      (15): Linear(in_features=137, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [26, 147, 418, 320, 137],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0029550120267889577,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.6901282668113708,\n",
       "  'train_acc': 0.6328125,\n",
       "  'val_loss': 0.6489993333816528,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 287: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=340, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=340, out_features=29, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=29, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [340, 29],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.009919082301104859,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.7805240154266357,\n",
       "  'train_acc': 0.3463541666666667,\n",
       "  'val_loss': 0.7057886123657227,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 288: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=453, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=453, out_features=321, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=321, out_features=408, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=408, out_features=272, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=272, out_features=148, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.2, inplace=False)\n",
       "      (15): Linear(in_features=148, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [453, 321, 408, 272, 148],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.004217455363895708,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.6945216059684753,\n",
       "  'train_acc': 0.4296875,\n",
       "  'val_loss': 0.6941800713539124,\n",
       "  'val_acc': 0.375},\n",
       " 289: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=234, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=234, out_features=97, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=97, out_features=99, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=99, out_features=188, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=188, out_features=444, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.2, inplace=False)\n",
       "      (15): Linear(in_features=444, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [234, 97, 99, 188, 444],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.00923063895317108,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.6875907778739929,\n",
       "  'train_acc': 0.6458333333333334,\n",
       "  'val_loss': 0.6737046837806702,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 290: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=216, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=216, out_features=189, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=189, out_features=310, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=310, out_features=157, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=157, out_features=170, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.2, inplace=False)\n",
       "      (15): Linear(in_features=170, out_features=51, bias=True)\n",
       "      (16): LeakyReLU(negative_slope=0.01)\n",
       "      (17): Dropout(p=0.2, inplace=False)\n",
       "      (18): Linear(in_features=51, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [216, 189, 310, 157, 170, 51],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.009524384244397919,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.6748591065406799,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.6244062185287476,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 291: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=315, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=315, out_features=102, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=102, out_features=286, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=286, out_features=207, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=207, out_features=232, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.1, inplace=False)\n",
       "      (15): Linear(in_features=232, out_features=394, bias=True)\n",
       "      (16): LeakyReLU(negative_slope=0.01)\n",
       "      (17): Dropout(p=0.1, inplace=False)\n",
       "      (18): Linear(in_features=394, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [315, 102, 286, 207, 232, 394],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.001835311215539331,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.6909303069114685,\n",
       "  'train_acc': 0.6432291666666666,\n",
       "  'val_loss': 0.6660836338996887,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 292: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=22, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=22, out_features=320, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=320, out_features=325, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=325, out_features=167, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=167, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [22, 320, 325, 167],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.00473409368417018,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.7117231488227844,\n",
       "  'train_acc': 0.3802083333333333,\n",
       "  'val_loss': 0.7092933058738708,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 293: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=148, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=148, out_features=466, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=466, out_features=338, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=338, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [148, 466, 338],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0025515895753455368,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.6839130520820618,\n",
       "  'train_acc': 0.6145833333333334,\n",
       "  'val_loss': 0.6429100036621094,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 294: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=504, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=504, out_features=194, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=194, out_features=511, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=511, out_features=45, bias=True)\n",
       "      (10): Sigmoid()\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=45, out_features=387, bias=True)\n",
       "      (13): Sigmoid()\n",
       "      (14): Dropout(p=0.2, inplace=False)\n",
       "      (15): Linear(in_features=387, out_features=214, bias=True)\n",
       "      (16): Sigmoid()\n",
       "      (17): Dropout(p=0.2, inplace=False)\n",
       "      (18): Linear(in_features=214, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [504, 194, 511, 45, 387, 214],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.008979347403893157,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.6780676245689392,\n",
       "  'train_acc': 0.5807291666666666,\n",
       "  'val_loss': 0.6583293080329895,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 295: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=272, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=272, out_features=260, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=260, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [272, 260],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.009405076072259176,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.6540820598602295,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.6336261630058289,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 296: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=398, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=398, out_features=90, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=90, out_features=492, bias=True)\n",
       "      (5): LeakyReLU(negative_slope=0.01)\n",
       "      (6): Linear(in_features=492, out_features=35, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Linear(in_features=35, out_features=442, bias=True)\n",
       "      (9): LeakyReLU(negative_slope=0.01)\n",
       "      (10): Linear(in_features=442, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [398, 90, 492, 35, 442],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.008136829415271135,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.70675128698349,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.6656345725059509,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 297: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=231, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=231, out_features=420, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=420, out_features=78, bias=True)\n",
       "      (5): LeakyReLU(negative_slope=0.01)\n",
       "      (6): Linear(in_features=78, out_features=364, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Linear(in_features=364, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [231, 420, 78, 364],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0095047834191529,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.6985952258110046,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.6971526145935059,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 298: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=92, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=92, out_features=128, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=128, out_features=40, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=40, out_features=200, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=200, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [92, 128, 40, 200],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.008490803512303899,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.7036418914794922,\n",
       "  'train_acc': 0.3385416666666667,\n",
       "  'val_loss': 0.6468043923377991,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 299: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=336, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=336, out_features=299, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=299, out_features=492, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=492, out_features=400, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=400, out_features=47, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.1, inplace=False)\n",
       "      (15): Linear(in_features=47, out_features=358, bias=True)\n",
       "      (16): ReLU()\n",
       "      (17): Dropout(p=0.1, inplace=False)\n",
       "      (18): Linear(in_features=358, out_features=464, bias=True)\n",
       "      (19): ReLU()\n",
       "      (20): Dropout(p=0.1, inplace=False)\n",
       "      (21): Linear(in_features=464, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [336, 299, 492, 400, 47, 358, 464],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0028585199436330895,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.7000627517700195,\n",
       "  'train_acc': 0.3463541666666667,\n",
       "  'val_loss': 0.6998007893562317,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 300: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=182, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=182, out_features=181, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=181, out_features=15, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=15, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [182, 181, 15],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.009079710975983136,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.6935190558433533,\n",
       "  'train_acc': 0.4973958333333333,\n",
       "  'val_loss': 0.6207983493804932,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 301: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=64, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=64, out_features=357, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=357, out_features=322, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=322, out_features=343, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=343, out_features=380, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.1, inplace=False)\n",
       "      (15): Linear(in_features=380, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [64, 357, 322, 343, 380],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.003844011659260645,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.6874744296073914,\n",
       "  'train_acc': 0.65625,\n",
       "  'val_loss': 0.6285646557807922,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 302: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=119, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=119, out_features=349, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=349, out_features=110, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=110, out_features=482, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=482, out_features=97, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.1, inplace=False)\n",
       "      (15): Linear(in_features=97, out_features=66, bias=True)\n",
       "      (16): LeakyReLU(negative_slope=0.01)\n",
       "      (17): Dropout(p=0.1, inplace=False)\n",
       "      (18): Linear(in_features=66, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [119, 349, 110, 482, 97, 66],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.005930622089392103,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.6741254329681396,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.6710770130157471,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 303: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=263, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=263, out_features=237, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=237, out_features=277, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=277, out_features=331, bias=True)\n",
       "      (10): Sigmoid()\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=331, out_features=188, bias=True)\n",
       "      (13): Sigmoid()\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=188, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [263, 237, 277, 331, 188],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.001331703374780408,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.6491914391517639,\n",
       "  'train_acc': 0.671875,\n",
       "  'val_loss': 0.6306701898574829,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 304: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=151, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=151, out_features=163, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=163, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [151, 163],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.007995384467326394,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.734511137008667,\n",
       "  'train_acc': 0.4036458333333333,\n",
       "  'val_loss': 0.6714895367622375,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 305: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=157, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=157, out_features=270, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=270, out_features=327, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=327, out_features=62, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=62, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [157, 270, 327, 62],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0023561232578518075,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.7094600796699524,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.6702019572257996,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 306: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=51, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=51, out_features=274, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=274, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [51, 274],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0023347624873862835,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.7259182333946228,\n",
       "  'train_acc': 0.3463541666666667,\n",
       "  'val_loss': 0.7276875376701355,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 307: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=151, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=151, out_features=161, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=161, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [151, 161],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.00731169390303987,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.7260596752166748,\n",
       "  'train_acc': 0.4140625,\n",
       "  'val_loss': 0.6676590442657471,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 308: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=112, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=112, out_features=359, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=359, out_features=462, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=462, out_features=318, bias=True)\n",
       "      (10): Sigmoid()\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=318, out_features=415, bias=True)\n",
       "      (13): Sigmoid()\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=415, out_features=355, bias=True)\n",
       "      (16): Sigmoid()\n",
       "      (17): Dropout(p=0.5, inplace=False)\n",
       "      (18): Linear(in_features=355, out_features=337, bias=True)\n",
       "      (19): Sigmoid()\n",
       "      (20): Dropout(p=0.5, inplace=False)\n",
       "      (21): Linear(in_features=337, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [112, 359, 462, 318, 415, 355, 337],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.006346345486119715,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.661912739276886,\n",
       "  'train_acc': 0.6484375,\n",
       "  'val_loss': 0.6296691298484802,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 309: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=178, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=178, out_features=223, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=223, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [178, 223],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0010170863109326546,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.6996760368347168,\n",
       "  'train_acc': 0.5182291666666666,\n",
       "  'val_loss': 0.6926448345184326,\n",
       "  'val_acc': 0.5833333333333334},\n",
       " 310: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=337, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=337, out_features=248, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=248, out_features=397, bias=True)\n",
       "      (5): ReLU()\n",
       "      (6): Linear(in_features=397, out_features=240, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Linear(in_features=240, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [337, 248, 397, 240],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0019126711311479353,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.6837121844291687,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.6330477595329285,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 311: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=41, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=41, out_features=329, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=329, out_features=308, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=308, out_features=131, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=131, out_features=288, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.2, inplace=False)\n",
       "      (15): Linear(in_features=288, out_features=47, bias=True)\n",
       "      (16): LeakyReLU(negative_slope=0.01)\n",
       "      (17): Dropout(p=0.2, inplace=False)\n",
       "      (18): Linear(in_features=47, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [41, 329, 308, 131, 288, 47],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.007513149800954578,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.6895644068717957,\n",
       "  'train_acc': 0.6432291666666666,\n",
       "  'val_loss': 0.6322177052497864,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 312: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=201, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=201, out_features=507, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=507, out_features=479, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=479, out_features=327, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=327, out_features=240, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.2, inplace=False)\n",
       "      (15): Linear(in_features=240, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [201, 507, 479, 327, 240],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.001981867566431438,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.6855291724205017,\n",
       "  'train_acc': 0.65625,\n",
       "  'val_loss': 0.6843836307525635,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 313: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=110, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=110, out_features=33, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=33, out_features=94, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=94, out_features=119, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=119, out_features=290, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.2, inplace=False)\n",
       "      (15): Linear(in_features=290, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [110, 33, 94, 119, 290],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.004249380040226624,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.6979207992553711,\n",
       "  'train_acc': 0.3802083333333333,\n",
       "  'val_loss': 0.6639887690544128,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 314: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=305, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=305, out_features=236, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=236, out_features=312, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=312, out_features=379, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=379, out_features=125, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=125, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [305, 236, 312, 379, 125],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0017373915850289919,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.7096760272979736,\n",
       "  'train_acc': 0.3619791666666667,\n",
       "  'val_loss': 0.7138499617576599,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 315: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=342, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=342, out_features=299, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=299, out_features=429, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=429, out_features=225, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=225, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [342, 299, 429, 225],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0012340208839938926,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.7179003357887268,\n",
       "  'train_acc': 0.3671875,\n",
       "  'val_loss': 0.7115523815155029,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 316: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=411, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=411, out_features=184, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=184, out_features=230, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=230, out_features=107, bias=True)\n",
       "      (10): Sigmoid()\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=107, out_features=452, bias=True)\n",
       "      (13): Sigmoid()\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=452, out_features=200, bias=True)\n",
       "      (16): Sigmoid()\n",
       "      (17): Dropout(p=0.5, inplace=False)\n",
       "      (18): Linear(in_features=200, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [411, 184, 230, 107, 452, 200],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0013989782157349453,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.649223804473877,\n",
       "  'train_acc': 0.6276041666666666,\n",
       "  'val_loss': 0.651649534702301,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 317: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=86, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=86, out_features=109, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=109, out_features=194, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=194, out_features=153, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=153, out_features=58, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.2, inplace=False)\n",
       "      (15): Linear(in_features=58, out_features=53, bias=True)\n",
       "      (16): ReLU()\n",
       "      (17): Dropout(p=0.2, inplace=False)\n",
       "      (18): Linear(in_features=53, out_features=130, bias=True)\n",
       "      (19): ReLU()\n",
       "      (20): Dropout(p=0.2, inplace=False)\n",
       "      (21): Linear(in_features=130, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [86, 109, 194, 153, 58, 53, 130],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0066576278633933,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.6753242611885071,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.647102952003479,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 318: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=161, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=161, out_features=302, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=302, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [161, 302],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.006279244406198964,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.699913501739502,\n",
       "  'train_acc': 0.484375,\n",
       "  'val_loss': 0.6695289015769958,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 319: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=29, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=29, out_features=386, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=386, out_features=332, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=332, out_features=190, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=190, out_features=166, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.1, inplace=False)\n",
       "      (15): Linear(in_features=166, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [29, 386, 332, 190, 166],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.007262738083673214,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.6737143993377686,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.6710882186889648,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 320: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=101, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=101, out_features=241, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=241, out_features=210, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=210, out_features=237, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=237, out_features=156, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.1, inplace=False)\n",
       "      (15): Linear(in_features=156, out_features=359, bias=True)\n",
       "      (16): LeakyReLU(negative_slope=0.01)\n",
       "      (17): Dropout(p=0.1, inplace=False)\n",
       "      (18): Linear(in_features=359, out_features=104, bias=True)\n",
       "      (19): LeakyReLU(negative_slope=0.01)\n",
       "      (20): Dropout(p=0.1, inplace=False)\n",
       "      (21): Linear(in_features=104, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [101, 241, 210, 237, 156, 359, 104],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.009385106583718276,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.6715207695960999,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.6681206822395325,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 321: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=56, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=56, out_features=46, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=46, out_features=139, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=139, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [56, 46, 139],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.008677564056004571,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.7350711822509766,\n",
       "  'train_acc': 0.3671875,\n",
       "  'val_loss': 0.6771289706230164,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 322: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=352, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Linear(in_features=352, out_features=17, bias=True)\n",
       "      (3): Sigmoid()\n",
       "      (4): Linear(in_features=17, out_features=367, bias=True)\n",
       "      (5): Sigmoid()\n",
       "      (6): Linear(in_features=367, out_features=433, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Linear(in_features=433, out_features=205, bias=True)\n",
       "      (9): Sigmoid()\n",
       "      (10): Linear(in_features=205, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [352, 17, 367, 433, 205],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.001485653793140283,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.6992921233177185,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.6486160159111023,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 323: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=332, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=332, out_features=454, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=454, out_features=360, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=360, out_features=441, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=441, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [332, 454, 360, 441],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.006274385862543783,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.6849169135093689,\n",
       "  'train_acc': 0.5625,\n",
       "  'val_loss': 0.6856234073638916,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 324: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=440, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Linear(in_features=440, out_features=438, bias=True)\n",
       "      (3): Sigmoid()\n",
       "      (4): Linear(in_features=438, out_features=389, bias=True)\n",
       "      (5): Sigmoid()\n",
       "      (6): Linear(in_features=389, out_features=278, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Linear(in_features=278, out_features=397, bias=True)\n",
       "      (9): Sigmoid()\n",
       "      (10): Linear(in_features=397, out_features=325, bias=True)\n",
       "      (11): Sigmoid()\n",
       "      (12): Linear(in_features=325, out_features=453, bias=True)\n",
       "      (13): Sigmoid()\n",
       "      (14): Linear(in_features=453, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [440, 438, 389, 278, 397, 325, 453],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.007153497506310202,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.6732382774353027,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.6465705037117004,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 325: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=280, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Linear(in_features=280, out_features=88, bias=True)\n",
       "      (3): Sigmoid()\n",
       "      (4): Linear(in_features=88, out_features=129, bias=True)\n",
       "      (5): Sigmoid()\n",
       "      (6): Linear(in_features=129, out_features=128, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Linear(in_features=128, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [280, 88, 129, 128],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.00437074294938296,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.6487473845481873,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.7002062797546387,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 326: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=147, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=147, out_features=257, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=257, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [147, 257],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.005292609798774597,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.6698479056358337,\n",
       "  'train_acc': 0.6119791666666666,\n",
       "  'val_loss': 0.6326765418052673,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 327: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=13, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=13, out_features=20, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=20, out_features=504, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=504, out_features=218, bias=True)\n",
       "      (10): Sigmoid()\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=218, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [13, 20, 504, 218],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0023478227780397974,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.713205873966217,\n",
       "  'train_acc': 0.4192708333333333,\n",
       "  'val_loss': 0.7260820865631104,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 328: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=276, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=276, out_features=419, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=419, out_features=101, bias=True)\n",
       "      (5): LeakyReLU(negative_slope=0.01)\n",
       "      (6): Linear(in_features=101, out_features=382, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Linear(in_features=382, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [276, 419, 101, 382],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.009152378965841326,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.6907482147216797,\n",
       "  'train_acc': 0.5911458333333334,\n",
       "  'val_loss': 0.6906713843345642,\n",
       "  'val_acc': 0.5625},\n",
       " 329: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=313, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=313, out_features=490, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=490, out_features=482, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=482, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [313, 490, 482],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.008195927488707355,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.7209622859954834,\n",
       "  'train_acc': 0.3645833333333333,\n",
       "  'val_loss': 0.7119411826133728,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 330: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=242, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=242, out_features=361, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=361, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [242, 361],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.005208317838735793,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.684675395488739,\n",
       "  'train_acc': 0.5651041666666666,\n",
       "  'val_loss': 0.8844113349914551,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 331: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=133, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=133, out_features=30, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=30, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [133, 30],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.008788880651500545,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.6789204478263855,\n",
       "  'train_acc': 0.5546875,\n",
       "  'val_loss': 0.6551265716552734,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 332: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=188, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Linear(in_features=188, out_features=350, bias=True)\n",
       "      (3): Sigmoid()\n",
       "      (4): Linear(in_features=350, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [188, 350],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.002678831664021481,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.6727858185768127,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.7500503659248352,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 333: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=376, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=376, out_features=176, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=176, out_features=360, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=360, out_features=353, bias=True)\n",
       "      (10): Sigmoid()\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=353, out_features=102, bias=True)\n",
       "      (13): Sigmoid()\n",
       "      (14): Dropout(p=0.1, inplace=False)\n",
       "      (15): Linear(in_features=102, out_features=89, bias=True)\n",
       "      (16): Sigmoid()\n",
       "      (17): Dropout(p=0.1, inplace=False)\n",
       "      (18): Linear(in_features=89, out_features=469, bias=True)\n",
       "      (19): Sigmoid()\n",
       "      (20): Dropout(p=0.1, inplace=False)\n",
       "      (21): Linear(in_features=469, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [376, 176, 360, 353, 102, 89, 469],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0031834008053795355,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.7048873901367188,\n",
       "  'train_acc': 0.453125,\n",
       "  'val_loss': 0.7781879901885986,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 334: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=48, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=48, out_features=462, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=462, out_features=327, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=327, out_features=381, bias=True)\n",
       "      (10): Sigmoid()\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=381, out_features=341, bias=True)\n",
       "      (13): Sigmoid()\n",
       "      (14): Dropout(p=0.1, inplace=False)\n",
       "      (15): Linear(in_features=341, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [48, 462, 327, 381, 341],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.005366752862730645,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.6825286746025085,\n",
       "  'train_acc': 0.5494791666666666,\n",
       "  'val_loss': 0.6568201780319214,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 335: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=322, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=322, out_features=280, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=280, out_features=272, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=272, out_features=158, bias=True)\n",
       "      (10): Sigmoid()\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=158, out_features=435, bias=True)\n",
       "      (13): Sigmoid()\n",
       "      (14): Dropout(p=0.1, inplace=False)\n",
       "      (15): Linear(in_features=435, out_features=234, bias=True)\n",
       "      (16): Sigmoid()\n",
       "      (17): Dropout(p=0.1, inplace=False)\n",
       "      (18): Linear(in_features=234, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [322, 280, 272, 158, 435, 234],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0012331988006212876,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.7452495694160461,\n",
       "  'train_acc': 0.3541666666666667,\n",
       "  'val_loss': 0.7475261092185974,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 336: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=470, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=470, out_features=445, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=445, out_features=156, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=156, out_features=85, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=85, out_features=156, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=156, out_features=133, bias=True)\n",
       "      (16): LeakyReLU(negative_slope=0.01)\n",
       "      (17): Dropout(p=0.5, inplace=False)\n",
       "      (18): Linear(in_features=133, out_features=81, bias=True)\n",
       "      (19): LeakyReLU(negative_slope=0.01)\n",
       "      (20): Dropout(p=0.5, inplace=False)\n",
       "      (21): Linear(in_features=81, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [470, 445, 156, 85, 156, 133, 81],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.005127653362271884,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.6911388039588928,\n",
       "  'train_acc': 0.5651041666666666,\n",
       "  'val_loss': 0.6874146461486816,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 337: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=460, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=460, out_features=91, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=91, out_features=353, bias=True)\n",
       "      (5): ReLU()\n",
       "      (6): Linear(in_features=353, out_features=446, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Linear(in_features=446, out_features=251, bias=True)\n",
       "      (9): ReLU()\n",
       "      (10): Linear(in_features=251, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [460, 91, 353, 446, 251],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0011856824513706869,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.6949217915534973,\n",
       "  'train_acc': 0.3463541666666667,\n",
       "  'val_loss': 0.6949372887611389,\n",
       "  'val_acc': 0.3645833333333333},\n",
       " 338: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=462, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=462, out_features=357, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=357, out_features=458, bias=True)\n",
       "      (5): LeakyReLU(negative_slope=0.01)\n",
       "      (6): Linear(in_features=458, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [462, 357, 458],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0011376797854504715,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.6893048286437988,\n",
       "  'train_acc': 0.6015625,\n",
       "  'val_loss': 0.6198301911354065,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 339: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=319, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=319, out_features=265, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=265, out_features=432, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=432, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [319, 265, 432],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.007090905246516421,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.680128812789917,\n",
       "  'train_acc': 0.6458333333333334,\n",
       "  'val_loss': 0.6808473467826843,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 340: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=201, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=201, out_features=97, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=97, out_features=209, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=209, out_features=261, bias=True)\n",
       "      (10): Sigmoid()\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=261, out_features=240, bias=True)\n",
       "      (13): Sigmoid()\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=240, out_features=416, bias=True)\n",
       "      (16): Sigmoid()\n",
       "      (17): Dropout(p=0.5, inplace=False)\n",
       "      (18): Linear(in_features=416, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [201, 97, 209, 261, 240, 416],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0031524251717476416,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.6574319005012512,\n",
       "  'train_acc': 0.6328125,\n",
       "  'val_loss': 0.7364461421966553,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 341: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=438, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=438, out_features=310, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=310, out_features=77, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=77, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [438, 310, 77],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.00216414212103807,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.7381071448326111,\n",
       "  'train_acc': 0.3932291666666667,\n",
       "  'val_loss': 0.6334157586097717,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 342: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=363, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=363, out_features=239, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=239, out_features=162, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=162, out_features=70, bias=True)\n",
       "      (10): Sigmoid()\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=70, out_features=37, bias=True)\n",
       "      (13): Sigmoid()\n",
       "      (14): Dropout(p=0.2, inplace=False)\n",
       "      (15): Linear(in_features=37, out_features=494, bias=True)\n",
       "      (16): Sigmoid()\n",
       "      (17): Dropout(p=0.2, inplace=False)\n",
       "      (18): Linear(in_features=494, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [363, 239, 162, 70, 37, 494],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0026980044430896842,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.7075515389442444,\n",
       "  'train_acc': 0.4557291666666667,\n",
       "  'val_loss': 0.6831490993499756,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 343: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=158, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=158, out_features=298, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=298, out_features=67, bias=True)\n",
       "      (5): ReLU()\n",
       "      (6): Linear(in_features=67, out_features=108, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Linear(in_features=108, out_features=255, bias=True)\n",
       "      (9): ReLU()\n",
       "      (10): Linear(in_features=255, out_features=496, bias=True)\n",
       "      (11): ReLU()\n",
       "      (12): Linear(in_features=496, out_features=278, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Linear(in_features=278, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [158, 298, 67, 108, 255, 496, 278],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.001157758613771974,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.7000628113746643,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.7007784843444824,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 344: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=102, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=102, out_features=124, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=124, out_features=385, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=385, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [102, 124, 385],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.003526064053402622,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.6972399353981018,\n",
       "  'train_acc': 0.4270833333333333,\n",
       "  'val_loss': 0.6312978863716125,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 345: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=429, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=429, out_features=334, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=334, out_features=364, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=364, out_features=424, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=424, out_features=355, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.2, inplace=False)\n",
       "      (15): Linear(in_features=355, out_features=335, bias=True)\n",
       "      (16): LeakyReLU(negative_slope=0.01)\n",
       "      (17): Dropout(p=0.2, inplace=False)\n",
       "      (18): Linear(in_features=335, out_features=37, bias=True)\n",
       "      (19): LeakyReLU(negative_slope=0.01)\n",
       "      (20): Dropout(p=0.2, inplace=False)\n",
       "      (21): Linear(in_features=37, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [429, 334, 364, 424, 355, 335, 37],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0075616596452737495,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.6763790249824524,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.673556387424469,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 346: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=224, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=224, out_features=250, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=250, out_features=283, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=283, out_features=478, bias=True)\n",
       "      (10): Sigmoid()\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=478, out_features=168, bias=True)\n",
       "      (13): Sigmoid()\n",
       "      (14): Dropout(p=0.1, inplace=False)\n",
       "      (15): Linear(in_features=168, out_features=29, bias=True)\n",
       "      (16): Sigmoid()\n",
       "      (17): Dropout(p=0.1, inplace=False)\n",
       "      (18): Linear(in_features=29, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [224, 250, 283, 478, 168, 29],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0091565856214301,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.6630927920341492,\n",
       "  'train_acc': 0.640625,\n",
       "  'val_loss': 0.7071917653083801,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 347: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=299, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Linear(in_features=299, out_features=353, bias=True)\n",
       "      (3): Sigmoid()\n",
       "      (4): Linear(in_features=353, out_features=136, bias=True)\n",
       "      (5): Sigmoid()\n",
       "      (6): Linear(in_features=136, out_features=324, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Linear(in_features=324, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [299, 353, 136, 324],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0038711120097668006,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.7263140678405762,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.7838999629020691,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 348: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=35, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=35, out_features=129, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=129, out_features=155, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=155, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [35, 129, 155],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0025193014656739125,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.7486419677734375,\n",
       "  'train_acc': 0.375,\n",
       "  'val_loss': 0.7419395446777344,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 349: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=152, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=152, out_features=429, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=429, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [152, 429],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.003874628577497316,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.712489128112793,\n",
       "  'train_acc': 0.4088541666666667,\n",
       "  'val_loss': 0.6476638913154602,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 350: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=394, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=394, out_features=25, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=25, out_features=443, bias=True)\n",
       "      (5): ReLU()\n",
       "      (6): Linear(in_features=443, out_features=315, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Linear(in_features=315, out_features=321, bias=True)\n",
       "      (9): ReLU()\n",
       "      (10): Linear(in_features=321, out_features=451, bias=True)\n",
       "      (11): ReLU()\n",
       "      (12): Linear(in_features=451, out_features=23, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Linear(in_features=23, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [394, 25, 443, 315, 321, 451, 23],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.008600337075681926,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.6909467577934265,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.7169742584228516,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 351: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=67, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=67, out_features=478, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=478, out_features=317, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=317, out_features=181, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=181, out_features=124, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.2, inplace=False)\n",
       "      (15): Linear(in_features=124, out_features=48, bias=True)\n",
       "      (16): LeakyReLU(negative_slope=0.01)\n",
       "      (17): Dropout(p=0.2, inplace=False)\n",
       "      (18): Linear(in_features=48, out_features=74, bias=True)\n",
       "      (19): LeakyReLU(negative_slope=0.01)\n",
       "      (20): Dropout(p=0.2, inplace=False)\n",
       "      (21): Linear(in_features=74, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [67, 478, 317, 181, 124, 48, 74],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0019355359156039576,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.7371425032615662,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.7311020493507385,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 352: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=303, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=303, out_features=116, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=116, out_features=134, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=134, out_features=441, bias=True)\n",
       "      (10): Sigmoid()\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=441, out_features=205, bias=True)\n",
       "      (13): Sigmoid()\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=205, out_features=96, bias=True)\n",
       "      (16): Sigmoid()\n",
       "      (17): Dropout(p=0.5, inplace=False)\n",
       "      (18): Linear(in_features=96, out_features=170, bias=True)\n",
       "      (19): Sigmoid()\n",
       "      (20): Dropout(p=0.5, inplace=False)\n",
       "      (21): Linear(in_features=170, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [303, 116, 134, 441, 205, 96, 170],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.005086702852120283,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.7809552550315857,\n",
       "  'train_acc': 0.40625,\n",
       "  'val_loss': 0.7313144207000732,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 353: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=431, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=431, out_features=22, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=22, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [431, 22],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.00807676208425153,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.7268178462982178,\n",
       "  'train_acc': 0.4270833333333333,\n",
       "  'val_loss': 0.7072481513023376,\n",
       "  'val_acc': 0.3541666666666667},\n",
       " 354: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=181, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=181, out_features=507, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=507, out_features=121, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=121, out_features=234, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=234, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [181, 507, 121, 234],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.006438682043980748,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.6934568881988525,\n",
       "  'train_acc': 0.5026041666666666,\n",
       "  'val_loss': 0.626695454120636,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 355: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=333, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=333, out_features=75, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=75, out_features=248, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=248, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [333, 75, 248],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.007122599806774501,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.6890726089477539,\n",
       "  'train_acc': 0.5625,\n",
       "  'val_loss': 0.7510890960693359,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 356: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=495, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=495, out_features=174, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=174, out_features=34, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=34, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [495, 174, 34],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.00800895857815561,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.6704569458961487,\n",
       "  'train_acc': 0.6692708333333334,\n",
       "  'val_loss': 0.6662976145744324,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 357: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=415, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=415, out_features=43, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=43, out_features=455, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=455, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [415, 43, 455],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.00541618335711378,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.7111788392066956,\n",
       "  'train_acc': 0.3723958333333333,\n",
       "  'val_loss': 0.7098575234413147,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 358: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=28, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=28, out_features=16, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=16, out_features=208, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=208, out_features=409, bias=True)\n",
       "      (10): Sigmoid()\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=409, out_features=305, bias=True)\n",
       "      (13): Sigmoid()\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=305, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [28, 16, 208, 409, 305],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.005845961812016052,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.7379271388053894,\n",
       "  'train_acc': 0.4557291666666667,\n",
       "  'val_loss': 0.6806513667106628,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 359: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=235, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=235, out_features=323, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=323, out_features=486, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=486, out_features=23, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=23, out_features=80, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=80, out_features=29, bias=True)\n",
       "      (16): ReLU()\n",
       "      (17): Dropout(p=0.5, inplace=False)\n",
       "      (18): Linear(in_features=29, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [235, 323, 486, 23, 80, 29],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.00551478941400921,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.7165647149085999,\n",
       "  'train_acc': 0.3515625,\n",
       "  'val_loss': 0.7142133712768555,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 360: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=36, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=36, out_features=155, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=155, out_features=451, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=451, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [36, 155, 451],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.006758395174683411,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.6757492423057556,\n",
       "  'train_acc': 0.6484375,\n",
       "  'val_loss': 0.7023372650146484,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 361: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=404, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=404, out_features=15, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=15, out_features=82, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=82, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [404, 15, 82],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.004069593085466351,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.7984857559204102,\n",
       "  'train_acc': 0.3828125,\n",
       "  'val_loss': 0.7713741660118103,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 362: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=483, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=483, out_features=296, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=296, out_features=16, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=16, out_features=137, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=137, out_features=153, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=153, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [483, 296, 16, 137, 153],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.007613897197885949,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.6879693865776062,\n",
       "  'train_acc': 0.5598958333333334,\n",
       "  'val_loss': 0.6831923127174377,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 363: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=432, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=432, out_features=212, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=212, out_features=103, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=103, out_features=298, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=298, out_features=227, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=227, out_features=284, bias=True)\n",
       "      (16): LeakyReLU(negative_slope=0.01)\n",
       "      (17): Dropout(p=0.5, inplace=False)\n",
       "      (18): Linear(in_features=284, out_features=326, bias=True)\n",
       "      (19): LeakyReLU(negative_slope=0.01)\n",
       "      (20): Dropout(p=0.5, inplace=False)\n",
       "      (21): Linear(in_features=326, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [432, 212, 103, 298, 227, 284, 326],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.009706131537609582,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.6980579495429993,\n",
       "  'train_acc': 0.40625,\n",
       "  'val_loss': 0.6980457305908203,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 364: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=81, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=81, out_features=200, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=200, out_features=264, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=264, out_features=373, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=373, out_features=400, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.2, inplace=False)\n",
       "      (15): Linear(in_features=400, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [81, 200, 264, 373, 400],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0032743129740533793,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.6997196674346924,\n",
       "  'train_acc': 0.3489583333333333,\n",
       "  'val_loss': 0.6974024772644043,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 365: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=215, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=215, out_features=199, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=199, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [215, 199],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.008074414638374928,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.6960307955741882,\n",
       "  'train_acc': 0.4765625,\n",
       "  'val_loss': 0.6818068623542786,\n",
       "  'val_acc': 0.5625},\n",
       " 366: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=311, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=311, out_features=382, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=382, out_features=205, bias=True)\n",
       "      (5): LeakyReLU(negative_slope=0.01)\n",
       "      (6): Linear(in_features=205, out_features=423, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Linear(in_features=423, out_features=195, bias=True)\n",
       "      (9): LeakyReLU(negative_slope=0.01)\n",
       "      (10): Linear(in_features=195, out_features=232, bias=True)\n",
       "      (11): LeakyReLU(negative_slope=0.01)\n",
       "      (12): Linear(in_features=232, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [311, 382, 205, 423, 195, 232],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.006395906343868587,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.6953279376029968,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.6339136362075806,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 367: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=70, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=70, out_features=472, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=472, out_features=136, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=136, out_features=462, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=462, out_features=72, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.2, inplace=False)\n",
       "      (15): Linear(in_features=72, out_features=385, bias=True)\n",
       "      (16): LeakyReLU(negative_slope=0.01)\n",
       "      (17): Dropout(p=0.2, inplace=False)\n",
       "      (18): Linear(in_features=385, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [70, 472, 136, 462, 72, 385],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.006384389594517104,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.6895394921302795,\n",
       "  'train_acc': 0.609375,\n",
       "  'val_loss': 0.6311888098716736,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 368: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=456, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=456, out_features=231, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=231, out_features=154, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=154, out_features=182, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=182, out_features=223, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=223, out_features=347, bias=True)\n",
       "      (16): ReLU()\n",
       "      (17): Dropout(p=0.5, inplace=False)\n",
       "      (18): Linear(in_features=347, out_features=225, bias=True)\n",
       "      (19): ReLU()\n",
       "      (20): Dropout(p=0.5, inplace=False)\n",
       "      (21): Linear(in_features=225, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [456, 231, 154, 182, 223, 347, 225],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0016367703372715389,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.6935212016105652,\n",
       "  'train_acc': 0.5130208333333334,\n",
       "  'val_loss': 0.6953305602073669,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 369: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=315, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=315, out_features=227, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=227, out_features=296, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=296, out_features=60, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=60, out_features=17, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.2, inplace=False)\n",
       "      (15): Linear(in_features=17, out_features=232, bias=True)\n",
       "      (16): ReLU()\n",
       "      (17): Dropout(p=0.2, inplace=False)\n",
       "      (18): Linear(in_features=232, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [315, 227, 296, 60, 17, 232],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.008713964680696289,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.726162850856781,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.6599476933479309,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 370: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=127, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=127, out_features=501, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=501, out_features=445, bias=True)\n",
       "      (5): LeakyReLU(negative_slope=0.01)\n",
       "      (6): Linear(in_features=445, out_features=255, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Linear(in_features=255, out_features=228, bias=True)\n",
       "      (9): LeakyReLU(negative_slope=0.01)\n",
       "      (10): Linear(in_features=228, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [127, 501, 445, 255, 228],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0062166845952021255,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.6892246603965759,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.8931543827056885,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 371: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=264, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Linear(in_features=264, out_features=291, bias=True)\n",
       "      (3): Sigmoid()\n",
       "      (4): Linear(in_features=291, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [264, 291],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0036820242096273657,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.764605700969696,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.7844666838645935,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 372: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=270, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=270, out_features=258, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=258, out_features=157, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=157, out_features=426, bias=True)\n",
       "      (10): Sigmoid()\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=426, out_features=62, bias=True)\n",
       "      (13): Sigmoid()\n",
       "      (14): Dropout(p=0.2, inplace=False)\n",
       "      (15): Linear(in_features=62, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [270, 258, 157, 426, 62],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.006399997196670708,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.6480215191841125,\n",
       "  'train_acc': 0.6536458333333334,\n",
       "  'val_loss': 0.8812113404273987,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 373: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=506, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=506, out_features=24, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=24, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [506, 24],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.007020555275965675,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.6770937442779541,\n",
       "  'train_acc': 0.5885416666666666,\n",
       "  'val_loss': 0.7848308086395264,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 374: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=394, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Linear(in_features=394, out_features=30, bias=True)\n",
       "      (3): Sigmoid()\n",
       "      (4): Linear(in_features=30, out_features=264, bias=True)\n",
       "      (5): Sigmoid()\n",
       "      (6): Linear(in_features=264, out_features=430, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Linear(in_features=430, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [394, 30, 264, 430],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.004494611724075026,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.7993965148925781,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.7343201637268066,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 375: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=318, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=318, out_features=164, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=164, out_features=75, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=75, out_features=109, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=109, out_features=105, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.1, inplace=False)\n",
       "      (15): Linear(in_features=105, out_features=375, bias=True)\n",
       "      (16): ReLU()\n",
       "      (17): Dropout(p=0.1, inplace=False)\n",
       "      (18): Linear(in_features=375, out_features=140, bias=True)\n",
       "      (19): ReLU()\n",
       "      (20): Dropout(p=0.1, inplace=False)\n",
       "      (21): Linear(in_features=140, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [318, 164, 75, 109, 105, 375, 140],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.006569616276149557,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.6824234127998352,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.6807019114494324,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 376: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=294, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=294, out_features=248, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=248, out_features=427, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=427, out_features=168, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=168, out_features=264, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.2, inplace=False)\n",
       "      (15): Linear(in_features=264, out_features=72, bias=True)\n",
       "      (16): LeakyReLU(negative_slope=0.01)\n",
       "      (17): Dropout(p=0.2, inplace=False)\n",
       "      (18): Linear(in_features=72, out_features=28, bias=True)\n",
       "      (19): LeakyReLU(negative_slope=0.01)\n",
       "      (20): Dropout(p=0.2, inplace=False)\n",
       "      (21): Linear(in_features=28, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [294, 248, 427, 168, 264, 72, 28],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0033676193269619624,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.6955714821815491,\n",
       "  'train_acc': 0.3802083333333333,\n",
       "  'val_loss': 0.6836824417114258,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 377: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=384, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Linear(in_features=384, out_features=160, bias=True)\n",
       "      (3): Sigmoid()\n",
       "      (4): Linear(in_features=160, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [384, 160],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.005847439176550698,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.6957292556762695,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.6818169951438904,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 378: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=209, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=209, out_features=247, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=247, out_features=222, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=222, out_features=465, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=465, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [209, 247, 222, 465],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0015423383896820148,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.6997196674346924,\n",
       "  'train_acc': 0.3697916666666667,\n",
       "  'val_loss': 0.7006773948669434,\n",
       "  'val_acc': 0.3333333333333333},\n",
       " 379: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=164, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=164, out_features=335, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=335, out_features=501, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=501, out_features=497, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=497, out_features=390, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=390, out_features=488, bias=True)\n",
       "      (16): LeakyReLU(negative_slope=0.01)\n",
       "      (17): Dropout(p=0.5, inplace=False)\n",
       "      (18): Linear(in_features=488, out_features=379, bias=True)\n",
       "      (19): LeakyReLU(negative_slope=0.01)\n",
       "      (20): Dropout(p=0.5, inplace=False)\n",
       "      (21): Linear(in_features=379, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [164, 335, 501, 497, 390, 488, 379],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.009580425763414734,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.6911408305168152,\n",
       "  'train_acc': 0.5442708333333334,\n",
       "  'val_loss': 0.6895686984062195,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 380: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=278, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=278, out_features=171, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=171, out_features=162, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=162, out_features=75, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=75, out_features=110, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.1, inplace=False)\n",
       "      (15): Linear(in_features=110, out_features=330, bias=True)\n",
       "      (16): ReLU()\n",
       "      (17): Dropout(p=0.1, inplace=False)\n",
       "      (18): Linear(in_features=330, out_features=134, bias=True)\n",
       "      (19): ReLU()\n",
       "      (20): Dropout(p=0.1, inplace=False)\n",
       "      (21): Linear(in_features=134, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [278, 171, 162, 75, 110, 330, 134],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.003054781833927868,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.6983261704444885,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.698911190032959,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 381: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=169, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=169, out_features=460, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=460, out_features=240, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=240, out_features=231, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=231, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [169, 460, 240, 231],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0023572291431022538,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.6877622008323669,\n",
       "  'train_acc': 0.6484375,\n",
       "  'val_loss': 0.6355056762695312,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 382: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=227, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=227, out_features=73, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=73, out_features=465, bias=True)\n",
       "      (5): LeakyReLU(negative_slope=0.01)\n",
       "      (6): Linear(in_features=465, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [227, 73, 465],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.005026013523661099,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.6829875111579895,\n",
       "  'train_acc': 0.6510416666666666,\n",
       "  'val_loss': 0.6377162337303162,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 383: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=208, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=208, out_features=198, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=198, out_features=16, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=16, out_features=74, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=74, out_features=238, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=238, out_features=341, bias=True)\n",
       "      (16): ReLU()\n",
       "      (17): Dropout(p=0.5, inplace=False)\n",
       "      (18): Linear(in_features=341, out_features=138, bias=True)\n",
       "      (19): ReLU()\n",
       "      (20): Dropout(p=0.5, inplace=False)\n",
       "      (21): Linear(in_features=138, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [208, 198, 16, 74, 238, 341, 138],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0016369060548635825,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.7229921817779541,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.7247968316078186,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 384: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=274, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Linear(in_features=274, out_features=198, bias=True)\n",
       "      (3): Sigmoid()\n",
       "      (4): Linear(in_features=198, out_features=388, bias=True)\n",
       "      (5): Sigmoid()\n",
       "      (6): Linear(in_features=388, out_features=445, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Linear(in_features=445, out_features=71, bias=True)\n",
       "      (9): Sigmoid()\n",
       "      (10): Linear(in_features=71, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [274, 198, 388, 445, 71],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.008354122676286421,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.6950344443321228,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.6848731637001038,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 385: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=301, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=301, out_features=464, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=464, out_features=126, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=126, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [301, 464, 126],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.004251285088481414,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.6801372170448303,\n",
       "  'train_acc': 0.6640625,\n",
       "  'val_loss': 0.6795787215232849,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 386: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=37, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=37, out_features=402, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=402, out_features=58, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=58, out_features=186, bias=True)\n",
       "      (10): Sigmoid()\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=186, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [37, 402, 58, 186],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.008009726922929662,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.8211729526519775,\n",
       "  'train_acc': 0.390625,\n",
       "  'val_loss': 0.7664597630500793,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 387: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=29, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Linear(in_features=29, out_features=389, bias=True)\n",
       "      (3): Sigmoid()\n",
       "      (4): Linear(in_features=389, out_features=56, bias=True)\n",
       "      (5): Sigmoid()\n",
       "      (6): Linear(in_features=56, out_features=64, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Linear(in_features=64, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [29, 389, 56, 64],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.002144317364893075,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.7062838077545166,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.7050570845603943,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 388: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=486, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=486, out_features=140, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=140, out_features=63, bias=True)\n",
       "      (5): LeakyReLU(negative_slope=0.01)\n",
       "      (6): Linear(in_features=63, out_features=322, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Linear(in_features=322, out_features=55, bias=True)\n",
       "      (9): LeakyReLU(negative_slope=0.01)\n",
       "      (10): Linear(in_features=55, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [486, 140, 63, 322, 55],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.006187683153669393,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.7065091133117676,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.6475211977958679,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 389: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=371, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=371, out_features=473, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=473, out_features=138, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=138, out_features=40, bias=True)\n",
       "      (10): Sigmoid()\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=40, out_features=503, bias=True)\n",
       "      (13): Sigmoid()\n",
       "      (14): Dropout(p=0.1, inplace=False)\n",
       "      (15): Linear(in_features=503, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [371, 473, 138, 40, 503],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.006258479868058286,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.7166457772254944,\n",
       "  'train_acc': 0.3958333333333333,\n",
       "  'val_loss': 0.6607186198234558,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 390: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=447, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=447, out_features=497, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=497, out_features=38, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=38, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [447, 497, 38],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0020165131004487944,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.7424315810203552,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.655849039554596,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 391: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=360, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=360, out_features=96, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=96, out_features=148, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=148, out_features=390, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=390, out_features=176, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.2, inplace=False)\n",
       "      (15): Linear(in_features=176, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [360, 96, 148, 390, 176],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.007686852089055327,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.6791338324546814,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.80629563331604,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 392: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=197, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=197, out_features=368, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=368, out_features=210, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=210, out_features=365, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=365, out_features=484, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.2, inplace=False)\n",
       "      (15): Linear(in_features=484, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [197, 368, 210, 365, 484],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0010126251091701977,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.7033799290657043,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.7033913135528564,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 393: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=506, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=506, out_features=50, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=50, out_features=209, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=209, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [506, 50, 209],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.006763377742326873,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.713076114654541,\n",
       "  'train_acc': 0.3541666666666667,\n",
       "  'val_loss': 0.7127527594566345,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 394: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=163, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=163, out_features=126, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=126, out_features=220, bias=True)\n",
       "      (5): LeakyReLU(negative_slope=0.01)\n",
       "      (6): Linear(in_features=220, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [163, 126, 220],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.005812156202105609,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.6879744529724121,\n",
       "  'train_acc': 0.5989583333333334,\n",
       "  'val_loss': 0.6864107251167297,\n",
       "  'val_acc': 0.6354166666666666},\n",
       " 395: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=237, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=237, out_features=453, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=453, out_features=396, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=396, out_features=18, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=18, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [237, 453, 396, 18],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.008103180330833782,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.6633116006851196,\n",
       "  'train_acc': 0.6536458333333334,\n",
       "  'val_loss': 0.6616274118423462,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 396: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=107, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=107, out_features=76, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=76, out_features=477, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=477, out_features=114, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=114, out_features=290, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.2, inplace=False)\n",
       "      (15): Linear(in_features=290, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [107, 76, 477, 114, 290],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.008056271344097995,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.6871331334114075,\n",
       "  'train_acc': 0.6197916666666666,\n",
       "  'val_loss': 0.6670851111412048,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 397: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=457, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Linear(in_features=457, out_features=455, bias=True)\n",
       "      (3): Sigmoid()\n",
       "      (4): Linear(in_features=455, out_features=58, bias=True)\n",
       "      (5): Sigmoid()\n",
       "      (6): Linear(in_features=58, out_features=113, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Linear(in_features=113, out_features=344, bias=True)\n",
       "      (9): Sigmoid()\n",
       "      (10): Linear(in_features=344, out_features=464, bias=True)\n",
       "      (11): Sigmoid()\n",
       "      (12): Linear(in_features=464, out_features=150, bias=True)\n",
       "      (13): Sigmoid()\n",
       "      (14): Linear(in_features=150, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [457, 455, 58, 113, 344, 464, 150],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.008196535546516004,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.6669014096260071,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.6546381711959839,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 398: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=504, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=504, out_features=320, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=320, out_features=80, bias=True)\n",
       "      (5): LeakyReLU(negative_slope=0.01)\n",
       "      (6): Linear(in_features=80, out_features=213, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Linear(in_features=213, out_features=375, bias=True)\n",
       "      (9): LeakyReLU(negative_slope=0.01)\n",
       "      (10): Linear(in_features=375, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [504, 320, 80, 213, 375],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.009874092404247133,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.7021527290344238,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.701651394367218,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 399: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=173, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=173, out_features=283, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=283, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [173, 283],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.002533296633860407,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.6982114911079407,\n",
       "  'train_acc': 0.46875,\n",
       "  'val_loss': 0.6265677809715271,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 400: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=191, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=191, out_features=191, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=191, out_features=391, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=391, out_features=119, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=119, out_features=308, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.1, inplace=False)\n",
       "      (15): Linear(in_features=308, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [191, 191, 391, 119, 308],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.008149020017315378,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.6910275816917419,\n",
       "  'train_acc': 0.6380208333333334,\n",
       "  'val_loss': 0.6906996369361877,\n",
       "  'val_acc': 0.6666666666666666},\n",
       " 401: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=194, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=194, out_features=494, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=494, out_features=187, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=187, out_features=491, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=491, out_features=366, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.2, inplace=False)\n",
       "      (15): Linear(in_features=366, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [194, 494, 187, 491, 366],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.00418449297015379,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.6909072399139404,\n",
       "  'train_acc': 0.5989583333333334,\n",
       "  'val_loss': 0.6320841908454895,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 402: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=103, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=103, out_features=198, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=198, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [103, 198],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0027303496218732013,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.6981820464134216,\n",
       "  'train_acc': 0.4973958333333333,\n",
       "  'val_loss': 0.6357874274253845,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 403: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=114, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=114, out_features=195, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=195, out_features=390, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=390, out_features=484, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=484, out_features=389, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.2, inplace=False)\n",
       "      (15): Linear(in_features=389, out_features=210, bias=True)\n",
       "      (16): ReLU()\n",
       "      (17): Dropout(p=0.2, inplace=False)\n",
       "      (18): Linear(in_features=210, out_features=263, bias=True)\n",
       "      (19): ReLU()\n",
       "      (20): Dropout(p=0.2, inplace=False)\n",
       "      (21): Linear(in_features=263, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [114, 195, 390, 484, 389, 210, 263],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0018895473055005338,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.698891818523407,\n",
       "  'train_acc': 0.34375,\n",
       "  'val_loss': 0.6791115403175354,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 404: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=274, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=274, out_features=193, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=193, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [274, 193],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.00872898400438008,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.7141988277435303,\n",
       "  'train_acc': 0.3958333333333333,\n",
       "  'val_loss': 0.7074851989746094,\n",
       "  'val_acc': 0.4166666666666667},\n",
       " 405: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=369, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=369, out_features=446, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=446, out_features=226, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=226, out_features=436, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=436, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [369, 446, 226, 436],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0032439297187134655,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.709952175617218,\n",
       "  'train_acc': 0.3932291666666667,\n",
       "  'val_loss': 0.700442373752594,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 406: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=392, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=392, out_features=285, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=285, out_features=311, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=311, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [392, 285, 311],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.004434962033783091,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.7905721068382263,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.7478027939796448,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 407: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=329, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=329, out_features=120, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=120, out_features=414, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=414, out_features=63, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=63, out_features=360, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.1, inplace=False)\n",
       "      (15): Linear(in_features=360, out_features=225, bias=True)\n",
       "      (16): ReLU()\n",
       "      (17): Dropout(p=0.1, inplace=False)\n",
       "      (18): Linear(in_features=225, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [329, 120, 414, 63, 360, 225],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0038468361620814526,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.700429379940033,\n",
       "  'train_acc': 0.34375,\n",
       "  'val_loss': 0.6297461986541748,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 408: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=477, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Linear(in_features=477, out_features=181, bias=True)\n",
       "      (3): Sigmoid()\n",
       "      (4): Linear(in_features=181, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [477, 181],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.003757961137522447,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.655815839767456,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.6483469009399414,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 409: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=355, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=355, out_features=394, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=394, out_features=279, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=279, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [355, 394, 279],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.004305528394685693,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.7020292282104492,\n",
       "  'train_acc': 0.4739583333333333,\n",
       "  'val_loss': 0.6830406785011292,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 410: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=115, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=115, out_features=467, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=467, out_features=93, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=93, out_features=320, bias=True)\n",
       "      (10): Sigmoid()\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=320, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [115, 467, 93, 320],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0026829547893996216,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.692991316318512,\n",
       "  'train_acc': 0.5416666666666666,\n",
       "  'val_loss': 0.6812613606452942,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 411: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=293, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=293, out_features=181, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=181, out_features=124, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=124, out_features=63, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=63, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [293, 181, 124, 63],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.005932417988967481,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.679988443851471,\n",
       "  'train_acc': 0.59375,\n",
       "  'val_loss': 0.675825297832489,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 412: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=368, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=368, out_features=193, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=193, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [368, 193],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0049487817278864405,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.7390942573547363,\n",
       "  'train_acc': 0.3697916666666667,\n",
       "  'val_loss': 0.8482159972190857,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 413: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=49, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=49, out_features=263, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=263, out_features=296, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=296, out_features=186, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=186, out_features=421, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.2, inplace=False)\n",
       "      (15): Linear(in_features=421, out_features=189, bias=True)\n",
       "      (16): LeakyReLU(negative_slope=0.01)\n",
       "      (17): Dropout(p=0.2, inplace=False)\n",
       "      (18): Linear(in_features=189, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [49, 263, 296, 186, 421, 189],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.004975211869677698,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.6845610737800598,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.6304657459259033,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 414: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=281, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=281, out_features=347, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=347, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [281, 347],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.006012095051367325,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.6756882071495056,\n",
       "  'train_acc': 0.5651041666666666,\n",
       "  'val_loss': 0.89310222864151,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 415: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=140, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=140, out_features=189, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=189, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [140, 189],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.004335657527613169,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.6806695461273193,\n",
       "  'train_acc': 0.5546875,\n",
       "  'val_loss': 0.6505841612815857,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 416: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=433, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Linear(in_features=433, out_features=258, bias=True)\n",
       "      (3): Sigmoid()\n",
       "      (4): Linear(in_features=258, out_features=245, bias=True)\n",
       "      (5): Sigmoid()\n",
       "      (6): Linear(in_features=245, out_features=312, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Linear(in_features=312, out_features=163, bias=True)\n",
       "      (9): Sigmoid()\n",
       "      (10): Linear(in_features=163, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [433, 258, 245, 312, 163],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.007045198976798121,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.6538046002388,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.6436712741851807,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 417: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=86, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=86, out_features=429, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=429, out_features=129, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=129, out_features=409, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=409, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [86, 429, 129, 409],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.005976769688900327,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.6840200424194336,\n",
       "  'train_acc': 0.6354166666666666,\n",
       "  'val_loss': 0.6565301418304443,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 418: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=21, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=21, out_features=450, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=450, out_features=275, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=275, out_features=201, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=201, out_features=418, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.1, inplace=False)\n",
       "      (15): Linear(in_features=418, out_features=316, bias=True)\n",
       "      (16): LeakyReLU(negative_slope=0.01)\n",
       "      (17): Dropout(p=0.1, inplace=False)\n",
       "      (18): Linear(in_features=316, out_features=191, bias=True)\n",
       "      (19): LeakyReLU(negative_slope=0.01)\n",
       "      (20): Dropout(p=0.1, inplace=False)\n",
       "      (21): Linear(in_features=191, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [21, 450, 275, 201, 418, 316, 191],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0057268172514121155,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.6921069622039795,\n",
       "  'train_acc': 0.6119791666666666,\n",
       "  'val_loss': 0.6314598917961121,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 419: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=338, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=338, out_features=488, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=488, out_features=312, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=312, out_features=27, bias=True)\n",
       "      (10): Sigmoid()\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=27, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [338, 488, 312, 27],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.005197694279373283,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.6610318422317505,\n",
       "  'train_acc': 0.6458333333333334,\n",
       "  'val_loss': 0.6691608428955078,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 420: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=459, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=459, out_features=71, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=71, out_features=140, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=140, out_features=329, bias=True)\n",
       "      (10): Sigmoid()\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=329, out_features=65, bias=True)\n",
       "      (13): Sigmoid()\n",
       "      (14): Dropout(p=0.1, inplace=False)\n",
       "      (15): Linear(in_features=65, out_features=163, bias=True)\n",
       "      (16): Sigmoid()\n",
       "      (17): Dropout(p=0.1, inplace=False)\n",
       "      (18): Linear(in_features=163, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [459, 71, 140, 329, 65, 163],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.007197825082529996,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.8037849068641663,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.7676159739494324,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 421: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=248, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=248, out_features=186, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=186, out_features=288, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=288, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [248, 186, 288],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.004497886185905527,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.6847710609436035,\n",
       "  'train_acc': 0.5442708333333334,\n",
       "  'val_loss': 0.6321433186531067,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 422: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=292, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=292, out_features=53, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=53, out_features=478, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=478, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [292, 53, 478],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.003796188621790586,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.6820922493934631,\n",
       "  'train_acc': 0.5729166666666666,\n",
       "  'val_loss': 0.6560366749763489,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 423: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=304, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=304, out_features=365, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=365, out_features=305, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=305, out_features=506, bias=True)\n",
       "      (10): Sigmoid()\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=506, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [304, 365, 305, 506],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.008838755233345607,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.6777986884117126,\n",
       "  'train_acc': 0.6119791666666666,\n",
       "  'val_loss': 0.6396840214729309,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 424: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=228, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=228, out_features=115, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=115, out_features=466, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=466, out_features=125, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=125, out_features=424, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=424, out_features=471, bias=True)\n",
       "      (16): LeakyReLU(negative_slope=0.01)\n",
       "      (17): Dropout(p=0.5, inplace=False)\n",
       "      (18): Linear(in_features=471, out_features=329, bias=True)\n",
       "      (19): LeakyReLU(negative_slope=0.01)\n",
       "      (20): Dropout(p=0.5, inplace=False)\n",
       "      (21): Linear(in_features=329, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [228, 115, 466, 125, 424, 471, 329],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.008928587726841991,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.6862843632698059,\n",
       "  'train_acc': 0.6432291666666666,\n",
       "  'val_loss': 0.6848700046539307,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 425: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=308, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=308, out_features=173, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=173, out_features=443, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=443, out_features=204, bias=True)\n",
       "      (10): Sigmoid()\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=204, out_features=414, bias=True)\n",
       "      (13): Sigmoid()\n",
       "      (14): Dropout(p=0.2, inplace=False)\n",
       "      (15): Linear(in_features=414, out_features=412, bias=True)\n",
       "      (16): Sigmoid()\n",
       "      (17): Dropout(p=0.2, inplace=False)\n",
       "      (18): Linear(in_features=412, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [308, 173, 443, 204, 414, 412],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0025840898158432644,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.9548593163490295,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.7575806975364685,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 426: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=471, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=471, out_features=14, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=14, out_features=223, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=223, out_features=347, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=347, out_features=344, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=344, out_features=179, bias=True)\n",
       "      (16): ReLU()\n",
       "      (17): Dropout(p=0.5, inplace=False)\n",
       "      (18): Linear(in_features=179, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [471, 14, 223, 347, 344, 179],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.00786649013661558,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.6897805333137512,\n",
       "  'train_acc': 0.5833333333333334,\n",
       "  'val_loss': 0.6852150559425354,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 427: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=129, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=129, out_features=292, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=292, out_features=66, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=66, out_features=189, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=189, out_features=420, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.2, inplace=False)\n",
       "      (15): Linear(in_features=420, out_features=269, bias=True)\n",
       "      (16): LeakyReLU(negative_slope=0.01)\n",
       "      (17): Dropout(p=0.2, inplace=False)\n",
       "      (18): Linear(in_features=269, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [129, 292, 66, 189, 420, 269],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.008688252505731745,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.6814698576927185,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.6795170903205872,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 428: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=243, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=243, out_features=498, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=498, out_features=498, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=498, out_features=193, bias=True)\n",
       "      (10): Sigmoid()\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=193, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [243, 498, 498, 193],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.003098646105373154,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.6599023342132568,\n",
       "  'train_acc': 0.6614583333333334,\n",
       "  'val_loss': 0.6574761271476746,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 429: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=51, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=51, out_features=101, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=101, out_features=315, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=315, out_features=382, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=382, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [51, 101, 315, 382],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.002203025768077322,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.6815814971923828,\n",
       "  'train_acc': 0.6015625,\n",
       "  'val_loss': 0.6505454182624817,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 430: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=43, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=43, out_features=363, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=363, out_features=272, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=272, out_features=16, bias=True)\n",
       "      (10): Sigmoid()\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=16, out_features=35, bias=True)\n",
       "      (13): Sigmoid()\n",
       "      (14): Dropout(p=0.1, inplace=False)\n",
       "      (15): Linear(in_features=35, out_features=177, bias=True)\n",
       "      (16): Sigmoid()\n",
       "      (17): Dropout(p=0.1, inplace=False)\n",
       "      (18): Linear(in_features=177, out_features=33, bias=True)\n",
       "      (19): Sigmoid()\n",
       "      (20): Dropout(p=0.1, inplace=False)\n",
       "      (21): Linear(in_features=33, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [43, 363, 272, 16, 35, 177, 33],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.009096097173661086,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.6495524644851685,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.6370081901550293,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 431: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=376, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=376, out_features=316, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=316, out_features=198, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=198, out_features=46, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=46, out_features=503, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.1, inplace=False)\n",
       "      (15): Linear(in_features=503, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [376, 316, 198, 46, 503],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0025465667074752274,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.6866669654846191,\n",
       "  'train_acc': 0.6432291666666666,\n",
       "  'val_loss': 0.6861174702644348,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 432: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=135, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=135, out_features=242, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=242, out_features=401, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=401, out_features=306, bias=True)\n",
       "      (10): Sigmoid()\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=306, out_features=150, bias=True)\n",
       "      (13): Sigmoid()\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=150, out_features=246, bias=True)\n",
       "      (16): Sigmoid()\n",
       "      (17): Dropout(p=0.5, inplace=False)\n",
       "      (18): Linear(in_features=246, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [135, 242, 401, 306, 150, 246],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.003179627764645555,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.8939042091369629,\n",
       "  'train_acc': 0.3619791666666667,\n",
       "  'val_loss': 0.6303725838661194,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 433: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=420, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=420, out_features=161, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=161, out_features=97, bias=True)\n",
       "      (5): LeakyReLU(negative_slope=0.01)\n",
       "      (6): Linear(in_features=97, out_features=249, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Linear(in_features=249, out_features=211, bias=True)\n",
       "      (9): LeakyReLU(negative_slope=0.01)\n",
       "      (10): Linear(in_features=211, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [420, 161, 97, 249, 211],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.004641315608333278,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.683129072189331,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.6251086592674255,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 434: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=388, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=388, out_features=420, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=420, out_features=67, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=67, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [388, 420, 67],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.00851457817995624,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.7477990984916687,\n",
       "  'train_acc': 0.3541666666666667,\n",
       "  'val_loss': 0.7355772852897644,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 435: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=429, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=429, out_features=237, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=237, out_features=87, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=87, out_features=220, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=220, out_features=417, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=417, out_features=278, bias=True)\n",
       "      (16): ReLU()\n",
       "      (17): Dropout(p=0.5, inplace=False)\n",
       "      (18): Linear(in_features=278, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [429, 237, 87, 220, 417, 278],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.004055746472455072,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.6961965560913086,\n",
       "  'train_acc': 0.4348958333333333,\n",
       "  'val_loss': 0.6951500773429871,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 436: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=67, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Linear(in_features=67, out_features=336, bias=True)\n",
       "      (3): Sigmoid()\n",
       "      (4): Linear(in_features=336, out_features=204, bias=True)\n",
       "      (5): Sigmoid()\n",
       "      (6): Linear(in_features=204, out_features=469, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Linear(in_features=469, out_features=475, bias=True)\n",
       "      (9): Sigmoid()\n",
       "      (10): Linear(in_features=475, out_features=96, bias=True)\n",
       "      (11): Sigmoid()\n",
       "      (12): Linear(in_features=96, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [67, 336, 204, 469, 475, 96],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.005475375924483442,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.7286381721496582,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.9059470295906067,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 437: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=431, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=431, out_features=402, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=402, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [431, 402],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0035593416580177316,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.7011911273002625,\n",
       "  'train_acc': 0.4817708333333333,\n",
       "  'val_loss': 0.7004089951515198,\n",
       "  'val_acc': 0.4895833333333333},\n",
       " 438: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=261, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=261, out_features=115, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=115, out_features=345, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=345, out_features=266, bias=True)\n",
       "      (10): Sigmoid()\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=266, out_features=99, bias=True)\n",
       "      (13): Sigmoid()\n",
       "      (14): Dropout(p=0.2, inplace=False)\n",
       "      (15): Linear(in_features=99, out_features=135, bias=True)\n",
       "      (16): Sigmoid()\n",
       "      (17): Dropout(p=0.2, inplace=False)\n",
       "      (18): Linear(in_features=135, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [261, 115, 345, 266, 99, 135],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.001450624952770918,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.7062650322914124,\n",
       "  'train_acc': 0.4895833333333333,\n",
       "  'val_loss': 0.6459831595420837,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 439: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=108, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=108, out_features=90, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=90, out_features=56, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=56, out_features=104, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=104, out_features=185, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=185, out_features=17, bias=True)\n",
       "      (16): ReLU()\n",
       "      (17): Dropout(p=0.5, inplace=False)\n",
       "      (18): Linear(in_features=17, out_features=203, bias=True)\n",
       "      (19): ReLU()\n",
       "      (20): Dropout(p=0.5, inplace=False)\n",
       "      (21): Linear(in_features=203, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [108, 90, 56, 104, 185, 17, 203],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.009744418151113782,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.6964747309684753,\n",
       "  'train_acc': 0.453125,\n",
       "  'val_loss': 0.6482468247413635,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 440: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=69, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=69, out_features=125, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=125, out_features=134, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=134, out_features=164, bias=True)\n",
       "      (10): Sigmoid()\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=164, out_features=37, bias=True)\n",
       "      (13): Sigmoid()\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=37, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [69, 125, 134, 164, 37],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.007049491987149305,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.7990595698356628,\n",
       "  'train_acc': 0.3854166666666667,\n",
       "  'val_loss': 0.6293911933898926,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 441: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=193, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=193, out_features=218, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=218, out_features=367, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=367, out_features=124, bias=True)\n",
       "      (10): Sigmoid()\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=124, out_features=156, bias=True)\n",
       "      (13): Sigmoid()\n",
       "      (14): Dropout(p=0.2, inplace=False)\n",
       "      (15): Linear(in_features=156, out_features=364, bias=True)\n",
       "      (16): Sigmoid()\n",
       "      (17): Dropout(p=0.2, inplace=False)\n",
       "      (18): Linear(in_features=364, out_features=100, bias=True)\n",
       "      (19): Sigmoid()\n",
       "      (20): Dropout(p=0.2, inplace=False)\n",
       "      (21): Linear(in_features=100, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [193, 218, 367, 124, 156, 364, 100],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.005084378120852703,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.7752079367637634,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.7562652230262756,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 442: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=211, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=211, out_features=70, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=70, out_features=260, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=260, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [211, 70, 260],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.004410670925277032,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.7543813586235046,\n",
       "  'train_acc': 0.4453125,\n",
       "  'val_loss': 0.7169031500816345,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 443: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=480, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=480, out_features=468, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=468, out_features=493, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=493, out_features=245, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=245, out_features=384, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.2, inplace=False)\n",
       "      (15): Linear(in_features=384, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [480, 468, 493, 245, 384],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.004269073204618496,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.6920121312141418,\n",
       "  'train_acc': 0.5755208333333334,\n",
       "  'val_loss': 0.6907792687416077,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 444: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=230, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=230, out_features=297, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=297, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [230, 297],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0028070599075748284,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.6599553227424622,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.8955896496772766,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 445: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=203, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=203, out_features=57, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=57, out_features=293, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=293, out_features=426, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=426, out_features=117, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=117, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [203, 57, 293, 426, 117],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.009867664247762378,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.6932553648948669,\n",
       "  'train_acc': 0.4921875,\n",
       "  'val_loss': 0.6931479573249817,\n",
       "  'val_acc': 0.4583333333333333},\n",
       " 446: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=65, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=65, out_features=262, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=262, out_features=134, bias=True)\n",
       "      (5): ReLU()\n",
       "      (6): Linear(in_features=134, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [65, 262, 134],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0046619416340690275,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.7028555870056152,\n",
       "  'train_acc': 0.328125,\n",
       "  'val_loss': 0.6247164607048035,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 447: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=149, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=149, out_features=364, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=364, out_features=369, bias=True)\n",
       "      (5): LeakyReLU(negative_slope=0.01)\n",
       "      (6): Linear(in_features=369, out_features=93, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Linear(in_features=93, out_features=361, bias=True)\n",
       "      (9): LeakyReLU(negative_slope=0.01)\n",
       "      (10): Linear(in_features=361, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [149, 364, 369, 93, 361],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.007893400345662799,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.7059007287025452,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.7061927318572998,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 448: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=42, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=42, out_features=123, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=123, out_features=24, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=24, out_features=356, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=356, out_features=506, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.1, inplace=False)\n",
       "      (15): Linear(in_features=506, out_features=62, bias=True)\n",
       "      (16): ReLU()\n",
       "      (17): Dropout(p=0.1, inplace=False)\n",
       "      (18): Linear(in_features=62, out_features=64, bias=True)\n",
       "      (19): ReLU()\n",
       "      (20): Dropout(p=0.1, inplace=False)\n",
       "      (21): Linear(in_features=64, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [42, 123, 24, 356, 506, 62, 64],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.007128642836411096,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.7254292964935303,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.6938464045524597,\n",
       "  'val_acc': 0.3854166666666667},\n",
       " 449: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=87, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=87, out_features=196, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=196, out_features=279, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=279, out_features=227, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=227, out_features=365, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.1, inplace=False)\n",
       "      (15): Linear(in_features=365, out_features=455, bias=True)\n",
       "      (16): LeakyReLU(negative_slope=0.01)\n",
       "      (17): Dropout(p=0.1, inplace=False)\n",
       "      (18): Linear(in_features=455, out_features=401, bias=True)\n",
       "      (19): LeakyReLU(negative_slope=0.01)\n",
       "      (20): Dropout(p=0.1, inplace=False)\n",
       "      (21): Linear(in_features=401, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [87, 196, 279, 227, 365, 455, 401],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.004008502036988729,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.6859461665153503,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.6845853328704834,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 450: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=131, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=131, out_features=250, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=250, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [131, 250],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0091634212718049,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.6942054629325867,\n",
       "  'train_acc': 0.5286458333333334,\n",
       "  'val_loss': 0.6921555995941162,\n",
       "  'val_acc': 0.5729166666666666},\n",
       " 451: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=22, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=22, out_features=485, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=485, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [22, 485],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.008986492328650366,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.6927608847618103,\n",
       "  'train_acc': 0.4895833333333333,\n",
       "  'val_loss': 0.6992846131324768,\n",
       "  'val_acc': 0.5},\n",
       " 452: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=321, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=321, out_features=128, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=128, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [321, 128],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.009518778445920268,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.7065615653991699,\n",
       "  'train_acc': 0.4427083333333333,\n",
       "  'val_loss': 0.7040812969207764,\n",
       "  'val_acc': 0.4270833333333333},\n",
       " 453: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=148, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=148, out_features=89, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=89, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [148, 89],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.004368767499621432,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.6948090195655823,\n",
       "  'train_acc': 0.5234375,\n",
       "  'val_loss': 0.6885438561439514,\n",
       "  'val_acc': 0.59375},\n",
       " 454: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=49, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=49, out_features=262, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=262, out_features=69, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=69, out_features=176, bias=True)\n",
       "      (10): Sigmoid()\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=176, out_features=95, bias=True)\n",
       "      (13): Sigmoid()\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=95, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [49, 262, 69, 176, 95],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0013877019691811512,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.8183398842811584,\n",
       "  'train_acc': 0.375,\n",
       "  'val_loss': 0.7024800181388855,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 455: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=410, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=410, out_features=358, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=358, out_features=298, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=298, out_features=387, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=387, out_features=324, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.2, inplace=False)\n",
       "      (15): Linear(in_features=324, out_features=87, bias=True)\n",
       "      (16): LeakyReLU(negative_slope=0.01)\n",
       "      (17): Dropout(p=0.2, inplace=False)\n",
       "      (18): Linear(in_features=87, out_features=319, bias=True)\n",
       "      (19): LeakyReLU(negative_slope=0.01)\n",
       "      (20): Dropout(p=0.2, inplace=False)\n",
       "      (21): Linear(in_features=319, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [410, 358, 298, 387, 324, 87, 319],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0044470604256742,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.707960844039917,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.7092271447181702,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 456: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=485, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=485, out_features=319, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=319, out_features=27, bias=True)\n",
       "      (5): ReLU()\n",
       "      (6): Linear(in_features=27, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [485, 319, 27],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.008175144955207658,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.7515029907226562,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.7539482116699219,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 457: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=510, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=510, out_features=269, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=269, out_features=374, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=374, out_features=171, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=171, out_features=368, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.1, inplace=False)\n",
       "      (15): Linear(in_features=368, out_features=404, bias=True)\n",
       "      (16): ReLU()\n",
       "      (17): Dropout(p=0.1, inplace=False)\n",
       "      (18): Linear(in_features=404, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [510, 269, 374, 171, 368, 404],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.005581424391191261,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.6861543655395508,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.794675350189209,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 458: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=483, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=483, out_features=97, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=97, out_features=179, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=179, out_features=44, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=44, out_features=84, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.2, inplace=False)\n",
       "      (15): Linear(in_features=84, out_features=395, bias=True)\n",
       "      (16): LeakyReLU(negative_slope=0.01)\n",
       "      (17): Dropout(p=0.2, inplace=False)\n",
       "      (18): Linear(in_features=395, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [483, 97, 179, 44, 84, 395],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.009474900171848592,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.7008922696113586,\n",
       "  'train_acc': 0.3619791666666667,\n",
       "  'val_loss': 0.7005515694618225,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 459: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=217, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=217, out_features=270, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=270, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [217, 270],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.006712987844976466,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.7036700248718262,\n",
       "  'train_acc': 0.4947916666666667,\n",
       "  'val_loss': 0.6985607147216797,\n",
       "  'val_acc': 0.4270833333333333},\n",
       " 460: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=135, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=135, out_features=205, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=205, out_features=462, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=462, out_features=318, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=318, out_features=396, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.2, inplace=False)\n",
       "      (15): Linear(in_features=396, out_features=393, bias=True)\n",
       "      (16): ReLU()\n",
       "      (17): Dropout(p=0.2, inplace=False)\n",
       "      (18): Linear(in_features=393, out_features=33, bias=True)\n",
       "      (19): ReLU()\n",
       "      (20): Dropout(p=0.2, inplace=False)\n",
       "      (21): Linear(in_features=33, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [135, 205, 462, 318, 396, 393, 33],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0028346786917890646,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.6872256398200989,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.6860618591308594,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 461: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=405, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=405, out_features=138, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=138, out_features=15, bias=True)\n",
       "      (5): LeakyReLU(negative_slope=0.01)\n",
       "      (6): Linear(in_features=15, out_features=329, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Linear(in_features=329, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [405, 138, 15, 329],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.007929201869300994,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.6619873046875,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.7456435561180115,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 462: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=435, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=435, out_features=483, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=483, out_features=501, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=501, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [435, 483, 501],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0011130112589933505,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.6864917278289795,\n",
       "  'train_acc': 0.5442708333333334,\n",
       "  'val_loss': 0.6251059174537659,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 463: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=197, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=197, out_features=454, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=454, out_features=410, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=410, out_features=419, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=419, out_features=158, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=158, out_features=199, bias=True)\n",
       "      (16): ReLU()\n",
       "      (17): Dropout(p=0.5, inplace=False)\n",
       "      (18): Linear(in_features=199, out_features=176, bias=True)\n",
       "      (19): ReLU()\n",
       "      (20): Dropout(p=0.5, inplace=False)\n",
       "      (21): Linear(in_features=176, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [197, 454, 410, 419, 158, 199, 176],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0030195532800594504,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.7056960463523865,\n",
       "  'train_acc': 0.3671875,\n",
       "  'val_loss': 0.707636296749115,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 464: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=174, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=174, out_features=101, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=101, out_features=374, bias=True)\n",
       "      (5): ReLU()\n",
       "      (6): Linear(in_features=374, out_features=335, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Linear(in_features=335, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [174, 101, 374, 335],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0031129355617755465,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.7015278935432434,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.6419350504875183,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 465: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=34, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=34, out_features=175, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=175, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [34, 175],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.005617547584369711,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.7537029385566711,\n",
       "  'train_acc': 0.359375,\n",
       "  'val_loss': 0.7438109517097473,\n",
       "  'val_acc': 0.3125},\n",
       " 466: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=282, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=282, out_features=175, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=175, out_features=285, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=285, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [282, 175, 285],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.004887803231566588,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.7214663624763489,\n",
       "  'train_acc': 0.4817708333333333,\n",
       "  'val_loss': 0.9206349849700928,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 467: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=95, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=95, out_features=150, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=150, out_features=60, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=60, out_features=257, bias=True)\n",
       "      (10): Sigmoid()\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=257, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [95, 150, 60, 257],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.006827679459561688,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.8949869275093079,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.8051806092262268,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 468: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=97, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=97, out_features=267, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=267, out_features=294, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=294, out_features=469, bias=True)\n",
       "      (10): Sigmoid()\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=469, out_features=61, bias=True)\n",
       "      (13): Sigmoid()\n",
       "      (14): Dropout(p=0.1, inplace=False)\n",
       "      (15): Linear(in_features=61, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [97, 267, 294, 469, 61],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.006263392276409217,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.7313456535339355,\n",
       "  'train_acc': 0.3697916666666667,\n",
       "  'val_loss': 0.7240684628486633,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 469: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=431, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=431, out_features=84, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=84, out_features=331, bias=True)\n",
       "      (5): LeakyReLU(negative_slope=0.01)\n",
       "      (6): Linear(in_features=331, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [431, 84, 331],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.00888029277919495,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.710136890411377,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.7093608379364014,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 470: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=381, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=381, out_features=182, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=182, out_features=428, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=428, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [381, 182, 428],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.002133719633031365,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.6699447631835938,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.6373293399810791,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 471: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=260, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=260, out_features=183, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=183, out_features=479, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=479, out_features=345, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=345, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [260, 183, 479, 345],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.002451189274891273,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.7090725898742676,\n",
       "  'train_acc': 0.34375,\n",
       "  'val_loss': 0.7116902470588684,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 472: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=253, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=253, out_features=401, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=401, out_features=202, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=202, out_features=175, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=175, out_features=28, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=28, out_features=35, bias=True)\n",
       "      (16): LeakyReLU(negative_slope=0.01)\n",
       "      (17): Dropout(p=0.5, inplace=False)\n",
       "      (18): Linear(in_features=35, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [253, 401, 202, 175, 28, 35],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.00673533847833316,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.7307019829750061,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.7073578238487244,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 473: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=128, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=128, out_features=335, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=335, out_features=387, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=387, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [128, 335, 387],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.003981722525782836,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.6829696297645569,\n",
       "  'train_acc': 0.5286458333333334,\n",
       "  'val_loss': 0.6644958853721619,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 474: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=129, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=129, out_features=462, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=462, out_features=201, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=201, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [129, 462, 201],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0046161127583694995,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.6917425990104675,\n",
       "  'train_acc': 0.5052083333333334,\n",
       "  'val_loss': 0.6912599205970764,\n",
       "  'val_acc': 0.5520833333333334},\n",
       " 475: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=458, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=458, out_features=288, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=288, out_features=503, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=503, out_features=149, bias=True)\n",
       "      (10): Sigmoid()\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=149, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [458, 288, 503, 149],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0028762125891229834,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.8060480952262878,\n",
       "  'train_acc': 0.3880208333333333,\n",
       "  'val_loss': 0.7724688649177551,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 476: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=338, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=338, out_features=297, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=297, out_features=212, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=212, out_features=299, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=299, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [338, 297, 212, 299],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0015720003265400533,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.6908604502677917,\n",
       "  'train_acc': 0.578125,\n",
       "  'val_loss': 0.6911687850952148,\n",
       "  'val_acc': 0.59375},\n",
       " 477: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=162, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=162, out_features=171, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=171, out_features=364, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=364, out_features=502, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=502, out_features=123, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.2, inplace=False)\n",
       "      (15): Linear(in_features=123, out_features=151, bias=True)\n",
       "      (16): ReLU()\n",
       "      (17): Dropout(p=0.2, inplace=False)\n",
       "      (18): Linear(in_features=151, out_features=384, bias=True)\n",
       "      (19): ReLU()\n",
       "      (20): Dropout(p=0.2, inplace=False)\n",
       "      (21): Linear(in_features=384, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [162, 171, 364, 502, 123, 151, 384],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.002882618377871297,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.6941160559654236,\n",
       "  'train_acc': 0.4348958333333333,\n",
       "  'val_loss': 0.6943966746330261,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 478: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=35, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=35, out_features=77, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=77, out_features=76, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=76, out_features=248, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=248, out_features=374, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.1, inplace=False)\n",
       "      (15): Linear(in_features=374, out_features=375, bias=True)\n",
       "      (16): LeakyReLU(negative_slope=0.01)\n",
       "      (17): Dropout(p=0.1, inplace=False)\n",
       "      (18): Linear(in_features=375, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [35, 77, 76, 248, 374, 375],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.004339259611519405,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.7069799900054932,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.637812077999115,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 479: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=479, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=479, out_features=419, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=419, out_features=510, bias=True)\n",
       "      (5): ReLU()\n",
       "      (6): Linear(in_features=510, out_features=224, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Linear(in_features=224, out_features=279, bias=True)\n",
       "      (9): ReLU()\n",
       "      (10): Linear(in_features=279, out_features=166, bias=True)\n",
       "      (11): ReLU()\n",
       "      (12): Linear(in_features=166, out_features=15, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Linear(in_features=15, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [479, 419, 510, 224, 279, 166, 15],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.005730460952444704,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.7422568202018738,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.7461736798286438,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 480: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=25, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=25, out_features=343, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=343, out_features=409, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=409, out_features=400, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=400, out_features=411, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=411, out_features=148, bias=True)\n",
       "      (16): LeakyReLU(negative_slope=0.01)\n",
       "      (17): Dropout(p=0.5, inplace=False)\n",
       "      (18): Linear(in_features=148, out_features=291, bias=True)\n",
       "      (19): LeakyReLU(negative_slope=0.01)\n",
       "      (20): Dropout(p=0.5, inplace=False)\n",
       "      (21): Linear(in_features=291, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [25, 343, 409, 400, 411, 148, 291],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.004081238265280504,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.6879943013191223,\n",
       "  'train_acc': 0.6067708333333334,\n",
       "  'val_loss': 0.6867853999137878,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 481: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=399, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=399, out_features=71, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=71, out_features=80, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=80, out_features=63, bias=True)\n",
       "      (10): Sigmoid()\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=63, out_features=370, bias=True)\n",
       "      (13): Sigmoid()\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=370, out_features=183, bias=True)\n",
       "      (16): Sigmoid()\n",
       "      (17): Dropout(p=0.5, inplace=False)\n",
       "      (18): Linear(in_features=183, out_features=387, bias=True)\n",
       "      (19): Sigmoid()\n",
       "      (20): Dropout(p=0.5, inplace=False)\n",
       "      (21): Linear(in_features=387, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [399, 71, 80, 63, 370, 183, 387],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.009029432663829055,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.6918324828147888,\n",
       "  'train_acc': 0.5442708333333334,\n",
       "  'val_loss': 0.644936740398407,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 482: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=110, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=110, out_features=29, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=29, out_features=170, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=170, out_features=445, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=445, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [110, 29, 170, 445],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.005632776628398326,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.7034439444541931,\n",
       "  'train_acc': 0.34375,\n",
       "  'val_loss': 0.6329326033592224,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 483: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=296, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=296, out_features=334, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=334, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [296, 334],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.005227797790181083,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.6907973289489746,\n",
       "  'train_acc': 0.5416666666666666,\n",
       "  'val_loss': 0.8862064480781555,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 484: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=421, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=421, out_features=268, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=268, out_features=277, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=277, out_features=88, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=88, out_features=60, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=60, out_features=376, bias=True)\n",
       "      (16): LeakyReLU(negative_slope=0.01)\n",
       "      (17): Dropout(p=0.5, inplace=False)\n",
       "      (18): Linear(in_features=376, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [421, 268, 277, 88, 60, 376],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0031439115501680427,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.6960185170173645,\n",
       "  'train_acc': 0.4817708333333333,\n",
       "  'val_loss': 0.6669578552246094,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 485: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=225, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=225, out_features=357, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=357, out_features=371, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=371, out_features=29, bias=True)\n",
       "      (10): Sigmoid()\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=29, out_features=403, bias=True)\n",
       "      (13): Sigmoid()\n",
       "      (14): Dropout(p=0.2, inplace=False)\n",
       "      (15): Linear(in_features=403, out_features=472, bias=True)\n",
       "      (16): Sigmoid()\n",
       "      (17): Dropout(p=0.2, inplace=False)\n",
       "      (18): Linear(in_features=472, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [225, 357, 371, 29, 403, 472],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.007877591747888529,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.7008927464485168,\n",
       "  'train_acc': 0.4609375,\n",
       "  'val_loss': 0.6464670896530151,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 486: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=437, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=437, out_features=88, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=88, out_features=368, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=368, out_features=370, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=370, out_features=436, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.2, inplace=False)\n",
       "      (15): Linear(in_features=436, out_features=238, bias=True)\n",
       "      (16): LeakyReLU(negative_slope=0.01)\n",
       "      (17): Dropout(p=0.2, inplace=False)\n",
       "      (18): Linear(in_features=238, out_features=370, bias=True)\n",
       "      (19): LeakyReLU(negative_slope=0.01)\n",
       "      (20): Dropout(p=0.2, inplace=False)\n",
       "      (21): Linear(in_features=370, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [437, 88, 368, 370, 436, 238, 370],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.00265711850858866,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.6728804111480713,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.6699942946434021,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 487: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=98, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=98, out_features=150, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=150, out_features=275, bias=True)\n",
       "      (5): ReLU()\n",
       "      (6): Linear(in_features=275, out_features=397, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Linear(in_features=397, out_features=159, bias=True)\n",
       "      (9): ReLU()\n",
       "      (10): Linear(in_features=159, out_features=167, bias=True)\n",
       "      (11): ReLU()\n",
       "      (12): Linear(in_features=167, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [98, 150, 275, 397, 159, 167],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.004270294312611058,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.6745184063911438,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.6719503998756409,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 488: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=484, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=484, out_features=508, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=508, out_features=396, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=396, out_features=64, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=64, out_features=53, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.1, inplace=False)\n",
       "      (15): Linear(in_features=53, out_features=27, bias=True)\n",
       "      (16): LeakyReLU(negative_slope=0.01)\n",
       "      (17): Dropout(p=0.1, inplace=False)\n",
       "      (18): Linear(in_features=27, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [484, 508, 396, 64, 53, 27],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.005095093253043183,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.7040782570838928,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.6746652126312256,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 489: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=169, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Linear(in_features=169, out_features=345, bias=True)\n",
       "      (3): Sigmoid()\n",
       "      (4): Linear(in_features=345, out_features=331, bias=True)\n",
       "      (5): Sigmoid()\n",
       "      (6): Linear(in_features=331, out_features=431, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Linear(in_features=431, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [169, 345, 331, 431],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0016528424697841806,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.6490805745124817,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.6400273442268372,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 490: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=427, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Linear(in_features=427, out_features=152, bias=True)\n",
       "      (3): Sigmoid()\n",
       "      (4): Linear(in_features=152, out_features=386, bias=True)\n",
       "      (5): Sigmoid()\n",
       "      (6): Linear(in_features=386, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [427, 152, 386],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0012991783531457876,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.673088550567627,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.6389377117156982,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 491: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=39, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=39, out_features=424, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=424, out_features=56, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=56, out_features=129, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=129, out_features=311, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.1, inplace=False)\n",
       "      (15): Linear(in_features=311, out_features=244, bias=True)\n",
       "      (16): LeakyReLU(negative_slope=0.01)\n",
       "      (17): Dropout(p=0.1, inplace=False)\n",
       "      (18): Linear(in_features=244, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [39, 424, 56, 129, 311, 244],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.007917850129113023,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.7078220844268799,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.6408039927482605,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 492: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=372, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=372, out_features=110, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=110, out_features=385, bias=True)\n",
       "      (5): ReLU()\n",
       "      (6): Linear(in_features=385, out_features=383, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Linear(in_features=383, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [372, 110, 385, 383],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.008318401929960247,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.6912516951560974,\n",
       "  'train_acc': 0.59375,\n",
       "  'val_loss': 0.6903658509254456,\n",
       "  'val_acc': 0.6458333333333334},\n",
       " 493: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=142, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=142, out_features=44, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=44, out_features=307, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=307, out_features=134, bias=True)\n",
       "      (10): Sigmoid()\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=134, out_features=183, bias=True)\n",
       "      (13): Sigmoid()\n",
       "      (14): Dropout(p=0.2, inplace=False)\n",
       "      (15): Linear(in_features=183, out_features=403, bias=True)\n",
       "      (16): Sigmoid()\n",
       "      (17): Dropout(p=0.2, inplace=False)\n",
       "      (18): Linear(in_features=403, out_features=73, bias=True)\n",
       "      (19): Sigmoid()\n",
       "      (20): Dropout(p=0.2, inplace=False)\n",
       "      (21): Linear(in_features=73, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [142, 44, 307, 134, 183, 403, 73],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.005506796374522586,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.6526123881340027,\n",
       "  'train_acc': 0.6536458333333334,\n",
       "  'val_loss': 0.6473535895347595,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 494: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=177, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=177, out_features=56, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=56, out_features=499, bias=True)\n",
       "      (5): ReLU()\n",
       "      (6): Linear(in_features=499, out_features=73, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Linear(in_features=73, out_features=146, bias=True)\n",
       "      (9): ReLU()\n",
       "      (10): Linear(in_features=146, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [177, 56, 499, 73, 146],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.007760010852591617,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.7093421816825867,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.6351402401924133,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 495: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=105, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=105, out_features=233, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=233, out_features=276, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=276, out_features=279, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=279, out_features=465, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.2, inplace=False)\n",
       "      (15): Linear(in_features=465, out_features=148, bias=True)\n",
       "      (16): LeakyReLU(negative_slope=0.01)\n",
       "      (17): Dropout(p=0.2, inplace=False)\n",
       "      (18): Linear(in_features=148, out_features=79, bias=True)\n",
       "      (19): LeakyReLU(negative_slope=0.01)\n",
       "      (20): Dropout(p=0.2, inplace=False)\n",
       "      (21): Linear(in_features=79, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [105, 233, 276, 279, 465, 148, 79],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.006112983952583489,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.6753283143043518,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.6374828815460205,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 496: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=37, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=37, out_features=383, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=383, out_features=203, bias=True)\n",
       "      (5): ReLU()\n",
       "      (6): Linear(in_features=203, out_features=506, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Linear(in_features=506, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [37, 383, 203, 506],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.004017586818615042,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.6974034905433655,\n",
       "  'train_acc': 0.3463541666666667,\n",
       "  'val_loss': 0.6973421573638916,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 497: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=292, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=292, out_features=296, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=296, out_features=387, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=387, out_features=182, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=182, out_features=92, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.2, inplace=False)\n",
       "      (15): Linear(in_features=92, out_features=122, bias=True)\n",
       "      (16): ReLU()\n",
       "      (17): Dropout(p=0.2, inplace=False)\n",
       "      (18): Linear(in_features=122, out_features=123, bias=True)\n",
       "      (19): ReLU()\n",
       "      (20): Dropout(p=0.2, inplace=False)\n",
       "      (21): Linear(in_features=123, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [292, 296, 387, 182, 92, 122, 123],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.003856730474402354,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.6871736645698547,\n",
       "  'train_acc': 0.6380208333333334,\n",
       "  'val_loss': 0.6608179211616516,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 498: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=434, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=434, out_features=377, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=377, out_features=174, bias=True)\n",
       "      (5): ReLU()\n",
       "      (6): Linear(in_features=174, out_features=448, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Linear(in_features=448, out_features=308, bias=True)\n",
       "      (9): ReLU()\n",
       "      (10): Linear(in_features=308, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [434, 377, 174, 448, 308],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0011287945858141119,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.6948238015174866,\n",
       "  'train_acc': 0.3515625,\n",
       "  'val_loss': 0.6945295333862305,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 499: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=407, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=407, out_features=327, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=327, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [407, 327],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.008221633798079792,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.7103232741355896,\n",
       "  'train_acc': 0.4505208333333333,\n",
       "  'val_loss': 0.7058632969856262,\n",
       "  'val_acc': 0.4479166666666667},\n",
       " 500: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=60, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=60, out_features=415, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=415, out_features=250, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=250, out_features=182, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=182, out_features=355, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=355, out_features=409, bias=True)\n",
       "      (16): ReLU()\n",
       "      (17): Dropout(p=0.5, inplace=False)\n",
       "      (18): Linear(in_features=409, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [60, 415, 250, 182, 355, 409],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.006873656823950143,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.6832096576690674,\n",
       "  'train_acc': 0.6380208333333334,\n",
       "  'val_loss': 0.6898705363273621,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 501: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=144, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=144, out_features=104, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=104, out_features=303, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=303, out_features=364, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=364, out_features=358, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.2, inplace=False)\n",
       "      (15): Linear(in_features=358, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [144, 104, 303, 364, 358],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.005559577846230171,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.6927981376647949,\n",
       "  'train_acc': 0.5234375,\n",
       "  'val_loss': 0.6927444934844971,\n",
       "  'val_acc': 0.5833333333333334},\n",
       " 502: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=197, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=197, out_features=422, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=422, out_features=241, bias=True)\n",
       "      (5): ReLU()\n",
       "      (6): Linear(in_features=241, out_features=380, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Linear(in_features=380, out_features=508, bias=True)\n",
       "      (9): ReLU()\n",
       "      (10): Linear(in_features=508, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [197, 422, 241, 380, 508],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0027469749442429314,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.6937088370323181,\n",
       "  'train_acc': 0.4505208333333333,\n",
       "  'val_loss': 0.6939743161201477,\n",
       "  'val_acc': 0.40625},\n",
       " 503: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=252, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=252, out_features=209, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=209, out_features=436, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=436, out_features=168, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=168, out_features=160, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.1, inplace=False)\n",
       "      (15): Linear(in_features=160, out_features=198, bias=True)\n",
       "      (16): ReLU()\n",
       "      (17): Dropout(p=0.1, inplace=False)\n",
       "      (18): Linear(in_features=198, out_features=139, bias=True)\n",
       "      (19): ReLU()\n",
       "      (20): Dropout(p=0.1, inplace=False)\n",
       "      (21): Linear(in_features=139, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [252, 209, 436, 168, 160, 198, 139],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.007859711227645587,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.6885235905647278,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.6240150332450867,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 504: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=182, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=182, out_features=297, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=297, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [182, 297],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.009947166703442221,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.6746987700462341,\n",
       "  'train_acc': 0.5885416666666666,\n",
       "  'val_loss': 0.6612586975097656,\n",
       "  'val_acc': 0.6666666666666666},\n",
       " 505: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=445, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=445, out_features=166, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=166, out_features=455, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=455, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [445, 166, 455],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.009654387934053002,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.6840658783912659,\n",
       "  'train_acc': 0.5625,\n",
       "  'val_loss': 0.6764312386512756,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 506: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=436, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=436, out_features=37, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=37, out_features=405, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=405, out_features=114, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=114, out_features=245, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=245, out_features=394, bias=True)\n",
       "      (16): ReLU()\n",
       "      (17): Dropout(p=0.5, inplace=False)\n",
       "      (18): Linear(in_features=394, out_features=213, bias=True)\n",
       "      (19): ReLU()\n",
       "      (20): Dropout(p=0.5, inplace=False)\n",
       "      (21): Linear(in_features=213, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [436, 37, 405, 114, 245, 394, 213],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.009412178655229472,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.6991272568702698,\n",
       "  'train_acc': 0.421875,\n",
       "  'val_loss': 0.6508278250694275,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 507: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=289, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=289, out_features=56, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=56, out_features=506, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=506, out_features=314, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=314, out_features=282, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.1, inplace=False)\n",
       "      (15): Linear(in_features=282, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [289, 56, 506, 314, 282],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.004099933927960105,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.6951861381530762,\n",
       "  'train_acc': 0.3723958333333333,\n",
       "  'val_loss': 0.6300199627876282,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 508: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=470, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=470, out_features=134, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=134, out_features=395, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=395, out_features=87, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=87, out_features=456, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.2, inplace=False)\n",
       "      (15): Linear(in_features=456, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [470, 134, 395, 87, 456],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.006696256002928729,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.6897022724151611,\n",
       "  'train_acc': 0.609375,\n",
       "  'val_loss': 0.6884669661521912,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 509: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=50, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Linear(in_features=50, out_features=202, bias=True)\n",
       "      (3): Sigmoid()\n",
       "      (4): Linear(in_features=202, out_features=434, bias=True)\n",
       "      (5): Sigmoid()\n",
       "      (6): Linear(in_features=434, out_features=296, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Linear(in_features=296, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [50, 202, 434, 296],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0014912212136398704,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.7662208080291748,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.6439706683158875,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 510: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=34, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=34, out_features=265, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=265, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [34, 265],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.003194411434852162,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.6925437450408936,\n",
       "  'train_acc': 0.5208333333333334,\n",
       "  'val_loss': 0.6554476022720337,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 511: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=200, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=200, out_features=393, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=393, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [200, 393],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.003399799469648511,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.6912973523139954,\n",
       "  'train_acc': 0.5416666666666666,\n",
       "  'val_loss': 0.9316741824150085,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 512: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=219, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=219, out_features=151, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=151, out_features=355, bias=True)\n",
       "      (5): ReLU()\n",
       "      (6): Linear(in_features=355, out_features=77, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Linear(in_features=77, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [219, 151, 355, 77],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.008967021868806779,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.6857267022132874,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.6842334270477295,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 513: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=200, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=200, out_features=352, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=352, out_features=267, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=267, out_features=198, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=198, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [200, 352, 267, 198],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0037316894640573393,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.7160217761993408,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.6288359761238098,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 514: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=184, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=184, out_features=419, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=419, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [184, 419],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.008176482281159535,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.6992453932762146,\n",
       "  'train_acc': 0.5026041666666666,\n",
       "  'val_loss': 0.6904304623603821,\n",
       "  'val_acc': 0.5416666666666666},\n",
       " 515: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=119, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=119, out_features=62, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=62, out_features=247, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=247, out_features=56, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=56, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [119, 62, 247, 56],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.007051029004596352,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.6815573573112488,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.6790955662727356,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 516: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=198, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=198, out_features=47, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=47, out_features=112, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=112, out_features=142, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=142, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [198, 47, 112, 142],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.002016763600818376,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.702641487121582,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.6824539303779602,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 517: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=109, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=109, out_features=189, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=189, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [109, 189],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.005160700016122219,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.6943880915641785,\n",
       "  'train_acc': 0.4817708333333333,\n",
       "  'val_loss': 0.6862453818321228,\n",
       "  'val_acc': 0.5104166666666666},\n",
       " 518: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=488, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=488, out_features=468, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=468, out_features=308, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=308, out_features=84, bias=True)\n",
       "      (10): Sigmoid()\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=84, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [488, 468, 308, 84],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.007590639163626897,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.6700107455253601,\n",
       "  'train_acc': 0.6302083333333334,\n",
       "  'val_loss': 0.6496151685714722,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 519: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=491, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=491, out_features=204, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=204, out_features=158, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=158, out_features=245, bias=True)\n",
       "      (10): Sigmoid()\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=245, out_features=313, bias=True)\n",
       "      (13): Sigmoid()\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=313, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [491, 204, 158, 245, 313],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.005209470749094946,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.6960645318031311,\n",
       "  'train_acc': 0.5416666666666666,\n",
       "  'val_loss': 0.6533612608909607,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 520: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=458, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=458, out_features=80, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=80, out_features=272, bias=True)\n",
       "      (5): ReLU()\n",
       "      (6): Linear(in_features=272, out_features=17, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Linear(in_features=17, out_features=232, bias=True)\n",
       "      (9): ReLU()\n",
       "      (10): Linear(in_features=232, out_features=444, bias=True)\n",
       "      (11): ReLU()\n",
       "      (12): Linear(in_features=444, out_features=396, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Linear(in_features=396, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [458, 80, 272, 17, 232, 444, 396],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0027231614280482197,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.6963622570037842,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.643583357334137,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 521: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=471, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=471, out_features=218, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=218, out_features=198, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=198, out_features=90, bias=True)\n",
       "      (10): Sigmoid()\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=90, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [471, 218, 198, 90],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.006480368288502104,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.8169639706611633,\n",
       "  'train_acc': 0.34375,\n",
       "  'val_loss': 0.6517931818962097,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 522: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=94, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=94, out_features=179, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=179, out_features=48, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=48, out_features=161, bias=True)\n",
       "      (10): Sigmoid()\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=161, out_features=256, bias=True)\n",
       "      (13): Sigmoid()\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=256, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [94, 179, 48, 161, 256],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.00391051064230998,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.7202911972999573,\n",
       "  'train_acc': 0.5104166666666666,\n",
       "  'val_loss': 0.7724878191947937,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 523: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=113, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=113, out_features=179, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=179, out_features=145, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=145, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [113, 179, 145],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.006186791679652225,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.7123551368713379,\n",
       "  'train_acc': 0.3385416666666667,\n",
       "  'val_loss': 0.7127606868743896,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 524: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=468, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Linear(in_features=468, out_features=16, bias=True)\n",
       "      (3): Sigmoid()\n",
       "      (4): Linear(in_features=16, out_features=314, bias=True)\n",
       "      (5): Sigmoid()\n",
       "      (6): Linear(in_features=314, out_features=215, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Linear(in_features=215, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [468, 16, 314, 215],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.005868624170860252,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.6820942759513855,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.6661876440048218,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 525: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=165, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=165, out_features=324, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=324, out_features=148, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=148, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [165, 324, 148],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.002209600864964352,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.8077210783958435,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.6322697997093201,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 526: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=421, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=421, out_features=26, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=26, out_features=353, bias=True)\n",
       "      (5): LeakyReLU(negative_slope=0.01)\n",
       "      (6): Linear(in_features=353, out_features=452, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Linear(in_features=452, out_features=131, bias=True)\n",
       "      (9): LeakyReLU(negative_slope=0.01)\n",
       "      (10): Linear(in_features=131, out_features=307, bias=True)\n",
       "      (11): LeakyReLU(negative_slope=0.01)\n",
       "      (12): Linear(in_features=307, out_features=281, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Linear(in_features=281, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [421, 26, 353, 452, 131, 307, 281],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0073532408888684776,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.7043275237083435,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.7048604488372803,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 527: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=131, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=131, out_features=96, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=96, out_features=85, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=85, out_features=181, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=181, out_features=268, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.1, inplace=False)\n",
       "      (15): Linear(in_features=268, out_features=299, bias=True)\n",
       "      (16): LeakyReLU(negative_slope=0.01)\n",
       "      (17): Dropout(p=0.1, inplace=False)\n",
       "      (18): Linear(in_features=299, out_features=468, bias=True)\n",
       "      (19): LeakyReLU(negative_slope=0.01)\n",
       "      (20): Dropout(p=0.1, inplace=False)\n",
       "      (21): Linear(in_features=468, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [131, 96, 85, 181, 268, 299, 468],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.005108644603602004,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.6844847202301025,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.6348287463188171,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 528: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=75, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=75, out_features=287, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=287, out_features=251, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=251, out_features=320, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=320, out_features=110, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.2, inplace=False)\n",
       "      (15): Linear(in_features=110, out_features=76, bias=True)\n",
       "      (16): LeakyReLU(negative_slope=0.01)\n",
       "      (17): Dropout(p=0.2, inplace=False)\n",
       "      (18): Linear(in_features=76, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [75, 287, 251, 320, 110, 76],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.004028238238744339,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.685340166091919,\n",
       "  'train_acc': 0.6614583333333334,\n",
       "  'val_loss': 0.6849307417869568,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 529: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=132, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Linear(in_features=132, out_features=266, bias=True)\n",
       "      (3): Sigmoid()\n",
       "      (4): Linear(in_features=266, out_features=421, bias=True)\n",
       "      (5): Sigmoid()\n",
       "      (6): Linear(in_features=421, out_features=33, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Linear(in_features=33, out_features=484, bias=True)\n",
       "      (9): Sigmoid()\n",
       "      (10): Linear(in_features=484, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [132, 266, 421, 33, 484],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0021525125097668118,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.6830918192863464,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.6623738408088684,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 530: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=418, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=418, out_features=258, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=258, out_features=267, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=267, out_features=282, bias=True)\n",
       "      (10): Sigmoid()\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=282, out_features=221, bias=True)\n",
       "      (13): Sigmoid()\n",
       "      (14): Dropout(p=0.1, inplace=False)\n",
       "      (15): Linear(in_features=221, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [418, 258, 267, 282, 221],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0025431596348725106,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.6735658645629883,\n",
       "  'train_acc': 0.6302083333333334,\n",
       "  'val_loss': 0.7374947667121887,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 531: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=175, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=175, out_features=344, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=344, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [175, 344],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.002147312789448086,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.724517822265625,\n",
       "  'train_acc': 0.5104166666666666,\n",
       "  'val_loss': 0.686558187007904,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 532: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=181, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Linear(in_features=181, out_features=24, bias=True)\n",
       "      (3): Sigmoid()\n",
       "      (4): Linear(in_features=24, out_features=88, bias=True)\n",
       "      (5): Sigmoid()\n",
       "      (6): Linear(in_features=88, out_features=195, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Linear(in_features=195, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [181, 24, 88, 195],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.006611381299558749,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.6647511720657349,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.823965847492218,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 533: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=199, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Linear(in_features=199, out_features=434, bias=True)\n",
       "      (3): Sigmoid()\n",
       "      (4): Linear(in_features=434, out_features=321, bias=True)\n",
       "      (5): Sigmoid()\n",
       "      (6): Linear(in_features=321, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [199, 434, 321],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0034875530611245095,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.6460970044136047,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.6360741257667542,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 534: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=379, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=379, out_features=36, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=36, out_features=37, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=37, out_features=157, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=157, out_features=273, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.2, inplace=False)\n",
       "      (15): Linear(in_features=273, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [379, 36, 37, 157, 273],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.00202879464299867,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.6874663233757019,\n",
       "  'train_acc': 0.6197916666666666,\n",
       "  'val_loss': 0.6873590350151062,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 535: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=40, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=40, out_features=67, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=67, out_features=435, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=435, out_features=152, bias=True)\n",
       "      (10): Sigmoid()\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=152, out_features=467, bias=True)\n",
       "      (13): Sigmoid()\n",
       "      (14): Dropout(p=0.2, inplace=False)\n",
       "      (15): Linear(in_features=467, out_features=479, bias=True)\n",
       "      (16): Sigmoid()\n",
       "      (17): Dropout(p=0.2, inplace=False)\n",
       "      (18): Linear(in_features=479, out_features=40, bias=True)\n",
       "      (19): Sigmoid()\n",
       "      (20): Dropout(p=0.2, inplace=False)\n",
       "      (21): Linear(in_features=40, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [40, 67, 435, 152, 467, 479, 40],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0019198445805369477,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.7552375793457031,\n",
       "  'train_acc': 0.375,\n",
       "  'val_loss': 0.6367313265800476,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 536: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=236, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=236, out_features=64, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=64, out_features=444, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=444, out_features=427, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=427, out_features=330, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.2, inplace=False)\n",
       "      (15): Linear(in_features=330, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [236, 64, 444, 427, 330],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0030774618283896395,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.6959063410758972,\n",
       "  'train_acc': 0.3802083333333333,\n",
       "  'val_loss': 0.6307992935180664,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 537: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=346, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=346, out_features=302, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=302, out_features=239, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=239, out_features=435, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=435, out_features=380, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.1, inplace=False)\n",
       "      (15): Linear(in_features=380, out_features=223, bias=True)\n",
       "      (16): LeakyReLU(negative_slope=0.01)\n",
       "      (17): Dropout(p=0.1, inplace=False)\n",
       "      (18): Linear(in_features=223, out_features=110, bias=True)\n",
       "      (19): LeakyReLU(negative_slope=0.01)\n",
       "      (20): Dropout(p=0.1, inplace=False)\n",
       "      (21): Linear(in_features=110, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [346, 302, 239, 435, 380, 223, 110],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.009039617939044297,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.7177546620368958,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.8522139191627502,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 538: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=502, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=502, out_features=275, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=275, out_features=124, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=124, out_features=131, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=131, out_features=406, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.1, inplace=False)\n",
       "      (15): Linear(in_features=406, out_features=172, bias=True)\n",
       "      (16): ReLU()\n",
       "      (17): Dropout(p=0.1, inplace=False)\n",
       "      (18): Linear(in_features=172, out_features=77, bias=True)\n",
       "      (19): ReLU()\n",
       "      (20): Dropout(p=0.1, inplace=False)\n",
       "      (21): Linear(in_features=77, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [502, 275, 124, 131, 406, 172, 77],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0026339461743284274,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.6835828423500061,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.6693084239959717,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 539: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=291, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=291, out_features=192, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=192, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [291, 192],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0022765412694467,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.734281063079834,\n",
       "  'train_acc': 0.390625,\n",
       "  'val_loss': 0.6312143206596375,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 540: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=31, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=31, out_features=461, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=461, out_features=154, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=154, out_features=154, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=154, out_features=151, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.2, inplace=False)\n",
       "      (15): Linear(in_features=151, out_features=157, bias=True)\n",
       "      (16): ReLU()\n",
       "      (17): Dropout(p=0.2, inplace=False)\n",
       "      (18): Linear(in_features=157, out_features=283, bias=True)\n",
       "      (19): ReLU()\n",
       "      (20): Dropout(p=0.2, inplace=False)\n",
       "      (21): Linear(in_features=283, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [31, 461, 154, 154, 151, 157, 283],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.009918919035905836,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.708026647567749,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.6251974701881409,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 541: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=387, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=387, out_features=106, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=106, out_features=485, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=485, out_features=161, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=161, out_features=405, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=405, out_features=128, bias=True)\n",
       "      (16): ReLU()\n",
       "      (17): Dropout(p=0.5, inplace=False)\n",
       "      (18): Linear(in_features=128, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [387, 106, 485, 161, 405, 128],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.006716471650639541,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.7020354270935059,\n",
       "  'train_acc': 0.3645833333333333,\n",
       "  'val_loss': 0.7012949585914612,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 542: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=359, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=359, out_features=174, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=174, out_features=294, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=294, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [359, 174, 294],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0016697142658894126,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.6987903714179993,\n",
       "  'train_acc': 0.515625,\n",
       "  'val_loss': 0.6430343985557556,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 543: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=363, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=363, out_features=258, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=258, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [363, 258],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.008244030842681405,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.732980489730835,\n",
       "  'train_acc': 0.375,\n",
       "  'val_loss': 0.6873603463172913,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 544: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=495, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=495, out_features=127, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=127, out_features=493, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=493, out_features=68, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=68, out_features=103, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.1, inplace=False)\n",
       "      (15): Linear(in_features=103, out_features=360, bias=True)\n",
       "      (16): ReLU()\n",
       "      (17): Dropout(p=0.1, inplace=False)\n",
       "      (18): Linear(in_features=360, out_features=151, bias=True)\n",
       "      (19): ReLU()\n",
       "      (20): Dropout(p=0.1, inplace=False)\n",
       "      (21): Linear(in_features=151, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [495, 127, 493, 68, 103, 360, 151],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.005603206797190638,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.6801512837409973,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.6344470977783203,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 545: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=247, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=247, out_features=50, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=50, out_features=390, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=390, out_features=364, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=364, out_features=113, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=113, out_features=125, bias=True)\n",
       "      (16): LeakyReLU(negative_slope=0.01)\n",
       "      (17): Dropout(p=0.5, inplace=False)\n",
       "      (18): Linear(in_features=125, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [247, 50, 390, 364, 113, 125],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0011754448215621459,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.6999046206474304,\n",
       "  'train_acc': 0.3880208333333333,\n",
       "  'val_loss': 0.6941997408866882,\n",
       "  'val_acc': 0.3645833333333333},\n",
       " 546: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=479, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=479, out_features=45, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=45, out_features=283, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=283, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [479, 45, 283],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.007983473611780458,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.6939576268196106,\n",
       "  'train_acc': 0.4817708333333333,\n",
       "  'val_loss': 0.6909758448600769,\n",
       "  'val_acc': 0.5833333333333334},\n",
       " 547: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=246, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=246, out_features=496, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=496, out_features=214, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=214, out_features=290, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=290, out_features=228, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=228, out_features=316, bias=True)\n",
       "      (16): ReLU()\n",
       "      (17): Dropout(p=0.5, inplace=False)\n",
       "      (18): Linear(in_features=316, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [246, 496, 214, 290, 228, 316],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.007277933863715267,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.6939838528633118,\n",
       "  'train_acc': 0.4817708333333333,\n",
       "  'val_loss': 0.6945063471794128,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 548: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=261, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=261, out_features=154, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=154, out_features=350, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=350, out_features=341, bias=True)\n",
       "      (10): Sigmoid()\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=341, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [261, 154, 350, 341],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0022642877657785727,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.7086763381958008,\n",
       "  'train_acc': 0.5234375,\n",
       "  'val_loss': 0.7715268731117249,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 549: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=248, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=248, out_features=349, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=349, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [248, 349],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0012915905957217907,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.7086639404296875,\n",
       "  'train_acc': 0.4166666666666667,\n",
       "  'val_loss': 0.6369010806083679,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 550: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=298, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=298, out_features=75, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=75, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [298, 75],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.003890551883018876,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.6781041026115417,\n",
       "  'train_acc': 0.5859375,\n",
       "  'val_loss': 0.6677227020263672,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 551: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=377, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=377, out_features=463, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=463, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [377, 463],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.006301135666526131,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.7157609462738037,\n",
       "  'train_acc': 0.5,\n",
       "  'val_loss': 0.7062446475028992,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 552: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=47, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=47, out_features=423, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=423, out_features=403, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=403, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [47, 423, 403],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0014033474856532968,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.6653545498847961,\n",
       "  'train_acc': 0.640625,\n",
       "  'val_loss': 0.6364268660545349,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 553: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=322, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=322, out_features=405, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=405, out_features=310, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=310, out_features=435, bias=True)\n",
       "      (10): Sigmoid()\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=435, out_features=144, bias=True)\n",
       "      (13): Sigmoid()\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=144, out_features=161, bias=True)\n",
       "      (16): Sigmoid()\n",
       "      (17): Dropout(p=0.5, inplace=False)\n",
       "      (18): Linear(in_features=161, out_features=306, bias=True)\n",
       "      (19): Sigmoid()\n",
       "      (20): Dropout(p=0.5, inplace=False)\n",
       "      (21): Linear(in_features=306, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [322, 405, 310, 435, 144, 161, 306],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.002335833593770379,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.7736170887947083,\n",
       "  'train_acc': 0.4192708333333333,\n",
       "  'val_loss': 0.6334494948387146,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 554: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=120, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=120, out_features=390, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=390, out_features=15, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=15, out_features=296, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=296, out_features=334, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.1, inplace=False)\n",
       "      (15): Linear(in_features=334, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [120, 390, 15, 296, 334],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.007988932039355558,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.7211399078369141,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.7227485775947571,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 555: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=141, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=141, out_features=370, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=370, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [141, 370],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.009661122845209029,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.7080976963043213,\n",
       "  'train_acc': 0.4010416666666667,\n",
       "  'val_loss': 0.6979653835296631,\n",
       "  'val_acc': 0.4375},\n",
       " 556: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=270, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=270, out_features=301, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=301, out_features=312, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=312, out_features=476, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=476, out_features=456, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.2, inplace=False)\n",
       "      (15): Linear(in_features=456, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [270, 301, 312, 476, 456],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0032314159050039013,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.6860879063606262,\n",
       "  'train_acc': 0.6640625,\n",
       "  'val_loss': 0.6393630504608154,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 557: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=144, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=144, out_features=132, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=132, out_features=30, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=30, out_features=305, bias=True)\n",
       "      (10): Sigmoid()\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=305, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [144, 132, 30, 305],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0060158288414172605,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.8618488907814026,\n",
       "  'train_acc': 0.3802083333333333,\n",
       "  'val_loss': 0.7706323266029358,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 558: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=301, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=301, out_features=93, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=93, out_features=279, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=279, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [301, 93, 279],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.006498507078492292,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.7085967063903809,\n",
       "  'train_acc': 0.359375,\n",
       "  'val_loss': 0.7087624073028564,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 559: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=374, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=374, out_features=462, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=462, out_features=66, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=66, out_features=60, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=60, out_features=38, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.1, inplace=False)\n",
       "      (15): Linear(in_features=38, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [374, 462, 66, 60, 38],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.003916819576183922,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.7333088517189026,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.7368190884590149,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 560: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=276, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=276, out_features=358, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=358, out_features=121, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=121, out_features=471, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=471, out_features=132, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=132, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [276, 358, 121, 471, 132],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.009417791503554335,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.7034299373626709,\n",
       "  'train_acc': 0.3828125,\n",
       "  'val_loss': 0.7061944603919983,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 561: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=256, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Linear(in_features=256, out_features=264, bias=True)\n",
       "      (3): Sigmoid()\n",
       "      (4): Linear(in_features=264, out_features=43, bias=True)\n",
       "      (5): Sigmoid()\n",
       "      (6): Linear(in_features=43, out_features=379, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Linear(in_features=379, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [256, 264, 43, 379],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0059833564031665475,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.9241962432861328,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.7545552849769592,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 562: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=308, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=308, out_features=142, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=142, out_features=311, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=311, out_features=449, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=449, out_features=464, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.2, inplace=False)\n",
       "      (15): Linear(in_features=464, out_features=328, bias=True)\n",
       "      (16): ReLU()\n",
       "      (17): Dropout(p=0.2, inplace=False)\n",
       "      (18): Linear(in_features=328, out_features=262, bias=True)\n",
       "      (19): ReLU()\n",
       "      (20): Dropout(p=0.2, inplace=False)\n",
       "      (21): Linear(in_features=262, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [308, 142, 311, 449, 464, 328, 262],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0016964199581967732,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.6995093822479248,\n",
       "  'train_acc': 0.34375,\n",
       "  'val_loss': 0.7005208134651184,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 563: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=69, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=69, out_features=344, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=344, out_features=502, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=502, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [69, 344, 502],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.008186860161051539,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.7942338585853577,\n",
       "  'train_acc': 0.4192708333333333,\n",
       "  'val_loss': 0.666278064250946,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 564: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=186, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=186, out_features=406, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=406, out_features=62, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=62, out_features=374, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=374, out_features=225, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.2, inplace=False)\n",
       "      (15): Linear(in_features=225, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [186, 406, 62, 374, 225],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0075639594172794275,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.6890876889228821,\n",
       "  'train_acc': 0.6015625,\n",
       "  'val_loss': 0.7188014984130859,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 565: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=301, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=301, out_features=272, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=272, out_features=301, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=301, out_features=268, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=268, out_features=250, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=250, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [301, 272, 301, 268, 250],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0015770338775823326,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.6891357898712158,\n",
       "  'train_acc': 0.5651041666666666,\n",
       "  'val_loss': 0.6734587550163269,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 566: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=262, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=262, out_features=267, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=267, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [262, 267],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0049819304173324,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.7361814379692078,\n",
       "  'train_acc': 0.3359375,\n",
       "  'val_loss': 0.7218301892280579,\n",
       "  'val_acc': 0.3541666666666667},\n",
       " 567: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=372, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=372, out_features=363, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=363, out_features=464, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=464, out_features=46, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=46, out_features=396, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=396, out_features=480, bias=True)\n",
       "      (16): LeakyReLU(negative_slope=0.01)\n",
       "      (17): Dropout(p=0.5, inplace=False)\n",
       "      (18): Linear(in_features=480, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [372, 363, 464, 46, 396, 480],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0031244681762782646,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.695253312587738,\n",
       "  'train_acc': 0.4505208333333333,\n",
       "  'val_loss': 0.6335552930831909,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 568: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=59, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Linear(in_features=59, out_features=496, bias=True)\n",
       "      (3): Sigmoid()\n",
       "      (4): Linear(in_features=496, out_features=470, bias=True)\n",
       "      (5): Sigmoid()\n",
       "      (6): Linear(in_features=470, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [59, 496, 470],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.005918537125309317,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.8046420216560364,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.7110995650291443,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 569: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=485, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=485, out_features=503, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=503, out_features=436, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=436, out_features=210, bias=True)\n",
       "      (10): Sigmoid()\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=210, out_features=42, bias=True)\n",
       "      (13): Sigmoid()\n",
       "      (14): Dropout(p=0.2, inplace=False)\n",
       "      (15): Linear(in_features=42, out_features=33, bias=True)\n",
       "      (16): Sigmoid()\n",
       "      (17): Dropout(p=0.2, inplace=False)\n",
       "      (18): Linear(in_features=33, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [485, 503, 436, 210, 42, 33],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0073714487922578835,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.7270258069038391,\n",
       "  'train_acc': 0.40625,\n",
       "  'val_loss': 0.713660717010498,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 570: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=259, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=259, out_features=294, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=294, out_features=83, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=83, out_features=37, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=37, out_features=47, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.1, inplace=False)\n",
       "      (15): Linear(in_features=47, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [259, 294, 83, 37, 47],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.005684684662264324,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.7223474383354187,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.7239986062049866,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 571: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=501, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=501, out_features=109, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=109, out_features=443, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=443, out_features=41, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=41, out_features=17, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.2, inplace=False)\n",
       "      (15): Linear(in_features=17, out_features=64, bias=True)\n",
       "      (16): LeakyReLU(negative_slope=0.01)\n",
       "      (17): Dropout(p=0.2, inplace=False)\n",
       "      (18): Linear(in_features=64, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [501, 109, 443, 41, 17, 64],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.004333556307935282,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.7195866703987122,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.7217457890510559,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 572: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=231, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=231, out_features=483, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=483, out_features=453, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=453, out_features=270, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=270, out_features=465, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=465, out_features=308, bias=True)\n",
       "      (16): LeakyReLU(negative_slope=0.01)\n",
       "      (17): Dropout(p=0.5, inplace=False)\n",
       "      (18): Linear(in_features=308, out_features=503, bias=True)\n",
       "      (19): LeakyReLU(negative_slope=0.01)\n",
       "      (20): Dropout(p=0.5, inplace=False)\n",
       "      (21): Linear(in_features=503, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [231, 483, 453, 270, 465, 308, 503],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.007423191699432561,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.697955846786499,\n",
       "  'train_acc': 0.4010416666666667,\n",
       "  'val_loss': 0.787467896938324,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 573: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=144, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=144, out_features=230, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=230, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [144, 230],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.00506480399071922,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.7080829739570618,\n",
       "  'train_acc': 0.3776041666666667,\n",
       "  'val_loss': 0.705250084400177,\n",
       "  'val_acc': 0.40625},\n",
       " 574: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=412, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=412, out_features=386, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=386, out_features=23, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=23, out_features=343, bias=True)\n",
       "      (10): Sigmoid()\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=343, out_features=122, bias=True)\n",
       "      (13): Sigmoid()\n",
       "      (14): Dropout(p=0.2, inplace=False)\n",
       "      (15): Linear(in_features=122, out_features=377, bias=True)\n",
       "      (16): Sigmoid()\n",
       "      (17): Dropout(p=0.2, inplace=False)\n",
       "      (18): Linear(in_features=377, out_features=506, bias=True)\n",
       "      (19): Sigmoid()\n",
       "      (20): Dropout(p=0.2, inplace=False)\n",
       "      (21): Linear(in_features=506, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [412, 386, 23, 343, 122, 377, 506],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0034214719763112733,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.7850937843322754,\n",
       "  'train_acc': 0.3515625,\n",
       "  'val_loss': 0.7246444821357727,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 575: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=481, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=481, out_features=472, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=472, out_features=369, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=369, out_features=19, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=19, out_features=425, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=425, out_features=275, bias=True)\n",
       "      (16): LeakyReLU(negative_slope=0.01)\n",
       "      (17): Dropout(p=0.5, inplace=False)\n",
       "      (18): Linear(in_features=275, out_features=246, bias=True)\n",
       "      (19): LeakyReLU(negative_slope=0.01)\n",
       "      (20): Dropout(p=0.5, inplace=False)\n",
       "      (21): Linear(in_features=246, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [481, 472, 369, 19, 425, 275, 246],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.007009705846349421,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.688195526599884,\n",
       "  'train_acc': 0.6067708333333334,\n",
       "  'val_loss': 0.6752974390983582,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 576: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=91, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=91, out_features=55, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=55, out_features=511, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=511, out_features=27, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=27, out_features=42, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=42, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [91, 55, 511, 27, 42],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.009011789648294147,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.6732882857322693,\n",
       "  'train_acc': 0.6380208333333334,\n",
       "  'val_loss': 0.6724616885185242,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 577: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=486, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=486, out_features=201, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=201, out_features=131, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=131, out_features=110, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=110, out_features=497, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=497, out_features=350, bias=True)\n",
       "      (16): LeakyReLU(negative_slope=0.01)\n",
       "      (17): Dropout(p=0.5, inplace=False)\n",
       "      (18): Linear(in_features=350, out_features=141, bias=True)\n",
       "      (19): LeakyReLU(negative_slope=0.01)\n",
       "      (20): Dropout(p=0.5, inplace=False)\n",
       "      (21): Linear(in_features=141, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [486, 201, 131, 110, 497, 350, 141],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.009182135808134283,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.6980565190315247,\n",
       "  'train_acc': 0.3984375,\n",
       "  'val_loss': 0.6972523331642151,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 578: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=40, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=40, out_features=150, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=150, out_features=70, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=70, out_features=410, bias=True)\n",
       "      (10): Sigmoid()\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=410, out_features=118, bias=True)\n",
       "      (13): Sigmoid()\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=118, out_features=510, bias=True)\n",
       "      (16): Sigmoid()\n",
       "      (17): Dropout(p=0.5, inplace=False)\n",
       "      (18): Linear(in_features=510, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [40, 150, 70, 410, 118, 510],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0029514241241829857,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.6888620853424072,\n",
       "  'train_acc': 0.546875,\n",
       "  'val_loss': 0.8962398171424866,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 579: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=506, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=506, out_features=273, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=273, out_features=132, bias=True)\n",
       "      (5): ReLU()\n",
       "      (6): Linear(in_features=132, out_features=263, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Linear(in_features=263, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [506, 273, 132, 263],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0021686364100742235,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.7105746865272522,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.713512659072876,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 580: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=500, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=500, out_features=78, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=78, out_features=511, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=511, out_features=248, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=248, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [500, 78, 511, 248],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.004256543819530698,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.6867405772209167,\n",
       "  'train_acc': 0.6458333333333334,\n",
       "  'val_loss': 0.7090559601783752,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 581: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=43, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=43, out_features=401, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=401, out_features=284, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=284, out_features=202, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=202, out_features=142, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=142, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [43, 401, 284, 202, 142],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0013027982781049878,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.6767882704734802,\n",
       "  'train_acc': 0.6432291666666666,\n",
       "  'val_loss': 0.6658011078834534,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 582: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=115, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=115, out_features=77, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=77, out_features=504, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=504, out_features=200, bias=True)\n",
       "      (10): Sigmoid()\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=200, out_features=276, bias=True)\n",
       "      (13): Sigmoid()\n",
       "      (14): Dropout(p=0.1, inplace=False)\n",
       "      (15): Linear(in_features=276, out_features=174, bias=True)\n",
       "      (16): Sigmoid()\n",
       "      (17): Dropout(p=0.1, inplace=False)\n",
       "      (18): Linear(in_features=174, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [115, 77, 504, 200, 276, 174],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.009179721908408864,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.8648073077201843,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.7861340045928955,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 583: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=115, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=115, out_features=501, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=501, out_features=389, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=389, out_features=375, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=375, out_features=101, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.2, inplace=False)\n",
       "      (15): Linear(in_features=101, out_features=372, bias=True)\n",
       "      (16): ReLU()\n",
       "      (17): Dropout(p=0.2, inplace=False)\n",
       "      (18): Linear(in_features=372, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [115, 501, 389, 375, 101, 372],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.002096232538790598,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.6941422820091248,\n",
       "  'train_acc': 0.4270833333333333,\n",
       "  'val_loss': 0.6729643940925598,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 584: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=24, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=24, out_features=241, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=241, out_features=60, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=60, out_features=436, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=436, out_features=315, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=315, out_features=206, bias=True)\n",
       "      (16): LeakyReLU(negative_slope=0.01)\n",
       "      (17): Dropout(p=0.5, inplace=False)\n",
       "      (18): Linear(in_features=206, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [24, 241, 60, 436, 315, 206],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0034984197349008663,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.7041371464729309,\n",
       "  'train_acc': 0.3567708333333333,\n",
       "  'val_loss': 0.7004573941230774,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 585: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=145, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=145, out_features=411, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=411, out_features=42, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=42, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [145, 411, 42],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0050730944339475725,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.6812049746513367,\n",
       "  'train_acc': 0.5911458333333334,\n",
       "  'val_loss': 0.6235373616218567,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 586: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=323, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=323, out_features=296, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=296, out_features=280, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=280, out_features=405, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=405, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [323, 296, 280, 405],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0030777982303102896,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.6939567923545837,\n",
       "  'train_acc': 0.4739583333333333,\n",
       "  'val_loss': 0.6262958645820618,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 587: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=48, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=48, out_features=102, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=102, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [48, 102],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.009362593860857128,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.6755170226097107,\n",
       "  'train_acc': 0.609375,\n",
       "  'val_loss': 0.6236822605133057,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 588: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=262, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=262, out_features=403, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=403, out_features=353, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=353, out_features=210, bias=True)\n",
       "      (10): Sigmoid()\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=210, out_features=374, bias=True)\n",
       "      (13): Sigmoid()\n",
       "      (14): Dropout(p=0.1, inplace=False)\n",
       "      (15): Linear(in_features=374, out_features=153, bias=True)\n",
       "      (16): Sigmoid()\n",
       "      (17): Dropout(p=0.1, inplace=False)\n",
       "      (18): Linear(in_features=153, out_features=25, bias=True)\n",
       "      (19): Sigmoid()\n",
       "      (20): Dropout(p=0.1, inplace=False)\n",
       "      (21): Linear(in_features=25, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [262, 403, 353, 210, 374, 153, 25],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.00620436238350521,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.649458110332489,\n",
       "  'train_acc': 0.65625,\n",
       "  'val_loss': 0.6742264628410339,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 589: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=189, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=189, out_features=399, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=399, out_features=330, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=330, out_features=143, bias=True)\n",
       "      (10): Sigmoid()\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=143, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [189, 399, 330, 143],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.006033925448503539,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.7392396926879883,\n",
       "  'train_acc': 0.4479166666666667,\n",
       "  'val_loss': 0.6809280514717102,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 590: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=275, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=275, out_features=103, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=103, out_features=428, bias=True)\n",
       "      (5): LeakyReLU(negative_slope=0.01)\n",
       "      (6): Linear(in_features=428, out_features=465, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Linear(in_features=465, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [275, 103, 428, 465],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.007727900606476812,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.6868112683296204,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.6854835152626038,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 591: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=275, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=275, out_features=452, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=452, out_features=122, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=122, out_features=367, bias=True)\n",
       "      (10): Sigmoid()\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=367, out_features=317, bias=True)\n",
       "      (13): Sigmoid()\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=317, out_features=262, bias=True)\n",
       "      (16): Sigmoid()\n",
       "      (17): Dropout(p=0.5, inplace=False)\n",
       "      (18): Linear(in_features=262, out_features=222, bias=True)\n",
       "      (19): Sigmoid()\n",
       "      (20): Dropout(p=0.5, inplace=False)\n",
       "      (21): Linear(in_features=222, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [275, 452, 122, 367, 317, 262, 222],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.006175213281234333,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.78126460313797,\n",
       "  'train_acc': 0.4375,\n",
       "  'val_loss': 0.7162501811981201,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 592: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=58, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=58, out_features=101, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=101, out_features=451, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=451, out_features=189, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=189, out_features=222, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.1, inplace=False)\n",
       "      (15): Linear(in_features=222, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [58, 101, 451, 189, 222],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.00381618371815806,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.6994205117225647,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.7000706195831299,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 593: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=81, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=81, out_features=381, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=381, out_features=135, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=135, out_features=291, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=291, out_features=210, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=210, out_features=131, bias=True)\n",
       "      (16): LeakyReLU(negative_slope=0.01)\n",
       "      (17): Dropout(p=0.5, inplace=False)\n",
       "      (18): Linear(in_features=131, out_features=259, bias=True)\n",
       "      (19): LeakyReLU(negative_slope=0.01)\n",
       "      (20): Dropout(p=0.5, inplace=False)\n",
       "      (21): Linear(in_features=259, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [81, 381, 135, 291, 210, 131, 259],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.007237315977234859,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.716716468334198,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.7177495360374451,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 594: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=239, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=239, out_features=372, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=372, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [239, 372],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.005040856327218569,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.6939811110496521,\n",
       "  'train_acc': 0.5364583333333334,\n",
       "  'val_loss': 0.6809330582618713,\n",
       "  'val_acc': 0.6145833333333334},\n",
       " 595: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=274, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=274, out_features=404, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=404, out_features=504, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=504, out_features=186, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=186, out_features=455, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.1, inplace=False)\n",
       "      (15): Linear(in_features=455, out_features=346, bias=True)\n",
       "      (16): ReLU()\n",
       "      (17): Dropout(p=0.1, inplace=False)\n",
       "      (18): Linear(in_features=346, out_features=381, bias=True)\n",
       "      (19): ReLU()\n",
       "      (20): Dropout(p=0.1, inplace=False)\n",
       "      (21): Linear(in_features=381, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [274, 404, 504, 186, 455, 346, 381],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.007652297495964697,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.6865900158882141,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.6850005984306335,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 596: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=170, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Linear(in_features=170, out_features=498, bias=True)\n",
       "      (3): Sigmoid()\n",
       "      (4): Linear(in_features=498, out_features=403, bias=True)\n",
       "      (5): Sigmoid()\n",
       "      (6): Linear(in_features=403, out_features=447, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Linear(in_features=447, out_features=208, bias=True)\n",
       "      (9): Sigmoid()\n",
       "      (10): Linear(in_features=208, out_features=234, bias=True)\n",
       "      (11): Sigmoid()\n",
       "      (12): Linear(in_features=234, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [170, 498, 403, 447, 208, 234],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.00681429703473662,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.641889750957489,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.6294224262237549,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 597: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=449, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=449, out_features=319, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=319, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [449, 319],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0059986240488819394,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.7487965226173401,\n",
       "  'train_acc': 0.4244791666666667,\n",
       "  'val_loss': 0.6884069442749023,\n",
       "  'val_acc': 0.65625},\n",
       " 598: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=276, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=276, out_features=52, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=52, out_features=21, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=21, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [276, 52, 21],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.004432640791401741,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.7221456170082092,\n",
       "  'train_acc': 0.4192708333333333,\n",
       "  'val_loss': 0.6800922751426697,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 599: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=335, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=335, out_features=164, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=164, out_features=413, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=413, out_features=453, bias=True)\n",
       "      (10): Sigmoid()\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=453, out_features=143, bias=True)\n",
       "      (13): Sigmoid()\n",
       "      (14): Dropout(p=0.1, inplace=False)\n",
       "      (15): Linear(in_features=143, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [335, 164, 413, 453, 143],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0071512359402753425,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.7666451334953308,\n",
       "  'train_acc': 0.34375,\n",
       "  'val_loss': 0.7394495010375977,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 600: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=500, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=500, out_features=441, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=441, out_features=298, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=298, out_features=496, bias=True)\n",
       "      (10): Sigmoid()\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=496, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [500, 441, 298, 496],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.005606691422833878,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.6840603351593018,\n",
       "  'train_acc': 0.5572916666666666,\n",
       "  'val_loss': 0.6515036821365356,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 601: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=84, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=84, out_features=206, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=206, out_features=72, bias=True)\n",
       "      (5): LeakyReLU(negative_slope=0.01)\n",
       "      (6): Linear(in_features=72, out_features=349, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Linear(in_features=349, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [84, 206, 72, 349],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0010959500278095579,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.7019283175468445,\n",
       "  'train_acc': 0.3489583333333333,\n",
       "  'val_loss': 0.6844436526298523,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 602: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=52, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=52, out_features=62, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=62, out_features=267, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=267, out_features=219, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=219, out_features=466, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=466, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [52, 62, 267, 219, 466],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.004739793088440063,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.6926974654197693,\n",
       "  'train_acc': 0.4921875,\n",
       "  'val_loss': 0.6340586543083191,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 603: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=500, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=500, out_features=418, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=418, out_features=149, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=149, out_features=72, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=72, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [500, 418, 149, 72],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.007755164702282823,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.6903092265129089,\n",
       "  'train_acc': 0.6119791666666666,\n",
       "  'val_loss': 0.6694579124450684,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 604: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=15, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=15, out_features=30, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=30, out_features=334, bias=True)\n",
       "      (5): ReLU()\n",
       "      (6): Linear(in_features=334, out_features=230, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Linear(in_features=230, out_features=205, bias=True)\n",
       "      (9): ReLU()\n",
       "      (10): Linear(in_features=205, out_features=160, bias=True)\n",
       "      (11): ReLU()\n",
       "      (12): Linear(in_features=160, out_features=400, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Linear(in_features=400, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [15, 30, 334, 230, 205, 160, 400],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.004719502612891465,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.6851558685302734,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.6837749481201172,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 605: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=211, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=211, out_features=386, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=386, out_features=134, bias=True)\n",
       "      (5): ReLU()\n",
       "      (6): Linear(in_features=134, out_features=149, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Linear(in_features=149, out_features=388, bias=True)\n",
       "      (9): ReLU()\n",
       "      (10): Linear(in_features=388, out_features=407, bias=True)\n",
       "      (11): ReLU()\n",
       "      (12): Linear(in_features=407, out_features=484, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Linear(in_features=484, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [211, 386, 134, 149, 388, 407, 484],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0057100107296175736,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.6896925568580627,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.6266103386878967,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 606: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=279, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=279, out_features=223, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=223, out_features=433, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=433, out_features=118, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=118, out_features=411, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.1, inplace=False)\n",
       "      (15): Linear(in_features=411, out_features=360, bias=True)\n",
       "      (16): LeakyReLU(negative_slope=0.01)\n",
       "      (17): Dropout(p=0.1, inplace=False)\n",
       "      (18): Linear(in_features=360, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [279, 223, 433, 118, 411, 360],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0019523817461933432,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.6923285126686096,\n",
       "  'train_acc': 0.5729166666666666,\n",
       "  'val_loss': 0.6557623744010925,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 607: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=280, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=280, out_features=510, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=510, out_features=111, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=111, out_features=121, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=121, out_features=458, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=458, out_features=448, bias=True)\n",
       "      (16): ReLU()\n",
       "      (17): Dropout(p=0.5, inplace=False)\n",
       "      (18): Linear(in_features=448, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [280, 510, 111, 121, 458, 448],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.004422085828861966,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.6925673484802246,\n",
       "  'train_acc': 0.5286458333333334,\n",
       "  'val_loss': 0.6294915676116943,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 608: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=89, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=89, out_features=107, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=107, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [89, 107],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0034952141333710906,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.7284685969352722,\n",
       "  'train_acc': 0.3515625,\n",
       "  'val_loss': 0.7171376347541809,\n",
       "  'val_acc': 0.3125},\n",
       " 609: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=366, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Linear(in_features=366, out_features=224, bias=True)\n",
       "      (3): Sigmoid()\n",
       "      (4): Linear(in_features=224, out_features=79, bias=True)\n",
       "      (5): Sigmoid()\n",
       "      (6): Linear(in_features=79, out_features=313, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Linear(in_features=313, out_features=421, bias=True)\n",
       "      (9): Sigmoid()\n",
       "      (10): Linear(in_features=421, out_features=297, bias=True)\n",
       "      (11): Sigmoid()\n",
       "      (12): Linear(in_features=297, out_features=13, bias=True)\n",
       "      (13): Sigmoid()\n",
       "      (14): Linear(in_features=13, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [366, 224, 79, 313, 421, 297, 13],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.007676777989723527,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.6721221804618835,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.6473470330238342,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 610: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=83, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=83, out_features=64, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=64, out_features=193, bias=True)\n",
       "      (5): ReLU()\n",
       "      (6): Linear(in_features=193, out_features=46, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Linear(in_features=46, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [83, 64, 193, 46],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.007811668409957293,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.713505744934082,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.7148372530937195,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 611: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=73, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=73, out_features=329, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=329, out_features=135, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=135, out_features=477, bias=True)\n",
       "      (10): Sigmoid()\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=477, out_features=462, bias=True)\n",
       "      (13): Sigmoid()\n",
       "      (14): Dropout(p=0.1, inplace=False)\n",
       "      (15): Linear(in_features=462, out_features=214, bias=True)\n",
       "      (16): Sigmoid()\n",
       "      (17): Dropout(p=0.1, inplace=False)\n",
       "      (18): Linear(in_features=214, out_features=384, bias=True)\n",
       "      (19): Sigmoid()\n",
       "      (20): Dropout(p=0.1, inplace=False)\n",
       "      (21): Linear(in_features=384, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [73, 329, 135, 477, 462, 214, 384],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0026035622601208743,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.7257215976715088,\n",
       "  'train_acc': 0.3802083333333333,\n",
       "  'val_loss': 0.7660745978355408,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 612: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=142, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=142, out_features=290, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=290, out_features=407, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=407, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [142, 290, 407],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.002486793996801389,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.7534300684928894,\n",
       "  'train_acc': 0.4036458333333333,\n",
       "  'val_loss': 0.7123433947563171,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 613: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=50, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=50, out_features=81, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=81, out_features=123, bias=True)\n",
       "      (5): LeakyReLU(negative_slope=0.01)\n",
       "      (6): Linear(in_features=123, out_features=247, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Linear(in_features=247, out_features=326, bias=True)\n",
       "      (9): LeakyReLU(negative_slope=0.01)\n",
       "      (10): Linear(in_features=326, out_features=414, bias=True)\n",
       "      (11): LeakyReLU(negative_slope=0.01)\n",
       "      (12): Linear(in_features=414, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [50, 81, 123, 247, 326, 414],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.009020100776034455,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.6889259219169617,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.6310979723930359,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 614: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=35, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=35, out_features=156, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=156, out_features=191, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=191, out_features=309, bias=True)\n",
       "      (10): Sigmoid()\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=309, out_features=358, bias=True)\n",
       "      (13): Sigmoid()\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=358, out_features=198, bias=True)\n",
       "      (16): Sigmoid()\n",
       "      (17): Dropout(p=0.5, inplace=False)\n",
       "      (18): Linear(in_features=198, out_features=79, bias=True)\n",
       "      (19): Sigmoid()\n",
       "      (20): Dropout(p=0.5, inplace=False)\n",
       "      (21): Linear(in_features=79, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [35, 156, 191, 309, 358, 198, 79],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.006908738020190143,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.6548649072647095,\n",
       "  'train_acc': 0.6614583333333334,\n",
       "  'val_loss': 0.8307291865348816,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 615: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=487, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=487, out_features=102, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=102, out_features=62, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=62, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [487, 102, 62],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.007977081352373763,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.7066187858581543,\n",
       "  'train_acc': 0.484375,\n",
       "  'val_loss': 0.6389910578727722,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 616: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=462, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=462, out_features=449, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=449, out_features=325, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=325, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [462, 449, 325],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.00937359773317465,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.6760196089744568,\n",
       "  'train_acc': 0.5859375,\n",
       "  'val_loss': 0.6736500263214111,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 617: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=213, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=213, out_features=509, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=509, out_features=68, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=68, out_features=169, bias=True)\n",
       "      (10): Sigmoid()\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=169, out_features=134, bias=True)\n",
       "      (13): Sigmoid()\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=134, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [213, 509, 68, 169, 134],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.009845991650133903,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.8880641460418701,\n",
       "  'train_acc': 0.3567708333333333,\n",
       "  'val_loss': 0.8254866600036621,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 618: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=433, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=433, out_features=462, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=462, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [433, 462],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.009260158085158243,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.7019832134246826,\n",
       "  'train_acc': 0.5286458333333334,\n",
       "  'val_loss': 0.6413060426712036,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 619: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=334, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=334, out_features=127, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=127, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [334, 127],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.008191334731400372,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.6775584816932678,\n",
       "  'train_acc': 0.6067708333333334,\n",
       "  'val_loss': 0.6584104895591736,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 620: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=310, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=310, out_features=393, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=393, out_features=192, bias=True)\n",
       "      (5): ReLU()\n",
       "      (6): Linear(in_features=192, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [310, 393, 192],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0049628998123746465,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.6877238154411316,\n",
       "  'train_acc': 0.59375,\n",
       "  'val_loss': 0.6891639232635498,\n",
       "  'val_acc': 0.5416666666666666},\n",
       " 621: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=71, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=71, out_features=31, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=31, out_features=477, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=477, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [71, 31, 477],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0019518182709035146,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.7158052325248718,\n",
       "  'train_acc': 0.4635416666666667,\n",
       "  'val_loss': 0.6319116950035095,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 622: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=406, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=406, out_features=312, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=312, out_features=241, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=241, out_features=109, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=109, out_features=500, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=500, out_features=47, bias=True)\n",
       "      (16): ReLU()\n",
       "      (17): Dropout(p=0.5, inplace=False)\n",
       "      (18): Linear(in_features=47, out_features=443, bias=True)\n",
       "      (19): ReLU()\n",
       "      (20): Dropout(p=0.5, inplace=False)\n",
       "      (21): Linear(in_features=443, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [406, 312, 241, 109, 500, 47, 443],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.002824125254217694,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.6881294846534729,\n",
       "  'train_acc': 0.59375,\n",
       "  'val_loss': 0.6883952021598816,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 623: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=76, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=76, out_features=375, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=375, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [76, 375],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.008071374486753772,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.7057486176490784,\n",
       "  'train_acc': 0.453125,\n",
       "  'val_loss': 0.7000076174736023,\n",
       "  'val_acc': 0.40625},\n",
       " 624: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=177, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=177, out_features=398, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=398, out_features=313, bias=True)\n",
       "      (5): LeakyReLU(negative_slope=0.01)\n",
       "      (6): Linear(in_features=313, out_features=77, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Linear(in_features=77, out_features=437, bias=True)\n",
       "      (9): LeakyReLU(negative_slope=0.01)\n",
       "      (10): Linear(in_features=437, out_features=44, bias=True)\n",
       "      (11): LeakyReLU(negative_slope=0.01)\n",
       "      (12): Linear(in_features=44, out_features=329, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Linear(in_features=329, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [177, 398, 313, 77, 437, 44, 329],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.003612660732847132,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.6877400875091553,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.6557585597038269,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 625: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=380, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=380, out_features=98, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=98, out_features=164, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=164, out_features=502, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=502, out_features=324, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.2, inplace=False)\n",
       "      (15): Linear(in_features=324, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [380, 98, 164, 502, 324],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.007159187593090843,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.6939991116523743,\n",
       "  'train_acc': 0.4739583333333333,\n",
       "  'val_loss': 0.6942949295043945,\n",
       "  'val_acc': 0.4166666666666667},\n",
       " 626: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=322, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=322, out_features=141, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=141, out_features=56, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=56, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [322, 141, 56],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.002068538394622581,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.68277907371521,\n",
       "  'train_acc': 0.5833333333333334,\n",
       "  'val_loss': 0.6890206933021545,\n",
       "  'val_acc': 0.6145833333333334},\n",
       " 627: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=14, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=14, out_features=115, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=115, out_features=155, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=155, out_features=473, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=473, out_features=135, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.2, inplace=False)\n",
       "      (15): Linear(in_features=135, out_features=429, bias=True)\n",
       "      (16): LeakyReLU(negative_slope=0.01)\n",
       "      (17): Dropout(p=0.2, inplace=False)\n",
       "      (18): Linear(in_features=429, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [14, 115, 155, 473, 135, 429],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.005325773654927594,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.6984116435050964,\n",
       "  'train_acc': 0.3541666666666667,\n",
       "  'val_loss': 0.6992574334144592,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 628: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=493, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Linear(in_features=493, out_features=336, bias=True)\n",
       "      (3): Sigmoid()\n",
       "      (4): Linear(in_features=336, out_features=423, bias=True)\n",
       "      (5): Sigmoid()\n",
       "      (6): Linear(in_features=423, out_features=14, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Linear(in_features=14, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [493, 336, 423, 14],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.008981772422183162,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.6417995691299438,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.7576088905334473,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 629: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=175, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=175, out_features=493, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=493, out_features=118, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=118, out_features=489, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=489, out_features=352, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.2, inplace=False)\n",
       "      (15): Linear(in_features=352, out_features=44, bias=True)\n",
       "      (16): ReLU()\n",
       "      (17): Dropout(p=0.2, inplace=False)\n",
       "      (18): Linear(in_features=44, out_features=377, bias=True)\n",
       "      (19): ReLU()\n",
       "      (20): Dropout(p=0.2, inplace=False)\n",
       "      (21): Linear(in_features=377, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [175, 493, 118, 489, 352, 44, 377],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.008869948176324655,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.6995086669921875,\n",
       "  'train_acc': 0.3802083333333333,\n",
       "  'val_loss': 0.6978518962860107,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 630: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=205, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=205, out_features=138, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=138, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [205, 138],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.004750710162948896,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.7264983057975769,\n",
       "  'train_acc': 0.4348958333333333,\n",
       "  'val_loss': 0.6293932795524597,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 631: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=292, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=292, out_features=80, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=80, out_features=235, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=235, out_features=472, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=472, out_features=37, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.1, inplace=False)\n",
       "      (15): Linear(in_features=37, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [292, 80, 235, 472, 37],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.007521939796106299,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.6645573377609253,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.72479248046875,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 632: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=174, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=174, out_features=159, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=159, out_features=247, bias=True)\n",
       "      (5): LeakyReLU(negative_slope=0.01)\n",
       "      (6): Linear(in_features=247, out_features=75, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Linear(in_features=75, out_features=403, bias=True)\n",
       "      (9): LeakyReLU(negative_slope=0.01)\n",
       "      (10): Linear(in_features=403, out_features=474, bias=True)\n",
       "      (11): LeakyReLU(negative_slope=0.01)\n",
       "      (12): Linear(in_features=474, out_features=251, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Linear(in_features=251, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [174, 159, 247, 75, 403, 474, 251],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.006866927143824918,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.6814760565757751,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.632041871547699,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 633: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=453, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=453, out_features=371, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=371, out_features=43, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=43, out_features=489, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=489, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [453, 371, 43, 489],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.007206868168039917,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.7103938460350037,\n",
       "  'train_acc': 0.34375,\n",
       "  'val_loss': 0.7093071341514587,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 634: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=160, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=160, out_features=257, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=257, out_features=141, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=141, out_features=155, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=155, out_features=117, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.1, inplace=False)\n",
       "      (15): Linear(in_features=117, out_features=434, bias=True)\n",
       "      (16): ReLU()\n",
       "      (17): Dropout(p=0.1, inplace=False)\n",
       "      (18): Linear(in_features=434, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [160, 257, 141, 155, 117, 434],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0020043028351773118,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.6997997164726257,\n",
       "  'train_acc': 0.3385416666666667,\n",
       "  'val_loss': 0.6716541647911072,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 635: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=325, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=325, out_features=153, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=153, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [325, 153],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.005663151777832509,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.711553156375885,\n",
       "  'train_acc': 0.4661458333333333,\n",
       "  'val_loss': 0.6941726207733154,\n",
       "  'val_acc': 0.5520833333333334},\n",
       " 636: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=186, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=186, out_features=133, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=133, out_features=76, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=76, out_features=475, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=475, out_features=37, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=37, out_features=99, bias=True)\n",
       "      (16): ReLU()\n",
       "      (17): Dropout(p=0.5, inplace=False)\n",
       "      (18): Linear(in_features=99, out_features=39, bias=True)\n",
       "      (19): ReLU()\n",
       "      (20): Dropout(p=0.5, inplace=False)\n",
       "      (21): Linear(in_features=39, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [186, 133, 76, 475, 37, 99, 39],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0023125765131069955,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.6623662114143372,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.6529778838157654,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 637: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=307, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=307, out_features=77, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=77, out_features=189, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=189, out_features=333, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=333, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [307, 77, 189, 333],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0098005318790153,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.7148725390434265,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.7131774425506592,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 638: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=415, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=415, out_features=121, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=121, out_features=365, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=365, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [415, 121, 365],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.006724275888940777,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.6849470734596252,\n",
       "  'train_acc': 0.6119791666666666,\n",
       "  'val_loss': 0.8448511958122253,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 639: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=502, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=502, out_features=432, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=432, out_features=337, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=337, out_features=473, bias=True)\n",
       "      (10): Sigmoid()\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=473, out_features=234, bias=True)\n",
       "      (13): Sigmoid()\n",
       "      (14): Dropout(p=0.1, inplace=False)\n",
       "      (15): Linear(in_features=234, out_features=376, bias=True)\n",
       "      (16): Sigmoid()\n",
       "      (17): Dropout(p=0.1, inplace=False)\n",
       "      (18): Linear(in_features=376, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [502, 432, 337, 473, 234, 376],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.008246266945722374,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.7464046478271484,\n",
       "  'train_acc': 0.3567708333333333,\n",
       "  'val_loss': 0.6756367683410645,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 640: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=71, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=71, out_features=414, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=414, out_features=329, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=329, out_features=87, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=87, out_features=110, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.1, inplace=False)\n",
       "      (15): Linear(in_features=110, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [71, 414, 329, 87, 110],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0013539291928806802,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.6918790936470032,\n",
       "  'train_acc': 0.5729166666666666,\n",
       "  'val_loss': 0.6791377067565918,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 641: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=240, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=240, out_features=130, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=130, out_features=134, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=134, out_features=487, bias=True)\n",
       "      (10): Sigmoid()\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=487, out_features=85, bias=True)\n",
       "      (13): Sigmoid()\n",
       "      (14): Dropout(p=0.2, inplace=False)\n",
       "      (15): Linear(in_features=85, out_features=219, bias=True)\n",
       "      (16): Sigmoid()\n",
       "      (17): Dropout(p=0.2, inplace=False)\n",
       "      (18): Linear(in_features=219, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [240, 130, 134, 487, 85, 219],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.006860761549299698,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.9438746571540833,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.8658735752105713,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 642: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=146, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=146, out_features=259, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=259, out_features=417, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=417, out_features=157, bias=True)\n",
       "      (10): Sigmoid()\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=157, out_features=489, bias=True)\n",
       "      (13): Sigmoid()\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=489, out_features=397, bias=True)\n",
       "      (16): Sigmoid()\n",
       "      (17): Dropout(p=0.5, inplace=False)\n",
       "      (18): Linear(in_features=397, out_features=217, bias=True)\n",
       "      (19): Sigmoid()\n",
       "      (20): Dropout(p=0.5, inplace=False)\n",
       "      (21): Linear(in_features=217, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [146, 259, 417, 157, 489, 397, 217],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.004837354200955206,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.7389258742332458,\n",
       "  'train_acc': 0.4973958333333333,\n",
       "  'val_loss': 0.6953082084655762,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 643: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=59, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Linear(in_features=59, out_features=457, bias=True)\n",
       "      (3): Sigmoid()\n",
       "      (4): Linear(in_features=457, out_features=193, bias=True)\n",
       "      (5): Sigmoid()\n",
       "      (6): Linear(in_features=193, out_features=495, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Linear(in_features=495, out_features=271, bias=True)\n",
       "      (9): Sigmoid()\n",
       "      (10): Linear(in_features=271, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [59, 457, 193, 495, 271],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0049448905988698395,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.7066856026649475,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.685065746307373,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 644: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=211, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=211, out_features=324, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=324, out_features=113, bias=True)\n",
       "      (5): LeakyReLU(negative_slope=0.01)\n",
       "      (6): Linear(in_features=113, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [211, 324, 113],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.002867840987137978,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.7026097774505615,\n",
       "  'train_acc': 0.359375,\n",
       "  'val_loss': 0.706272304058075,\n",
       "  'val_acc': 0.2916666666666667},\n",
       " 645: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=413, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=413, out_features=208, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=208, out_features=74, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=74, out_features=106, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=106, out_features=256, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.2, inplace=False)\n",
       "      (15): Linear(in_features=256, out_features=510, bias=True)\n",
       "      (16): ReLU()\n",
       "      (17): Dropout(p=0.2, inplace=False)\n",
       "      (18): Linear(in_features=510, out_features=163, bias=True)\n",
       "      (19): ReLU()\n",
       "      (20): Dropout(p=0.2, inplace=False)\n",
       "      (21): Linear(in_features=163, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [413, 208, 74, 106, 256, 510, 163],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.002340286298335276,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.7140477299690247,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.682455837726593,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 646: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=170, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=170, out_features=462, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=462, out_features=422, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=422, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [170, 462, 422],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0023841011038912754,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.8726332187652588,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.8307881355285645,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 647: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=183, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=183, out_features=201, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=201, out_features=178, bias=True)\n",
       "      (5): LeakyReLU(negative_slope=0.01)\n",
       "      (6): Linear(in_features=178, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [183, 201, 178],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.00831197934355625,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.6739182472229004,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.8638675212860107,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 648: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=412, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=412, out_features=131, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=131, out_features=454, bias=True)\n",
       "      (5): ReLU()\n",
       "      (6): Linear(in_features=454, out_features=343, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Linear(in_features=343, out_features=44, bias=True)\n",
       "      (9): ReLU()\n",
       "      (10): Linear(in_features=44, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [412, 131, 454, 343, 44],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0026255546297270457,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.6763351559638977,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.6743692755699158,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 649: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=208, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=208, out_features=417, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=417, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [208, 417],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.002011880411488324,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.7236671447753906,\n",
       "  'train_acc': 0.4010416666666667,\n",
       "  'val_loss': 0.6279141306877136,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 650: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=291, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=291, out_features=125, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=125, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [291, 125],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.004786189415828743,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.717634379863739,\n",
       "  'train_acc': 0.3567708333333333,\n",
       "  'val_loss': 0.7153315544128418,\n",
       "  'val_acc': 0.3125},\n",
       " 651: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=493, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=493, out_features=57, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=57, out_features=148, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=148, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [493, 57, 148],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.007963535891068081,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.7187735438346863,\n",
       "  'train_acc': 0.4088541666666667,\n",
       "  'val_loss': 0.6985277533531189,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 652: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=104, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Linear(in_features=104, out_features=473, bias=True)\n",
       "      (3): Sigmoid()\n",
       "      (4): Linear(in_features=473, out_features=19, bias=True)\n",
       "      (5): Sigmoid()\n",
       "      (6): Linear(in_features=19, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [104, 473, 19],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0014905719287831886,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.6628652215003967,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.6345812678337097,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 653: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=129, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=129, out_features=200, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=200, out_features=57, bias=True)\n",
       "      (5): LeakyReLU(negative_slope=0.01)\n",
       "      (6): Linear(in_features=57, out_features=468, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Linear(in_features=468, out_features=501, bias=True)\n",
       "      (9): LeakyReLU(negative_slope=0.01)\n",
       "      (10): Linear(in_features=501, out_features=423, bias=True)\n",
       "      (11): LeakyReLU(negative_slope=0.01)\n",
       "      (12): Linear(in_features=423, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [129, 200, 57, 468, 501, 423],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.005063945169918143,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.6916646361351013,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.6911064982414246,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 654: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=174, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=174, out_features=359, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=359, out_features=238, bias=True)\n",
       "      (5): ReLU()\n",
       "      (6): Linear(in_features=238, out_features=312, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Linear(in_features=312, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [174, 359, 238, 312],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.004560495500287287,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.6836941838264465,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.6488358378410339,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 655: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=301, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=301, out_features=406, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=406, out_features=220, bias=True)\n",
       "      (5): ReLU()\n",
       "      (6): Linear(in_features=220, out_features=59, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Linear(in_features=59, out_features=20, bias=True)\n",
       "      (9): ReLU()\n",
       "      (10): Linear(in_features=20, out_features=243, bias=True)\n",
       "      (11): ReLU()\n",
       "      (12): Linear(in_features=243, out_features=21, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Linear(in_features=21, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [301, 406, 220, 59, 20, 243, 21],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0024878514501394827,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.7398040890693665,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.7438759803771973,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 656: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=271, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=271, out_features=382, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=382, out_features=425, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=425, out_features=148, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=148, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [271, 382, 425, 148],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.007641201896881115,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.6818795204162598,\n",
       "  'train_acc': 0.6119791666666666,\n",
       "  'val_loss': 0.8199245929718018,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 657: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=440, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=440, out_features=49, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=49, out_features=291, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=291, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [440, 49, 291],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.005041936857566108,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.6908735632896423,\n",
       "  'train_acc': 0.5416666666666666,\n",
       "  'val_loss': 0.6866025328636169,\n",
       "  'val_acc': 0.7083333333333334},\n",
       " 658: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=167, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=167, out_features=16, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=16, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [167, 16],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0034540765322121636,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.6983663439750671,\n",
       "  'train_acc': 0.53125,\n",
       "  'val_loss': 0.6924746036529541,\n",
       "  'val_acc': 0.5},\n",
       " 659: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=300, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=300, out_features=307, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=307, out_features=105, bias=True)\n",
       "      (5): LeakyReLU(negative_slope=0.01)\n",
       "      (6): Linear(in_features=105, out_features=449, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Linear(in_features=449, out_features=414, bias=True)\n",
       "      (9): LeakyReLU(negative_slope=0.01)\n",
       "      (10): Linear(in_features=414, out_features=275, bias=True)\n",
       "      (11): LeakyReLU(negative_slope=0.01)\n",
       "      (12): Linear(in_features=275, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [300, 307, 105, 449, 414, 275],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0012092461166224914,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.6910808086395264,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.6700010299682617,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 660: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=368, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=368, out_features=498, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=498, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [368, 498],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0074588769159670155,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.6864671111106873,\n",
       "  'train_acc': 0.59375,\n",
       "  'val_loss': 0.679771900177002,\n",
       "  'val_acc': 0.6145833333333334},\n",
       " 661: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=153, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=153, out_features=458, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=458, out_features=183, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=183, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [153, 458, 183],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.004644538296472689,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.6944055557250977,\n",
       "  'train_acc': 0.4921875,\n",
       "  'val_loss': 0.6941797137260437,\n",
       "  'val_acc': 0.4583333333333333},\n",
       " 662: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=353, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=353, out_features=336, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=336, out_features=18, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=18, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [353, 336, 18],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.007229752286404,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.671133279800415,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.6644564270973206,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 663: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=88, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=88, out_features=419, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=419, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [88, 419],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.001849194992016428,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.7059955596923828,\n",
       "  'train_acc': 0.4166666666666667,\n",
       "  'val_loss': 0.6988242268562317,\n",
       "  'val_acc': 0.40625},\n",
       " 664: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=209, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=209, out_features=447, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=447, out_features=105, bias=True)\n",
       "      (5): LeakyReLU(negative_slope=0.01)\n",
       "      (6): Linear(in_features=105, out_features=32, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Linear(in_features=32, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [209, 447, 105, 32],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0043977510973682455,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.702756404876709,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.7044124007225037,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 665: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=473, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=473, out_features=155, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=155, out_features=431, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=431, out_features=26, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=26, out_features=474, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.2, inplace=False)\n",
       "      (15): Linear(in_features=474, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [473, 155, 431, 26, 474],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.003210980492478133,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.6879284381866455,\n",
       "  'train_acc': 0.6145833333333334,\n",
       "  'val_loss': 0.641590416431427,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 666: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=141, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=141, out_features=331, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=331, out_features=314, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=314, out_features=249, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=249, out_features=389, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=389, out_features=24, bias=True)\n",
       "      (16): LeakyReLU(negative_slope=0.01)\n",
       "      (17): Dropout(p=0.5, inplace=False)\n",
       "      (18): Linear(in_features=24, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [141, 331, 314, 249, 389, 24],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.004564457651846451,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.7173507213592529,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.7187898755073547,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 667: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=33, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=33, out_features=332, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=332, out_features=23, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=23, out_features=96, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=96, out_features=439, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.2, inplace=False)\n",
       "      (15): Linear(in_features=439, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [33, 332, 23, 96, 439],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.00856291129070429,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.6947792172431946,\n",
       "  'train_acc': 0.4479166666666667,\n",
       "  'val_loss': 0.6367608904838562,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 668: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=464, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=464, out_features=37, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=37, out_features=53, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=53, out_features=254, bias=True)\n",
       "      (10): Sigmoid()\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=254, out_features=305, bias=True)\n",
       "      (13): Sigmoid()\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=305, out_features=295, bias=True)\n",
       "      (16): Sigmoid()\n",
       "      (17): Dropout(p=0.5, inplace=False)\n",
       "      (18): Linear(in_features=295, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [464, 37, 53, 254, 305, 295],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.003473632311613549,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.7395254969596863,\n",
       "  'train_acc': 0.4557291666666667,\n",
       "  'val_loss': 0.6911618113517761,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 669: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=333, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=333, out_features=488, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=488, out_features=310, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=310, out_features=174, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=174, out_features=170, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.1, inplace=False)\n",
       "      (15): Linear(in_features=170, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [333, 488, 310, 174, 170],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.009342947735840726,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.6889955401420593,\n",
       "  'train_acc': 0.6354166666666666,\n",
       "  'val_loss': 0.6883406639099121,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 670: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=384, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=384, out_features=247, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=247, out_features=156, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=156, out_features=367, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=367, out_features=50, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=50, out_features=322, bias=True)\n",
       "      (16): ReLU()\n",
       "      (17): Dropout(p=0.5, inplace=False)\n",
       "      (18): Linear(in_features=322, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [384, 247, 156, 367, 50, 322],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.005781070142110061,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.6874206066131592,\n",
       "  'train_acc': 0.5963541666666666,\n",
       "  'val_loss': 0.6844115853309631,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 671: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=129, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=129, out_features=33, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=33, out_features=114, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=114, out_features=454, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=454, out_features=254, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.2, inplace=False)\n",
       "      (15): Linear(in_features=254, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [129, 33, 114, 454, 254],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.005240334274021876,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.7125532627105713,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.6298521161079407,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 672: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=338, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=338, out_features=308, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=308, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [338, 308],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.006029709147935034,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.6847653388977051,\n",
       "  'train_acc': 0.5442708333333334,\n",
       "  'val_loss': 0.6720256805419922,\n",
       "  'val_acc': 0.6666666666666666},\n",
       " 673: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=39, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=39, out_features=410, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=410, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [39, 410],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.009508817078888319,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.6936182975769043,\n",
       "  'train_acc': 0.515625,\n",
       "  'val_loss': 0.684719979763031,\n",
       "  'val_acc': 0.5625},\n",
       " 674: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=409, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=409, out_features=127, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=127, out_features=497, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=497, out_features=312, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=312, out_features=337, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=337, out_features=367, bias=True)\n",
       "      (16): LeakyReLU(negative_slope=0.01)\n",
       "      (17): Dropout(p=0.5, inplace=False)\n",
       "      (18): Linear(in_features=367, out_features=213, bias=True)\n",
       "      (19): LeakyReLU(negative_slope=0.01)\n",
       "      (20): Dropout(p=0.5, inplace=False)\n",
       "      (21): Linear(in_features=213, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [409, 127, 497, 312, 337, 367, 213],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.005620538321912353,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.7053012847900391,\n",
       "  'train_acc': 0.34375,\n",
       "  'val_loss': 0.706893265247345,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 675: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=259, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=259, out_features=357, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=357, out_features=468, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=468, out_features=278, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=278, out_features=194, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=194, out_features=165, bias=True)\n",
       "      (16): ReLU()\n",
       "      (17): Dropout(p=0.5, inplace=False)\n",
       "      (18): Linear(in_features=165, out_features=410, bias=True)\n",
       "      (19): ReLU()\n",
       "      (20): Dropout(p=0.5, inplace=False)\n",
       "      (21): Linear(in_features=410, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [259, 357, 468, 278, 194, 165, 410],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.008872995666911417,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.6985470652580261,\n",
       "  'train_acc': 0.4088541666666667,\n",
       "  'val_loss': 0.6499136686325073,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 676: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=387, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=387, out_features=293, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=293, out_features=331, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=331, out_features=212, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=212, out_features=319, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.1, inplace=False)\n",
       "      (15): Linear(in_features=319, out_features=331, bias=True)\n",
       "      (16): ReLU()\n",
       "      (17): Dropout(p=0.1, inplace=False)\n",
       "      (18): Linear(in_features=331, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [387, 293, 331, 212, 319, 331],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.00888573057203296,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.691764771938324,\n",
       "  'train_acc': 0.6171875,\n",
       "  'val_loss': 0.6904416084289551,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 677: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=260, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=260, out_features=118, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=118, out_features=220, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=220, out_features=53, bias=True)\n",
       "      (10): Sigmoid()\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=53, out_features=325, bias=True)\n",
       "      (13): Sigmoid()\n",
       "      (14): Dropout(p=0.2, inplace=False)\n",
       "      (15): Linear(in_features=325, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [260, 118, 220, 53, 325],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.006946753275851886,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.7928978800773621,\n",
       "  'train_acc': 0.34375,\n",
       "  'val_loss': 0.7241106033325195,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 678: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=276, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=276, out_features=207, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=207, out_features=422, bias=True)\n",
       "      (5): LeakyReLU(negative_slope=0.01)\n",
       "      (6): Linear(in_features=422, out_features=268, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Linear(in_features=268, out_features=334, bias=True)\n",
       "      (9): LeakyReLU(negative_slope=0.01)\n",
       "      (10): Linear(in_features=334, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [276, 207, 422, 268, 334],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0048634074008992775,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.6780421137809753,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.6529462933540344,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 679: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=357, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=357, out_features=346, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=346, out_features=64, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=64, out_features=508, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=508, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [357, 346, 64, 508],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.006098806677987615,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.7056694626808167,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.7045576572418213,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 680: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=471, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=471, out_features=379, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=379, out_features=237, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=237, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [471, 379, 237],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0017135211524258779,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.8882003426551819,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.6301044821739197,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 681: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=143, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=143, out_features=335, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=335, out_features=347, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=347, out_features=380, bias=True)\n",
       "      (10): Sigmoid()\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=380, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [143, 335, 347, 380],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.002523509527218958,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.686367928981781,\n",
       "  'train_acc': 0.5572916666666666,\n",
       "  'val_loss': 0.8898898959159851,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 682: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=445, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=445, out_features=411, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=411, out_features=49, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=49, out_features=423, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=423, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [445, 411, 49, 423],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.004066560667060718,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.6868931651115417,\n",
       "  'train_acc': 0.5677083333333334,\n",
       "  'val_loss': 0.6285929083824158,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 683: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=314, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=314, out_features=412, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=412, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [314, 412],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.004269494224935705,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.7045361995697021,\n",
       "  'train_acc': 0.5234375,\n",
       "  'val_loss': 0.6878584027290344,\n",
       "  'val_acc': 0.5833333333333334},\n",
       " 684: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=24, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=24, out_features=22, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=22, out_features=259, bias=True)\n",
       "      (5): LeakyReLU(negative_slope=0.01)\n",
       "      (6): Linear(in_features=259, out_features=394, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Linear(in_features=394, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [24, 22, 259, 394],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.009610576430326891,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.6857947707176208,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.7365412712097168,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 685: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=388, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=388, out_features=325, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=325, out_features=22, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=22, out_features=212, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=212, out_features=332, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.2, inplace=False)\n",
       "      (15): Linear(in_features=332, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [388, 325, 22, 212, 332],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.003456430171022344,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.6889772415161133,\n",
       "  'train_acc': 0.6171875,\n",
       "  'val_loss': 0.6417732238769531,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 686: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=460, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=460, out_features=89, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=89, out_features=217, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=217, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [460, 89, 217],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0036674587023316956,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.6928002834320068,\n",
       "  'train_acc': 0.4895833333333333,\n",
       "  'val_loss': 0.6915974020957947,\n",
       "  'val_acc': 0.53125},\n",
       " 687: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=228, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=228, out_features=288, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=288, out_features=194, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=194, out_features=204, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=204, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [228, 288, 194, 204],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.008970139873132426,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.6962737441062927,\n",
       "  'train_acc': 0.4453125,\n",
       "  'val_loss': 0.6953837275505066,\n",
       "  'val_acc': 0.375},\n",
       " 688: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=25, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=25, out_features=128, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=128, out_features=366, bias=True)\n",
       "      (5): LeakyReLU(negative_slope=0.01)\n",
       "      (6): Linear(in_features=366, out_features=138, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Linear(in_features=138, out_features=139, bias=True)\n",
       "      (9): LeakyReLU(negative_slope=0.01)\n",
       "      (10): Linear(in_features=139, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [25, 128, 366, 138, 139],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.003494136717091512,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.6983302235603333,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.6563943028450012,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 689: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=68, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=68, out_features=52, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=52, out_features=273, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=273, out_features=119, bias=True)\n",
       "      (10): Sigmoid()\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=119, out_features=313, bias=True)\n",
       "      (13): Sigmoid()\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=313, out_features=379, bias=True)\n",
       "      (16): Sigmoid()\n",
       "      (17): Dropout(p=0.5, inplace=False)\n",
       "      (18): Linear(in_features=379, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [68, 52, 273, 119, 313, 379],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0015644779164586398,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.7021427154541016,\n",
       "  'train_acc': 0.53125,\n",
       "  'val_loss': 0.6685409545898438,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 690: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=133, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=133, out_features=230, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=230, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [133, 230],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.006087101609181793,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.7052082419395447,\n",
       "  'train_acc': 0.4583333333333333,\n",
       "  'val_loss': 0.6517090201377869,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 691: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=425, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=425, out_features=170, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=170, out_features=315, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=315, out_features=290, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=290, out_features=321, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=321, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [425, 170, 315, 290, 321],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.008452569894341875,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.6773218512535095,\n",
       "  'train_acc': 0.6458333333333334,\n",
       "  'val_loss': 0.6749987006187439,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 692: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=331, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=331, out_features=466, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=466, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [331, 466],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0014784917611645554,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.7610542178153992,\n",
       "  'train_acc': 0.3697916666666667,\n",
       "  'val_loss': 0.6324616074562073,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 693: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=183, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=183, out_features=414, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=414, out_features=369, bias=True)\n",
       "      (5): ReLU()\n",
       "      (6): Linear(in_features=369, out_features=325, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Linear(in_features=325, out_features=295, bias=True)\n",
       "      (9): ReLU()\n",
       "      (10): Linear(in_features=295, out_features=216, bias=True)\n",
       "      (11): ReLU()\n",
       "      (12): Linear(in_features=216, out_features=410, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Linear(in_features=410, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [183, 414, 369, 325, 295, 216, 410],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.008413473277518027,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.6946189403533936,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.6940918564796448,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 694: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=147, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=147, out_features=48, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=48, out_features=477, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=477, out_features=83, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=83, out_features=197, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=197, out_features=388, bias=True)\n",
       "      (16): LeakyReLU(negative_slope=0.01)\n",
       "      (17): Dropout(p=0.5, inplace=False)\n",
       "      (18): Linear(in_features=388, out_features=209, bias=True)\n",
       "      (19): LeakyReLU(negative_slope=0.01)\n",
       "      (20): Dropout(p=0.5, inplace=False)\n",
       "      (21): Linear(in_features=209, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [147, 48, 477, 83, 197, 388, 209],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.002282497389383245,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.690115749835968,\n",
       "  'train_acc': 0.5989583333333334,\n",
       "  'val_loss': 0.6665470004081726,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 695: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=509, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=509, out_features=469, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=469, out_features=487, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=487, out_features=128, bias=True)\n",
       "      (10): Sigmoid()\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=128, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [509, 469, 487, 128],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.008862721188818038,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.6573096513748169,\n",
       "  'train_acc': 0.6510416666666666,\n",
       "  'val_loss': 0.6470497846603394,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 696: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=148, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Linear(in_features=148, out_features=415, bias=True)\n",
       "      (3): Sigmoid()\n",
       "      (4): Linear(in_features=415, out_features=186, bias=True)\n",
       "      (5): Sigmoid()\n",
       "      (6): Linear(in_features=186, out_features=488, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Linear(in_features=488, out_features=267, bias=True)\n",
       "      (9): Sigmoid()\n",
       "      (10): Linear(in_features=267, out_features=442, bias=True)\n",
       "      (11): Sigmoid()\n",
       "      (12): Linear(in_features=442, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [148, 415, 186, 488, 267, 442],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0027919140380129057,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.7977805733680725,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.8447826504707336,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 697: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=280, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=280, out_features=470, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=470, out_features=110, bias=True)\n",
       "      (5): ReLU()\n",
       "      (6): Linear(in_features=110, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [280, 470, 110],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0013985837982689556,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.6839256286621094,\n",
       "  'train_acc': 0.609375,\n",
       "  'val_loss': 0.6853749752044678,\n",
       "  'val_acc': 0.6458333333333334},\n",
       " 698: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=64, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=64, out_features=286, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=286, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [64, 286],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0032912084303151055,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.6682208180427551,\n",
       "  'train_acc': 0.6380208333333334,\n",
       "  'val_loss': 0.6701838374137878,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 699: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=430, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=430, out_features=266, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=266, out_features=260, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=260, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [430, 266, 260],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0018150410389069084,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.7037572860717773,\n",
       "  'train_acc': 0.421875,\n",
       "  'val_loss': 0.6987585425376892,\n",
       "  'val_acc': 0.40625},\n",
       " 700: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=176, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=176, out_features=95, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=95, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [176, 95],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0018842979062925974,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.7087644934654236,\n",
       "  'train_acc': 0.3776041666666667,\n",
       "  'val_loss': 0.7120506763458252,\n",
       "  'val_acc': 0.3541666666666667},\n",
       " 701: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=127, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=127, out_features=308, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=308, out_features=51, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=51, out_features=500, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=500, out_features=385, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.2, inplace=False)\n",
       "      (15): Linear(in_features=385, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [127, 308, 51, 500, 385],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0027459644132291853,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.6955263614654541,\n",
       "  'train_acc': 0.4010416666666667,\n",
       "  'val_loss': 0.6951630115509033,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 702: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=55, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=55, out_features=404, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=404, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [55, 404],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.009300859379393778,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.6850801110267639,\n",
       "  'train_acc': 0.5833333333333334,\n",
       "  'val_loss': 0.7614704966545105,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 703: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=287, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=287, out_features=97, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=97, out_features=166, bias=True)\n",
       "      (5): ReLU()\n",
       "      (6): Linear(in_features=166, out_features=96, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Linear(in_features=96, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [287, 97, 166, 96],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.004281555308820911,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.706956684589386,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.7083449959754944,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 704: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=279, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=279, out_features=250, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=250, out_features=131, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=131, out_features=174, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=174, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [279, 250, 131, 174],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.005223703800141357,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.6919472813606262,\n",
       "  'train_acc': 0.5625,\n",
       "  'val_loss': 0.6918239593505859,\n",
       "  'val_acc': 0.6041666666666666},\n",
       " 705: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=378, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=378, out_features=435, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=435, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [378, 435],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0014931423213074935,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.6846283078193665,\n",
       "  'train_acc': 0.5729166666666666,\n",
       "  'val_loss': 0.7289068102836609,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 706: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=63, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=63, out_features=493, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=493, out_features=24, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=24, out_features=326, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=326, out_features=260, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.1, inplace=False)\n",
       "      (15): Linear(in_features=260, out_features=271, bias=True)\n",
       "      (16): LeakyReLU(negative_slope=0.01)\n",
       "      (17): Dropout(p=0.1, inplace=False)\n",
       "      (18): Linear(in_features=271, out_features=238, bias=True)\n",
       "      (19): LeakyReLU(negative_slope=0.01)\n",
       "      (20): Dropout(p=0.1, inplace=False)\n",
       "      (21): Linear(in_features=238, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [63, 493, 24, 326, 260, 271, 238],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.004327593871527912,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.690104067325592,\n",
       "  'train_acc': 0.6536458333333334,\n",
       "  'val_loss': 0.6897484660148621,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 707: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=382, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=382, out_features=134, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=134, out_features=405, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=405, out_features=325, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=325, out_features=97, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.1, inplace=False)\n",
       "      (15): Linear(in_features=97, out_features=35, bias=True)\n",
       "      (16): ReLU()\n",
       "      (17): Dropout(p=0.1, inplace=False)\n",
       "      (18): Linear(in_features=35, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [382, 134, 405, 325, 97, 35],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.003088085614105628,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.7302084565162659,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.7337813973426819,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 708: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=24, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Linear(in_features=24, out_features=447, bias=True)\n",
       "      (3): Sigmoid()\n",
       "      (4): Linear(in_features=447, out_features=268, bias=True)\n",
       "      (5): Sigmoid()\n",
       "      (6): Linear(in_features=268, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [24, 447, 268],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.004692727390833399,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.65080726146698,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.6404467225074768,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 709: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=493, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=493, out_features=475, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=475, out_features=337, bias=True)\n",
       "      (5): LeakyReLU(negative_slope=0.01)\n",
       "      (6): Linear(in_features=337, out_features=351, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Linear(in_features=351, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [493, 475, 337, 351],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.005910660729033814,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.6954514384269714,\n",
       "  'train_acc': 0.4010416666666667,\n",
       "  'val_loss': 0.6964128017425537,\n",
       "  'val_acc': 0.2708333333333333},\n",
       " 710: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=123, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=123, out_features=279, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=279, out_features=500, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=500, out_features=501, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=501, out_features=450, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.1, inplace=False)\n",
       "      (15): Linear(in_features=450, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [123, 279, 500, 501, 450],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.006555115125425178,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.6965353488922119,\n",
       "  'train_acc': 0.3541666666666667,\n",
       "  'val_loss': 0.6964098811149597,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 711: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=274, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=274, out_features=103, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=103, out_features=129, bias=True)\n",
       "      (5): LeakyReLU(negative_slope=0.01)\n",
       "      (6): Linear(in_features=129, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [274, 103, 129],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0025566605530432307,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.7056058049201965,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.6607396006584167,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 712: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=235, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=235, out_features=227, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=227, out_features=99, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=99, out_features=388, bias=True)\n",
       "      (10): Sigmoid()\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=388, out_features=208, bias=True)\n",
       "      (13): Sigmoid()\n",
       "      (14): Dropout(p=0.2, inplace=False)\n",
       "      (15): Linear(in_features=208, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [235, 227, 99, 388, 208],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.007298565720045238,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.6450074315071106,\n",
       "  'train_acc': 0.65625,\n",
       "  'val_loss': 0.6300749182701111,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 713: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=293, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=293, out_features=62, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=62, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [293, 62],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.006777317368101138,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.7380959987640381,\n",
       "  'train_acc': 0.3515625,\n",
       "  'val_loss': 0.7436545491218567,\n",
       "  'val_acc': 0.3333333333333333},\n",
       " 714: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=145, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=145, out_features=19, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=19, out_features=324, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=324, out_features=459, bias=True)\n",
       "      (10): Sigmoid()\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=459, out_features=360, bias=True)\n",
       "      (13): Sigmoid()\n",
       "      (14): Dropout(p=0.1, inplace=False)\n",
       "      (15): Linear(in_features=360, out_features=45, bias=True)\n",
       "      (16): Sigmoid()\n",
       "      (17): Dropout(p=0.1, inplace=False)\n",
       "      (18): Linear(in_features=45, out_features=120, bias=True)\n",
       "      (19): Sigmoid()\n",
       "      (20): Dropout(p=0.1, inplace=False)\n",
       "      (21): Linear(in_features=120, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [145, 19, 324, 459, 360, 45, 120],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.009445293459131258,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.7090821862220764,\n",
       "  'train_acc': 0.4348958333333333,\n",
       "  'val_loss': 0.7125651836395264,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 715: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=25, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=25, out_features=248, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=248, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [25, 248],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.008900956536794517,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.687849223613739,\n",
       "  'train_acc': 0.5651041666666666,\n",
       "  'val_loss': 0.6389612555503845,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 716: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=477, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=477, out_features=340, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=340, out_features=323, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=323, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [477, 340, 323],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.003302854379725728,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.648798406124115,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.6412948966026306,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 717: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=403, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=403, out_features=32, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=32, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [403, 32],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.003902392892260079,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.6575555205345154,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.633429765701294,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 718: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=306, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=306, out_features=361, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=361, out_features=284, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=284, out_features=263, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=263, out_features=379, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.2, inplace=False)\n",
       "      (15): Linear(in_features=379, out_features=300, bias=True)\n",
       "      (16): ReLU()\n",
       "      (17): Dropout(p=0.2, inplace=False)\n",
       "      (18): Linear(in_features=300, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [306, 361, 284, 263, 379, 300],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.004197732222560677,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.6923215985298157,\n",
       "  'train_acc': 0.5911458333333334,\n",
       "  'val_loss': 0.6299257874488831,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 719: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=416, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=416, out_features=302, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=302, out_features=391, bias=True)\n",
       "      (5): ReLU()\n",
       "      (6): Linear(in_features=391, out_features=442, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Linear(in_features=442, out_features=344, bias=True)\n",
       "      (9): ReLU()\n",
       "      (10): Linear(in_features=344, out_features=40, bias=True)\n",
       "      (11): ReLU()\n",
       "      (12): Linear(in_features=40, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [416, 302, 391, 442, 344, 40],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.004354647581058515,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.7027203440666199,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.7033292651176453,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 720: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=354, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=354, out_features=207, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=207, out_features=471, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=471, out_features=372, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=372, out_features=207, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=207, out_features=51, bias=True)\n",
       "      (16): ReLU()\n",
       "      (17): Dropout(p=0.5, inplace=False)\n",
       "      (18): Linear(in_features=51, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [354, 207, 471, 372, 207, 51],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.004828413841399728,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.6802944540977478,\n",
       "  'train_acc': 0.6536458333333334,\n",
       "  'val_loss': 0.6448025107383728,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 721: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=351, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=351, out_features=414, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=414, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [351, 414],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0024955736382366437,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.693996012210846,\n",
       "  'train_acc': 0.5286458333333334,\n",
       "  'val_loss': 0.6789187788963318,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 722: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=459, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=459, out_features=26, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=26, out_features=488, bias=True)\n",
       "      (5): LeakyReLU(negative_slope=0.01)\n",
       "      (6): Linear(in_features=488, out_features=65, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Linear(in_features=65, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [459, 26, 488, 65],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0055326771483585405,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.6913056373596191,\n",
       "  'train_acc': 0.5520833333333334,\n",
       "  'val_loss': 0.6324836611747742,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 723: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=103, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=103, out_features=93, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=93, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [103, 93],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.00864320129910309,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.6765184998512268,\n",
       "  'train_acc': 0.625,\n",
       "  'val_loss': 0.6362905502319336,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 724: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=499, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=499, out_features=326, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=326, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [499, 326],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.00103021052667968,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.7106106877326965,\n",
       "  'train_acc': 0.5,\n",
       "  'val_loss': 0.6369745135307312,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 725: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=473, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=473, out_features=266, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=266, out_features=51, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=51, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [473, 266, 51],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.003446874300339185,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.6745676398277283,\n",
       "  'train_acc': 0.5885416666666666,\n",
       "  'val_loss': 0.6721868515014648,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 726: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=493, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=493, out_features=468, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=468, out_features=351, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=351, out_features=212, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=212, out_features=351, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.2, inplace=False)\n",
       "      (15): Linear(in_features=351, out_features=305, bias=True)\n",
       "      (16): LeakyReLU(negative_slope=0.01)\n",
       "      (17): Dropout(p=0.2, inplace=False)\n",
       "      (18): Linear(in_features=305, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [493, 468, 351, 212, 351, 305],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0059258126561304875,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.6841755509376526,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.7134631276130676,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 727: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=398, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=398, out_features=153, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=153, out_features=263, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=263, out_features=206, bias=True)\n",
       "      (10): Sigmoid()\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=206, out_features=277, bias=True)\n",
       "      (13): Sigmoid()\n",
       "      (14): Dropout(p=0.1, inplace=False)\n",
       "      (15): Linear(in_features=277, out_features=448, bias=True)\n",
       "      (16): Sigmoid()\n",
       "      (17): Dropout(p=0.1, inplace=False)\n",
       "      (18): Linear(in_features=448, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [398, 153, 263, 206, 277, 448],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.008650208322269879,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.6787680983543396,\n",
       "  'train_acc': 0.5729166666666666,\n",
       "  'val_loss': 0.6467575430870056,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 728: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=403, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=403, out_features=77, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=77, out_features=292, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=292, out_features=103, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=103, out_features=320, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.2, inplace=False)\n",
       "      (15): Linear(in_features=320, out_features=221, bias=True)\n",
       "      (16): LeakyReLU(negative_slope=0.01)\n",
       "      (17): Dropout(p=0.2, inplace=False)\n",
       "      (18): Linear(in_features=221, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [403, 77, 292, 103, 320, 221],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.006332450882722878,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.7170844078063965,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.7188026309013367,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 729: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=124, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=124, out_features=344, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=344, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [124, 344],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0038608410957249,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.6668865084648132,\n",
       "  'train_acc': 0.6458333333333334,\n",
       "  'val_loss': 0.6420812010765076,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 730: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=409, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=409, out_features=374, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=374, out_features=103, bias=True)\n",
       "      (5): LeakyReLU(negative_slope=0.01)\n",
       "      (6): Linear(in_features=103, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [409, 374, 103],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.004526045560396593,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.6731011271476746,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.7952955365180969,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 731: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=297, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=297, out_features=28, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=28, out_features=126, bias=True)\n",
       "      (5): ReLU()\n",
       "      (6): Linear(in_features=126, out_features=164, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Linear(in_features=164, out_features=165, bias=True)\n",
       "      (9): ReLU()\n",
       "      (10): Linear(in_features=165, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [297, 28, 126, 164, 165],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.00974090844009266,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.6929609179496765,\n",
       "  'train_acc': 0.5182291666666666,\n",
       "  'val_loss': 0.6923208236694336,\n",
       "  'val_acc': 0.6979166666666666},\n",
       " 732: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=84, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=84, out_features=188, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=188, out_features=306, bias=True)\n",
       "      (5): ReLU()\n",
       "      (6): Linear(in_features=306, out_features=102, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Linear(in_features=102, out_features=293, bias=True)\n",
       "      (9): ReLU()\n",
       "      (10): Linear(in_features=293, out_features=114, bias=True)\n",
       "      (11): ReLU()\n",
       "      (12): Linear(in_features=114, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [84, 188, 306, 102, 293, 114],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.009001873115812256,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.6912927031517029,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.6904714107513428,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 733: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=221, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=221, out_features=313, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=313, out_features=301, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=301, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [221, 313, 301],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.007671978486108429,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.7093812823295593,\n",
       "  'train_acc': 0.3619791666666667,\n",
       "  'val_loss': 0.7032048106193542,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 734: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=102, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Linear(in_features=102, out_features=493, bias=True)\n",
       "      (3): Sigmoid()\n",
       "      (4): Linear(in_features=493, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [102, 493],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.005382421187881456,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.7221243381500244,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.6741840243339539,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 735: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=485, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=485, out_features=16, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=16, out_features=383, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=383, out_features=386, bias=True)\n",
       "      (10): Sigmoid()\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=386, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [485, 16, 383, 386],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.005591634893040008,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.6738286018371582,\n",
       "  'train_acc': 0.6484375,\n",
       "  'val_loss': 0.6305949091911316,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 736: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=376, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=376, out_features=318, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=318, out_features=263, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=263, out_features=395, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=395, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [376, 318, 263, 395],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.001913475546085599,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.6947625279426575,\n",
       "  'train_acc': 0.4583333333333333,\n",
       "  'val_loss': 0.692843496799469,\n",
       "  'val_acc': 0.53125},\n",
       " 737: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=438, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=438, out_features=370, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=370, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [438, 370],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0010982836242883938,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.6748791337013245,\n",
       "  'train_acc': 0.6302083333333334,\n",
       "  'val_loss': 0.6220530867576599,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 738: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=375, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=375, out_features=465, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=465, out_features=32, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=32, out_features=26, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=26, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [375, 465, 32, 26],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.003753034315243145,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.7186515927314758,\n",
       "  'train_acc': 0.3828125,\n",
       "  'val_loss': 0.7164010405540466,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 739: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=14, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=14, out_features=288, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=288, out_features=294, bias=True)\n",
       "      (5): ReLU()\n",
       "      (6): Linear(in_features=294, out_features=420, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Linear(in_features=420, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [14, 288, 294, 420],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.007295509007889417,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.7038564085960388,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.7840516567230225,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 740: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=317, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=317, out_features=304, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=304, out_features=352, bias=True)\n",
       "      (5): LeakyReLU(negative_slope=0.01)\n",
       "      (6): Linear(in_features=352, out_features=106, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Linear(in_features=106, out_features=347, bias=True)\n",
       "      (9): LeakyReLU(negative_slope=0.01)\n",
       "      (10): Linear(in_features=347, out_features=450, bias=True)\n",
       "      (11): LeakyReLU(negative_slope=0.01)\n",
       "      (12): Linear(in_features=450, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [317, 304, 352, 106, 347, 450],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.009504585215248437,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.6936740875244141,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.6929237842559814,\n",
       "  'val_acc': 0.6145833333333334},\n",
       " 741: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=38, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=38, out_features=286, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=286, out_features=31, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=31, out_features=351, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=351, out_features=503, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.2, inplace=False)\n",
       "      (15): Linear(in_features=503, out_features=305, bias=True)\n",
       "      (16): ReLU()\n",
       "      (17): Dropout(p=0.2, inplace=False)\n",
       "      (18): Linear(in_features=305, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [38, 286, 31, 351, 503, 305],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.00269425678264276,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.6857039928436279,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.6841445565223694,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 742: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=207, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=207, out_features=276, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=276, out_features=422, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=422, out_features=455, bias=True)\n",
       "      (10): Sigmoid()\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=455, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [207, 276, 422, 455],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.007639772390061507,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.6510432958602905,\n",
       "  'train_acc': 0.6510416666666666,\n",
       "  'val_loss': 0.632882833480835,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 743: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=382, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=382, out_features=131, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=131, out_features=48, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=48, out_features=332, bias=True)\n",
       "      (10): Sigmoid()\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=332, out_features=24, bias=True)\n",
       "      (13): Sigmoid()\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=24, out_features=34, bias=True)\n",
       "      (16): Sigmoid()\n",
       "      (17): Dropout(p=0.5, inplace=False)\n",
       "      (18): Linear(in_features=34, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [382, 131, 48, 332, 24, 34],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.006265898922188439,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.8490898609161377,\n",
       "  'train_acc': 0.3697916666666667,\n",
       "  'val_loss': 0.7297544479370117,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 744: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=85, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=85, out_features=261, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=261, out_features=182, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=182, out_features=302, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=302, out_features=509, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.2, inplace=False)\n",
       "      (15): Linear(in_features=509, out_features=359, bias=True)\n",
       "      (16): LeakyReLU(negative_slope=0.01)\n",
       "      (17): Dropout(p=0.2, inplace=False)\n",
       "      (18): Linear(in_features=359, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [85, 261, 182, 302, 509, 359],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.007534584427383614,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.6862562298774719,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.6849285960197449,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 745: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=464, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=464, out_features=92, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=92, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [464, 92],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.005969526603022734,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.7153878211975098,\n",
       "  'train_acc': 0.4270833333333333,\n",
       "  'val_loss': 0.7031719088554382,\n",
       "  'val_acc': 0.4479166666666667},\n",
       " 746: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=223, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=223, out_features=81, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=81, out_features=116, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=116, out_features=164, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=164, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [223, 81, 116, 164],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.002131585866570156,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.6835484504699707,\n",
       "  'train_acc': 0.6536458333333334,\n",
       "  'val_loss': 0.6600956320762634,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 747: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=317, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=317, out_features=18, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=18, out_features=113, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=113, out_features=265, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=265, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [317, 18, 113, 265],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.007615971809264026,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.6778669953346252,\n",
       "  'train_acc': 0.6223958333333334,\n",
       "  'val_loss': 0.6323121786117554,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 748: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=103, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=103, out_features=80, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=80, out_features=373, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=373, out_features=295, bias=True)\n",
       "      (10): Sigmoid()\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=295, out_features=87, bias=True)\n",
       "      (13): Sigmoid()\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=87, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [103, 80, 373, 295, 87],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.005978295694975014,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.8528063297271729,\n",
       "  'train_acc': 0.359375,\n",
       "  'val_loss': 0.8103625178337097,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 749: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=146, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=146, out_features=236, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=236, out_features=199, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=199, out_features=343, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=343, out_features=164, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.1, inplace=False)\n",
       "      (15): Linear(in_features=164, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [146, 236, 199, 343, 164],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.008845174836184935,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.6923603415489197,\n",
       "  'train_acc': 0.5104166666666666,\n",
       "  'val_loss': 0.6921772360801697,\n",
       "  'val_acc': 0.6458333333333334},\n",
       " 750: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=18, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=18, out_features=78, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=78, out_features=74, bias=True)\n",
       "      (5): ReLU()\n",
       "      (6): Linear(in_features=74, out_features=131, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Linear(in_features=131, out_features=54, bias=True)\n",
       "      (9): ReLU()\n",
       "      (10): Linear(in_features=54, out_features=417, bias=True)\n",
       "      (11): ReLU()\n",
       "      (12): Linear(in_features=417, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [18, 78, 74, 131, 54, 417],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.004507298258361763,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.6929081082344055,\n",
       "  'train_acc': 0.5677083333333334,\n",
       "  'val_loss': 0.6920478940010071,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 751: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=415, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=415, out_features=140, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=140, out_features=119, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=119, out_features=304, bias=True)\n",
       "      (10): Sigmoid()\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=304, out_features=486, bias=True)\n",
       "      (13): Sigmoid()\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=486, out_features=280, bias=True)\n",
       "      (16): Sigmoid()\n",
       "      (17): Dropout(p=0.5, inplace=False)\n",
       "      (18): Linear(in_features=280, out_features=282, bias=True)\n",
       "      (19): Sigmoid()\n",
       "      (20): Dropout(p=0.5, inplace=False)\n",
       "      (21): Linear(in_features=282, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [415, 140, 119, 304, 486, 280, 282],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0057299458984525565,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.7178544402122498,\n",
       "  'train_acc': 0.4973958333333333,\n",
       "  'val_loss': 0.6692714095115662,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 752: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=206, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=206, out_features=28, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=28, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [206, 28],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.006687373683748236,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.6672356128692627,\n",
       "  'train_acc': 0.6380208333333334,\n",
       "  'val_loss': 0.6312426328659058,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 753: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=329, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=329, out_features=128, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=128, out_features=451, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=451, out_features=489, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=489, out_features=381, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.1, inplace=False)\n",
       "      (15): Linear(in_features=381, out_features=104, bias=True)\n",
       "      (16): ReLU()\n",
       "      (17): Dropout(p=0.1, inplace=False)\n",
       "      (18): Linear(in_features=104, out_features=358, bias=True)\n",
       "      (19): ReLU()\n",
       "      (20): Dropout(p=0.1, inplace=False)\n",
       "      (21): Linear(in_features=358, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [329, 128, 451, 489, 381, 104, 358],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.006518277999330401,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.6970884203910828,\n",
       "  'train_acc': 0.3463541666666667,\n",
       "  'val_loss': 0.6929418444633484,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 754: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=487, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=487, out_features=130, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=130, out_features=77, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=77, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [487, 130, 77],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.008684012652855172,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.7302466034889221,\n",
       "  'train_acc': 0.34375,\n",
       "  'val_loss': 0.7303602695465088,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 755: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=41, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=41, out_features=326, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=326, out_features=476, bias=True)\n",
       "      (5): LeakyReLU(negative_slope=0.01)\n",
       "      (6): Linear(in_features=476, out_features=449, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Linear(in_features=449, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [41, 326, 476, 449],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0058774471727759325,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.7042225003242493,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.7056028246879578,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 756: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=220, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=220, out_features=323, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=323, out_features=208, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=208, out_features=194, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=194, out_features=206, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.2, inplace=False)\n",
       "      (15): Linear(in_features=206, out_features=153, bias=True)\n",
       "      (16): ReLU()\n",
       "      (17): Dropout(p=0.2, inplace=False)\n",
       "      (18): Linear(in_features=153, out_features=126, bias=True)\n",
       "      (19): ReLU()\n",
       "      (20): Dropout(p=0.2, inplace=False)\n",
       "      (21): Linear(in_features=126, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [220, 323, 208, 194, 206, 153, 126],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.007868318014686525,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.6816784739494324,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.6791693568229675,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 757: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=239, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=239, out_features=301, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=301, out_features=202, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=202, out_features=125, bias=True)\n",
       "      (10): Sigmoid()\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=125, out_features=294, bias=True)\n",
       "      (13): Sigmoid()\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=294, out_features=98, bias=True)\n",
       "      (16): Sigmoid()\n",
       "      (17): Dropout(p=0.5, inplace=False)\n",
       "      (18): Linear(in_features=98, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [239, 301, 202, 125, 294, 98],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0029292154089303776,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.7176865935325623,\n",
       "  'train_acc': 0.4661458333333333,\n",
       "  'val_loss': 0.7003996968269348,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 758: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=288, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=288, out_features=333, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=333, out_features=32, bias=True)\n",
       "      (5): ReLU()\n",
       "      (6): Linear(in_features=32, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [288, 333, 32],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.007380128019475984,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.6739268898963928,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.6710259914398193,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 759: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=366, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=366, out_features=263, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=263, out_features=352, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=352, out_features=421, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=421, out_features=404, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=404, out_features=205, bias=True)\n",
       "      (16): LeakyReLU(negative_slope=0.01)\n",
       "      (17): Dropout(p=0.5, inplace=False)\n",
       "      (18): Linear(in_features=205, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [366, 263, 352, 421, 404, 205],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.003456825157020388,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.6855999827384949,\n",
       "  'train_acc': 0.6510416666666666,\n",
       "  'val_loss': 0.6534614562988281,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 760: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=290, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Linear(in_features=290, out_features=327, bias=True)\n",
       "      (3): Sigmoid()\n",
       "      (4): Linear(in_features=327, out_features=127, bias=True)\n",
       "      (5): Sigmoid()\n",
       "      (6): Linear(in_features=127, out_features=187, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Linear(in_features=187, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [290, 327, 127, 187],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.005417220114967804,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.6736475825309753,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.6620073914527893,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 761: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=320, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=320, out_features=474, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=474, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [320, 474],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.005657826916838072,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.7027702331542969,\n",
       "  'train_acc': 0.4296875,\n",
       "  'val_loss': 0.7030900120735168,\n",
       "  'val_acc': 0.4166666666666667},\n",
       " 762: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=260, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=260, out_features=49, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=49, out_features=105, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=105, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [260, 49, 105],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.004850311491554899,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.6823434829711914,\n",
       "  'train_acc': 0.6197916666666666,\n",
       "  'val_loss': 0.6754328608512878,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 763: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=91, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=91, out_features=56, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=56, out_features=31, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=31, out_features=368, bias=True)\n",
       "      (10): Sigmoid()\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=368, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [91, 56, 31, 368],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0044398130921182236,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.6664063334465027,\n",
       "  'train_acc': 0.6354166666666666,\n",
       "  'val_loss': 0.8008387088775635,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 764: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=465, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Linear(in_features=465, out_features=413, bias=True)\n",
       "      (3): Sigmoid()\n",
       "      (4): Linear(in_features=413, out_features=180, bias=True)\n",
       "      (5): Sigmoid()\n",
       "      (6): Linear(in_features=180, out_features=253, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Linear(in_features=253, out_features=16, bias=True)\n",
       "      (9): Sigmoid()\n",
       "      (10): Linear(in_features=16, out_features=178, bias=True)\n",
       "      (11): Sigmoid()\n",
       "      (12): Linear(in_features=178, out_features=377, bias=True)\n",
       "      (13): Sigmoid()\n",
       "      (14): Linear(in_features=377, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [465, 413, 180, 253, 16, 178, 377],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.009039839901321664,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.7119670510292053,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.6602959036827087,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 765: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=501, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=501, out_features=18, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=18, out_features=82, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=82, out_features=26, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=26, out_features=353, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=353, out_features=464, bias=True)\n",
       "      (16): LeakyReLU(negative_slope=0.01)\n",
       "      (17): Dropout(p=0.5, inplace=False)\n",
       "      (18): Linear(in_features=464, out_features=402, bias=True)\n",
       "      (19): LeakyReLU(negative_slope=0.01)\n",
       "      (20): Dropout(p=0.5, inplace=False)\n",
       "      (21): Linear(in_features=402, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [501, 18, 82, 26, 353, 464, 402],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.00977271349809401,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.695859432220459,\n",
       "  'train_acc': 0.4583333333333333,\n",
       "  'val_loss': 0.6953787803649902,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 766: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=56, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Linear(in_features=56, out_features=497, bias=True)\n",
       "      (3): Sigmoid()\n",
       "      (4): Linear(in_features=497, out_features=56, bias=True)\n",
       "      (5): Sigmoid()\n",
       "      (6): Linear(in_features=56, out_features=240, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Linear(in_features=240, out_features=492, bias=True)\n",
       "      (9): Sigmoid()\n",
       "      (10): Linear(in_features=492, out_features=199, bias=True)\n",
       "      (11): Sigmoid()\n",
       "      (12): Linear(in_features=199, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [56, 497, 56, 240, 492, 199],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0031208889385266276,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.6580775380134583,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.6497862935066223,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 767: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=280, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=280, out_features=509, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=509, out_features=136, bias=True)\n",
       "      (5): LeakyReLU(negative_slope=0.01)\n",
       "      (6): Linear(in_features=136, out_features=461, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Linear(in_features=461, out_features=380, bias=True)\n",
       "      (9): LeakyReLU(negative_slope=0.01)\n",
       "      (10): Linear(in_features=380, out_features=150, bias=True)\n",
       "      (11): LeakyReLU(negative_slope=0.01)\n",
       "      (12): Linear(in_features=150, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [280, 509, 136, 461, 380, 150],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.004278557513735388,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.7014111876487732,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.7020660042762756,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 768: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=487, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=487, out_features=206, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=206, out_features=428, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=428, out_features=137, bias=True)\n",
       "      (10): Sigmoid()\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=137, out_features=501, bias=True)\n",
       "      (13): Sigmoid()\n",
       "      (14): Dropout(p=0.1, inplace=False)\n",
       "      (15): Linear(in_features=501, out_features=104, bias=True)\n",
       "      (16): Sigmoid()\n",
       "      (17): Dropout(p=0.1, inplace=False)\n",
       "      (18): Linear(in_features=104, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [487, 206, 428, 137, 501, 104],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0011393940846770045,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.7439481616020203,\n",
       "  'train_acc': 0.3645833333333333,\n",
       "  'val_loss': 0.6415749788284302,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 769: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=134, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=134, out_features=157, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=157, out_features=280, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=280, out_features=171, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=171, out_features=396, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=396, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [134, 157, 280, 171, 396],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0065862428940274866,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.6855583190917969,\n",
       "  'train_acc': 0.6145833333333334,\n",
       "  'val_loss': 0.6824531555175781,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 770: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=443, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=443, out_features=502, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=502, out_features=149, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=149, out_features=431, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=431, out_features=140, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.1, inplace=False)\n",
       "      (15): Linear(in_features=140, out_features=408, bias=True)\n",
       "      (16): LeakyReLU(negative_slope=0.01)\n",
       "      (17): Dropout(p=0.1, inplace=False)\n",
       "      (18): Linear(in_features=408, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [443, 502, 149, 431, 140, 408],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0029445831123547416,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.6961933970451355,\n",
       "  'train_acc': 0.3463541666666667,\n",
       "  'val_loss': 0.6546657681465149,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 771: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=415, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=415, out_features=288, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=288, out_features=389, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=389, out_features=172, bias=True)\n",
       "      (10): Sigmoid()\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=172, out_features=153, bias=True)\n",
       "      (13): Sigmoid()\n",
       "      (14): Dropout(p=0.2, inplace=False)\n",
       "      (15): Linear(in_features=153, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [415, 288, 389, 172, 153],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.003986939291299082,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.7072682976722717,\n",
       "  'train_acc': 0.4557291666666667,\n",
       "  'val_loss': 0.6881551146507263,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 772: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=495, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=495, out_features=285, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=285, out_features=257, bias=True)\n",
       "      (5): ReLU()\n",
       "      (6): Linear(in_features=257, out_features=334, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Linear(in_features=334, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [495, 285, 257, 334],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0027519005984802235,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.6830170750617981,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.6350958943367004,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 773: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=214, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=214, out_features=216, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=216, out_features=219, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=219, out_features=489, bias=True)\n",
       "      (10): Sigmoid()\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=489, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [214, 216, 219, 489],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.005952750442963428,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.6464048027992249,\n",
       "  'train_acc': 0.6536458333333334,\n",
       "  'val_loss': 0.6312398314476013,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 774: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=220, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=220, out_features=126, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=126, out_features=309, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=309, out_features=40, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=40, out_features=51, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.1, inplace=False)\n",
       "      (15): Linear(in_features=51, out_features=134, bias=True)\n",
       "      (16): ReLU()\n",
       "      (17): Dropout(p=0.1, inplace=False)\n",
       "      (18): Linear(in_features=134, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [220, 126, 309, 40, 51, 134],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.008334490577077998,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.6876042485237122,\n",
       "  'train_acc': 0.6536458333333334,\n",
       "  'val_loss': 0.6847329139709473,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 775: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=312, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=312, out_features=289, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=289, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [312, 289],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.005734216832294,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.6449913382530212,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.6292431354522705,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 776: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=132, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=132, out_features=500, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=500, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [132, 500],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0034543986683288233,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.6993985772132874,\n",
       "  'train_acc': 0.4817708333333333,\n",
       "  'val_loss': 0.6991965174674988,\n",
       "  'val_acc': 0.4791666666666667},\n",
       " 777: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=101, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=101, out_features=195, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=195, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [101, 195],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.008353138500648815,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.6774182319641113,\n",
       "  'train_acc': 0.5885416666666666,\n",
       "  'val_loss': 0.6510626673698425,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 778: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=510, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=510, out_features=414, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=414, out_features=299, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=299, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [510, 414, 299],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.007573215500283361,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.6693165302276611,\n",
       "  'train_acc': 0.6145833333333334,\n",
       "  'val_loss': 0.636476993560791,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 779: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=75, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=75, out_features=239, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=239, out_features=469, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=469, out_features=224, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=224, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [75, 239, 469, 224],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0013979596720142258,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.7027246356010437,\n",
       "  'train_acc': 0.3359375,\n",
       "  'val_loss': 0.7015161514282227,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 780: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=319, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=319, out_features=140, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=140, out_features=485, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=485, out_features=365, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=365, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [319, 140, 485, 365],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.008167796104079259,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.6874361634254456,\n",
       "  'train_acc': 0.6484375,\n",
       "  'val_loss': 0.6863686442375183,\n",
       "  'val_acc': 0.6458333333333334},\n",
       " 781: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=269, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=269, out_features=372, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=372, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [269, 372],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.007895109308529165,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.6730998158454895,\n",
       "  'train_acc': 0.6354166666666666,\n",
       "  'val_loss': 0.6486678123474121,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 782: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=473, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=473, out_features=182, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=182, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [473, 182],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0015008926906896073,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.7005007266998291,\n",
       "  'train_acc': 0.4348958333333333,\n",
       "  'val_loss': 0.705889880657196,\n",
       "  'val_acc': 0.375},\n",
       " 783: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=373, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=373, out_features=464, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=464, out_features=119, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=119, out_features=325, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=325, out_features=46, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=46, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [373, 464, 119, 325, 46],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.00654908885519449,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.6921623349189758,\n",
       "  'train_acc': 0.5286458333333334,\n",
       "  'val_loss': 0.6345139741897583,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 784: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=187, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=187, out_features=76, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=76, out_features=391, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=391, out_features=210, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=210, out_features=421, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.1, inplace=False)\n",
       "      (15): Linear(in_features=421, out_features=450, bias=True)\n",
       "      (16): ReLU()\n",
       "      (17): Dropout(p=0.1, inplace=False)\n",
       "      (18): Linear(in_features=450, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [187, 76, 391, 210, 421, 450],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.002218528481851921,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.7004948258399963,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.7013439536094666,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 785: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=319, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=319, out_features=59, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=59, out_features=135, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=135, out_features=48, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=48, out_features=378, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.1, inplace=False)\n",
       "      (15): Linear(in_features=378, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [319, 59, 135, 48, 378],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0015581025766102405,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.6839895844459534,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.6817100048065186,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 786: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=307, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=307, out_features=256, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=256, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [307, 256],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.002720159420691775,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.7192773222923279,\n",
       "  'train_acc': 0.3359375,\n",
       "  'val_loss': 0.7173929214477539,\n",
       "  'val_acc': 0.3125},\n",
       " 787: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=368, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=368, out_features=144, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=144, out_features=247, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=247, out_features=272, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=272, out_features=205, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=205, out_features=482, bias=True)\n",
       "      (16): ReLU()\n",
       "      (17): Dropout(p=0.5, inplace=False)\n",
       "      (18): Linear(in_features=482, out_features=495, bias=True)\n",
       "      (19): ReLU()\n",
       "      (20): Dropout(p=0.5, inplace=False)\n",
       "      (21): Linear(in_features=495, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [368, 144, 247, 272, 205, 482, 495],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0028311201588320217,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.7082708477973938,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.6603384613990784,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 788: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=361, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=361, out_features=116, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=116, out_features=118, bias=True)\n",
       "      (5): ReLU()\n",
       "      (6): Linear(in_features=118, out_features=25, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Linear(in_features=25, out_features=189, bias=True)\n",
       "      (9): ReLU()\n",
       "      (10): Linear(in_features=189, out_features=414, bias=True)\n",
       "      (11): ReLU()\n",
       "      (12): Linear(in_features=414, out_features=302, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Linear(in_features=302, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [361, 116, 118, 25, 189, 414, 302],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.00509978583625971,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.6889539361000061,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.6333479881286621,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 789: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=159, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=159, out_features=462, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=462, out_features=321, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=321, out_features=91, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=91, out_features=270, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=270, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [159, 462, 321, 91, 270],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.009282532890041141,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.7061020731925964,\n",
       "  'train_acc': 0.3723958333333333,\n",
       "  'val_loss': 0.7036728858947754,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 790: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=54, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=54, out_features=406, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=406, out_features=174, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=174, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [54, 406, 174],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0054944710048197365,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.6916961073875427,\n",
       "  'train_acc': 0.5286458333333334,\n",
       "  'val_loss': 0.6890491843223572,\n",
       "  'val_acc': 0.53125},\n",
       " 791: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=355, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=355, out_features=224, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=224, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [355, 224],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.009943905970488196,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.875629723072052,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.7580241560935974,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 792: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=298, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=298, out_features=403, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=403, out_features=61, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=61, out_features=105, bias=True)\n",
       "      (10): Sigmoid()\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=105, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [298, 403, 61, 105],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0011978498978981672,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.7979775071144104,\n",
       "  'train_acc': 0.3984375,\n",
       "  'val_loss': 0.7164830565452576,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 793: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=461, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=461, out_features=489, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=489, out_features=186, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=186, out_features=161, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=161, out_features=329, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=329, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [461, 489, 186, 161, 329],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.00886882454876919,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.6827720999717712,\n",
       "  'train_acc': 0.6223958333333334,\n",
       "  'val_loss': 0.6830253005027771,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 794: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=221, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=221, out_features=446, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=446, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [221, 446],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.005064998432759115,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.701270580291748,\n",
       "  'train_acc': 0.46875,\n",
       "  'val_loss': 0.8162484765052795,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 795: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=27, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=27, out_features=443, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=443, out_features=109, bias=True)\n",
       "      (5): LeakyReLU(negative_slope=0.01)\n",
       "      (6): Linear(in_features=109, out_features=369, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Linear(in_features=369, out_features=445, bias=True)\n",
       "      (9): LeakyReLU(negative_slope=0.01)\n",
       "      (10): Linear(in_features=445, out_features=231, bias=True)\n",
       "      (11): LeakyReLU(negative_slope=0.01)\n",
       "      (12): Linear(in_features=231, out_features=478, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Linear(in_features=478, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [27, 443, 109, 369, 445, 231, 478],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0021357584201796612,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.6812508702278137,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.6797294020652771,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 796: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=124, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Linear(in_features=124, out_features=218, bias=True)\n",
       "      (3): Sigmoid()\n",
       "      (4): Linear(in_features=218, out_features=115, bias=True)\n",
       "      (5): Sigmoid()\n",
       "      (6): Linear(in_features=115, out_features=505, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Linear(in_features=505, out_features=455, bias=True)\n",
       "      (9): Sigmoid()\n",
       "      (10): Linear(in_features=455, out_features=445, bias=True)\n",
       "      (11): Sigmoid()\n",
       "      (12): Linear(in_features=445, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [124, 218, 115, 505, 455, 445],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0015476246661405456,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.651700496673584,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.642983615398407,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 797: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=77, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=77, out_features=299, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=299, out_features=344, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=344, out_features=72, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=72, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [77, 299, 344, 72],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0014458662090196996,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.725689709186554,\n",
       "  'train_acc': 0.3489583333333333,\n",
       "  'val_loss': 0.6941733360290527,\n",
       "  'val_acc': 0.3958333333333333},\n",
       " 798: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=80, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=80, out_features=122, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=122, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [80, 122],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.007457858728316162,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.6827461123466492,\n",
       "  'train_acc': 0.5885416666666666,\n",
       "  'val_loss': 0.7209897041320801,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 799: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=118, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=118, out_features=17, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=17, out_features=319, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=319, out_features=15, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=15, out_features=17, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=17, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [118, 17, 319, 15, 17],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.009328887061471638,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.692366898059845,\n",
       "  'train_acc': 0.5364583333333334,\n",
       "  'val_loss': 0.6682906150817871,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 800: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=368, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=368, out_features=389, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=389, out_features=342, bias=True)\n",
       "      (5): LeakyReLU(negative_slope=0.01)\n",
       "      (6): Linear(in_features=342, out_features=245, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Linear(in_features=245, out_features=94, bias=True)\n",
       "      (9): LeakyReLU(negative_slope=0.01)\n",
       "      (10): Linear(in_features=94, out_features=355, bias=True)\n",
       "      (11): LeakyReLU(negative_slope=0.01)\n",
       "      (12): Linear(in_features=355, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [368, 389, 342, 245, 94, 355],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.002557886002649597,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.6978158354759216,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.6656827330589294,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 801: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=113, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=113, out_features=414, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=414, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [113, 414],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0018448965784280819,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.8217496871948242,\n",
       "  'train_acc': 0.3567708333333333,\n",
       "  'val_loss': 0.7764661312103271,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 802: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=167, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=167, out_features=127, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=127, out_features=77, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=77, out_features=378, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=378, out_features=132, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.1, inplace=False)\n",
       "      (15): Linear(in_features=132, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [167, 127, 77, 378, 132],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.00405394114066837,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.6864176392555237,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.6419587731361389,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 803: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=230, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=230, out_features=135, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=135, out_features=277, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=277, out_features=80, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=80, out_features=240, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=240, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [230, 135, 277, 80, 240],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0053543935049509455,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.6812891364097595,\n",
       "  'train_acc': 0.640625,\n",
       "  'val_loss': 0.6794200539588928,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 804: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=39, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=39, out_features=471, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=471, out_features=442, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=442, out_features=238, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=238, out_features=196, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.1, inplace=False)\n",
       "      (15): Linear(in_features=196, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [39, 471, 442, 238, 196],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.006090117321248008,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.7041117548942566,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.7045807838439941,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 805: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=193, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=193, out_features=379, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=379, out_features=272, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=272, out_features=230, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=230, out_features=303, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.2, inplace=False)\n",
       "      (15): Linear(in_features=303, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [193, 379, 272, 230, 303],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0045292435227140704,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.6819701790809631,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.6303111910820007,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 806: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=148, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Linear(in_features=148, out_features=357, bias=True)\n",
       "      (3): Sigmoid()\n",
       "      (4): Linear(in_features=357, out_features=477, bias=True)\n",
       "      (5): Sigmoid()\n",
       "      (6): Linear(in_features=477, out_features=324, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Linear(in_features=324, out_features=506, bias=True)\n",
       "      (9): Sigmoid()\n",
       "      (10): Linear(in_features=506, out_features=46, bias=True)\n",
       "      (11): Sigmoid()\n",
       "      (12): Linear(in_features=46, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [148, 357, 477, 324, 506, 46],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.004413868391302654,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.6470434665679932,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.7711130976676941,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 807: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=39, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=39, out_features=39, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=39, out_features=473, bias=True)\n",
       "      (5): LeakyReLU(negative_slope=0.01)\n",
       "      (6): Linear(in_features=473, out_features=201, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Linear(in_features=201, out_features=186, bias=True)\n",
       "      (9): LeakyReLU(negative_slope=0.01)\n",
       "      (10): Linear(in_features=186, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [39, 39, 473, 201, 186],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.008154537462567139,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.6940541863441467,\n",
       "  'train_acc': 0.3619791666666667,\n",
       "  'val_loss': 0.6302735209465027,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 808: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=478, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Linear(in_features=478, out_features=393, bias=True)\n",
       "      (3): Sigmoid()\n",
       "      (4): Linear(in_features=393, out_features=442, bias=True)\n",
       "      (5): Sigmoid()\n",
       "      (6): Linear(in_features=442, out_features=344, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Linear(in_features=344, out_features=467, bias=True)\n",
       "      (9): Sigmoid()\n",
       "      (10): Linear(in_features=467, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [478, 393, 442, 344, 467],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.004757314360963603,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.9119489789009094,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.790941059589386,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 809: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=423, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=423, out_features=70, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=70, out_features=120, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=120, out_features=423, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=423, out_features=48, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.1, inplace=False)\n",
       "      (15): Linear(in_features=48, out_features=144, bias=True)\n",
       "      (16): LeakyReLU(negative_slope=0.01)\n",
       "      (17): Dropout(p=0.1, inplace=False)\n",
       "      (18): Linear(in_features=144, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [423, 70, 120, 423, 48, 144],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0038436660040678445,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.6915039420127869,\n",
       "  'train_acc': 0.5885416666666666,\n",
       "  'val_loss': 0.6631953716278076,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 810: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=324, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=324, out_features=162, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=162, out_features=55, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=55, out_features=430, bias=True)\n",
       "      (10): Sigmoid()\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=430, out_features=227, bias=True)\n",
       "      (13): Sigmoid()\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=227, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [324, 162, 55, 430, 227],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0018643209650127477,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.6826639175415039,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.6331633925437927,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 811: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=448, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=448, out_features=265, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=265, out_features=463, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=463, out_features=461, bias=True)\n",
       "      (10): Sigmoid()\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=461, out_features=347, bias=True)\n",
       "      (13): Sigmoid()\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=347, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [448, 265, 463, 461, 347],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0031184813499705523,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.7082180976867676,\n",
       "  'train_acc': 0.5182291666666666,\n",
       "  'val_loss': 0.6838302612304688,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 812: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=82, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=82, out_features=224, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=224, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [82, 224],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0021088762119317777,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.6816667914390564,\n",
       "  'train_acc': 0.5651041666666666,\n",
       "  'val_loss': 0.6474171280860901,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 813: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=124, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=124, out_features=319, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=319, out_features=355, bias=True)\n",
       "      (5): LeakyReLU(negative_slope=0.01)\n",
       "      (6): Linear(in_features=355, out_features=306, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Linear(in_features=306, out_features=212, bias=True)\n",
       "      (9): LeakyReLU(negative_slope=0.01)\n",
       "      (10): Linear(in_features=212, out_features=185, bias=True)\n",
       "      (11): LeakyReLU(negative_slope=0.01)\n",
       "      (12): Linear(in_features=185, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [124, 319, 355, 306, 212, 185],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0015789290054716541,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.6833856701850891,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.6820869445800781,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 814: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=65, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=65, out_features=298, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=298, out_features=56, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=56, out_features=270, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=270, out_features=221, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.1, inplace=False)\n",
       "      (15): Linear(in_features=221, out_features=98, bias=True)\n",
       "      (16): LeakyReLU(negative_slope=0.01)\n",
       "      (17): Dropout(p=0.1, inplace=False)\n",
       "      (18): Linear(in_features=98, out_features=30, bias=True)\n",
       "      (19): LeakyReLU(negative_slope=0.01)\n",
       "      (20): Dropout(p=0.1, inplace=False)\n",
       "      (21): Linear(in_features=30, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [65, 298, 56, 270, 221, 98, 30],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0015999984031461667,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.7546837329864502,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.7601775527000427,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 815: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=133, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=133, out_features=37, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=37, out_features=14, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=14, out_features=117, bias=True)\n",
       "      (10): Sigmoid()\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=117, out_features=181, bias=True)\n",
       "      (13): Sigmoid()\n",
       "      (14): Dropout(p=0.1, inplace=False)\n",
       "      (15): Linear(in_features=181, out_features=94, bias=True)\n",
       "      (16): Sigmoid()\n",
       "      (17): Dropout(p=0.1, inplace=False)\n",
       "      (18): Linear(in_features=94, out_features=436, bias=True)\n",
       "      (19): Sigmoid()\n",
       "      (20): Dropout(p=0.1, inplace=False)\n",
       "      (21): Linear(in_features=436, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [133, 37, 14, 117, 181, 94, 436],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0020074462321776464,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.7325161099433899,\n",
       "  'train_acc': 0.3723958333333333,\n",
       "  'val_loss': 0.7127540111541748,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 816: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=342, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Linear(in_features=342, out_features=120, bias=True)\n",
       "      (3): Sigmoid()\n",
       "      (4): Linear(in_features=120, out_features=132, bias=True)\n",
       "      (5): Sigmoid()\n",
       "      (6): Linear(in_features=132, out_features=446, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Linear(in_features=446, out_features=365, bias=True)\n",
       "      (9): Sigmoid()\n",
       "      (10): Linear(in_features=365, out_features=427, bias=True)\n",
       "      (11): Sigmoid()\n",
       "      (12): Linear(in_features=427, out_features=88, bias=True)\n",
       "      (13): Sigmoid()\n",
       "      (14): Linear(in_features=88, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [342, 120, 132, 446, 365, 427, 88],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0020724991619290156,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.880277693271637,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.881221354007721,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 817: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=498, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=498, out_features=104, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=104, out_features=440, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=440, out_features=13, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=13, out_features=395, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.1, inplace=False)\n",
       "      (15): Linear(in_features=395, out_features=423, bias=True)\n",
       "      (16): LeakyReLU(negative_slope=0.01)\n",
       "      (17): Dropout(p=0.1, inplace=False)\n",
       "      (18): Linear(in_features=423, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [498, 104, 440, 13, 395, 423],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0019518146718715901,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.6899117827415466,\n",
       "  'train_acc': 0.6302083333333334,\n",
       "  'val_loss': 0.636005699634552,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 818: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=376, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=376, out_features=108, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=108, out_features=511, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=511, out_features=178, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=178, out_features=97, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.1, inplace=False)\n",
       "      (15): Linear(in_features=97, out_features=477, bias=True)\n",
       "      (16): ReLU()\n",
       "      (17): Dropout(p=0.1, inplace=False)\n",
       "      (18): Linear(in_features=477, out_features=164, bias=True)\n",
       "      (19): ReLU()\n",
       "      (20): Dropout(p=0.1, inplace=False)\n",
       "      (21): Linear(in_features=164, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [376, 108, 511, 178, 97, 477, 164],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.00807799303837774,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.7158051133155823,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.7176842093467712,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 819: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=246, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=246, out_features=76, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=76, out_features=285, bias=True)\n",
       "      (5): LeakyReLU(negative_slope=0.01)\n",
       "      (6): Linear(in_features=285, out_features=143, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Linear(in_features=143, out_features=178, bias=True)\n",
       "      (9): LeakyReLU(negative_slope=0.01)\n",
       "      (10): Linear(in_features=178, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [246, 76, 285, 143, 178],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.009177818874856938,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.6844015717506409,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.6827231049537659,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 820: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=438, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=438, out_features=388, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=388, out_features=386, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=386, out_features=406, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=406, out_features=99, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=99, out_features=300, bias=True)\n",
       "      (16): LeakyReLU(negative_slope=0.01)\n",
       "      (17): Dropout(p=0.5, inplace=False)\n",
       "      (18): Linear(in_features=300, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [438, 388, 386, 406, 99, 300],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0019972125834488968,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.7003300786018372,\n",
       "  'train_acc': 0.3828125,\n",
       "  'val_loss': 0.699932336807251,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 821: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=119, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=119, out_features=111, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=111, out_features=178, bias=True)\n",
       "      (5): ReLU()\n",
       "      (6): Linear(in_features=178, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [119, 111, 178],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.008540429352342886,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.6688070297241211,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.7102205157279968,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 822: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=363, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=363, out_features=247, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=247, out_features=454, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=454, out_features=411, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=411, out_features=164, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=164, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [363, 247, 454, 411, 164],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.008931035819687017,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.6869468688964844,\n",
       "  'train_acc': 0.5755208333333334,\n",
       "  'val_loss': 0.6844428181648254,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 823: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=163, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=163, out_features=304, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=304, out_features=396, bias=True)\n",
       "      (5): LeakyReLU(negative_slope=0.01)\n",
       "      (6): Linear(in_features=396, out_features=457, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Linear(in_features=457, out_features=334, bias=True)\n",
       "      (9): LeakyReLU(negative_slope=0.01)\n",
       "      (10): Linear(in_features=334, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [163, 304, 396, 457, 334],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0016734841049659698,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.6813414692878723,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.679762065410614,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 824: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=420, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=420, out_features=199, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=199, out_features=374, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=374, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [420, 199, 374],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0013710442532782283,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.6934095025062561,\n",
       "  'train_acc': 0.5104166666666666,\n",
       "  'val_loss': 0.6907971501350403,\n",
       "  'val_acc': 0.6145833333333334},\n",
       " 825: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=202, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=202, out_features=256, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=256, out_features=109, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=109, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [202, 256, 109],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0014915482134517696,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.6961438059806824,\n",
       "  'train_acc': 0.4921875,\n",
       "  'val_loss': 0.6499525904655457,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 826: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=406, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=406, out_features=246, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=246, out_features=388, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=388, out_features=95, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=95, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [406, 246, 388, 95],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0015767574944055127,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.680558979511261,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.6774277687072754,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 827: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=175, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=175, out_features=144, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=144, out_features=143, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=143, out_features=225, bias=True)\n",
       "      (10): Sigmoid()\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=225, out_features=81, bias=True)\n",
       "      (13): Sigmoid()\n",
       "      (14): Dropout(p=0.1, inplace=False)\n",
       "      (15): Linear(in_features=81, out_features=234, bias=True)\n",
       "      (16): Sigmoid()\n",
       "      (17): Dropout(p=0.1, inplace=False)\n",
       "      (18): Linear(in_features=234, out_features=75, bias=True)\n",
       "      (19): Sigmoid()\n",
       "      (20): Dropout(p=0.1, inplace=False)\n",
       "      (21): Linear(in_features=75, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [175, 144, 143, 225, 81, 234, 75],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.007026710579843435,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.6736543774604797,\n",
       "  'train_acc': 0.625,\n",
       "  'val_loss': 0.7575363516807556,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 828: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=122, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=122, out_features=471, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=471, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [122, 471],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.004266994269217669,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.6941433548927307,\n",
       "  'train_acc': 0.4869791666666667,\n",
       "  'val_loss': 0.6736916899681091,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 829: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=354, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=354, out_features=284, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=284, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [354, 284],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.009667196282259979,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.7166109085083008,\n",
       "  'train_acc': 0.3984375,\n",
       "  'val_loss': 0.7061215043067932,\n",
       "  'val_acc': 0.4166666666666667},\n",
       " 830: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=429, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=429, out_features=343, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=343, out_features=375, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=375, out_features=169, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=169, out_features=197, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=197, out_features=31, bias=True)\n",
       "      (16): LeakyReLU(negative_slope=0.01)\n",
       "      (17): Dropout(p=0.5, inplace=False)\n",
       "      (18): Linear(in_features=31, out_features=148, bias=True)\n",
       "      (19): LeakyReLU(negative_slope=0.01)\n",
       "      (20): Dropout(p=0.5, inplace=False)\n",
       "      (21): Linear(in_features=148, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [429, 343, 375, 169, 197, 31, 148],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.009754736769908925,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.6942682266235352,\n",
       "  'train_acc': 0.4661458333333333,\n",
       "  'val_loss': 0.6934632658958435,\n",
       "  'val_acc': 0.3645833333333333},\n",
       " 831: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=391, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=391, out_features=96, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=96, out_features=460, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=460, out_features=422, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=422, out_features=457, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.1, inplace=False)\n",
       "      (15): Linear(in_features=457, out_features=108, bias=True)\n",
       "      (16): LeakyReLU(negative_slope=0.01)\n",
       "      (17): Dropout(p=0.1, inplace=False)\n",
       "      (18): Linear(in_features=108, out_features=108, bias=True)\n",
       "      (19): LeakyReLU(negative_slope=0.01)\n",
       "      (20): Dropout(p=0.1, inplace=False)\n",
       "      (21): Linear(in_features=108, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [391, 96, 460, 422, 457, 108, 108],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.007854646938619215,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.6933757662773132,\n",
       "  'train_acc': 0.5104166666666666,\n",
       "  'val_loss': 0.6924131512641907,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 832: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=281, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=281, out_features=38, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=38, out_features=350, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=350, out_features=414, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=414, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [281, 38, 350, 414],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.004427938637120106,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.6974906921386719,\n",
       "  'train_acc': 0.4088541666666667,\n",
       "  'val_loss': 0.628073513507843,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 833: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=17, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=17, out_features=120, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=120, out_features=378, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=378, out_features=146, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=146, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [17, 120, 378, 146],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.008837194021937198,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.6887180805206299,\n",
       "  'train_acc': 0.5729166666666666,\n",
       "  'val_loss': 0.7569727301597595,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 834: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=428, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=428, out_features=498, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=498, out_features=106, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=106, out_features=315, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=315, out_features=189, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=189, out_features=437, bias=True)\n",
       "      (16): LeakyReLU(negative_slope=0.01)\n",
       "      (17): Dropout(p=0.5, inplace=False)\n",
       "      (18): Linear(in_features=437, out_features=458, bias=True)\n",
       "      (19): LeakyReLU(negative_slope=0.01)\n",
       "      (20): Dropout(p=0.5, inplace=False)\n",
       "      (21): Linear(in_features=458, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [428, 498, 106, 315, 189, 437, 458],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.004302491223998613,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.7015647292137146,\n",
       "  'train_acc': 0.3489583333333333,\n",
       "  'val_loss': 0.6452945470809937,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 835: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=167, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=167, out_features=58, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=58, out_features=285, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=285, out_features=418, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=418, out_features=181, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.2, inplace=False)\n",
       "      (15): Linear(in_features=181, out_features=266, bias=True)\n",
       "      (16): ReLU()\n",
       "      (17): Dropout(p=0.2, inplace=False)\n",
       "      (18): Linear(in_features=266, out_features=59, bias=True)\n",
       "      (19): ReLU()\n",
       "      (20): Dropout(p=0.2, inplace=False)\n",
       "      (21): Linear(in_features=59, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [167, 58, 285, 418, 181, 266, 59],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.005390179493656197,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.693552553653717,\n",
       "  'train_acc': 0.4791666666666667,\n",
       "  'val_loss': 0.6553592085838318,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 836: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=146, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=146, out_features=185, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=185, out_features=302, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=302, out_features=198, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=198, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [146, 185, 302, 198],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.001150972855755437,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 777},\n",
       "  'train_loss': 0.6968815922737122,\n",
       "  'train_acc': 0.4947916666666667,\n",
       "  'val_loss': 0.6769865155220032,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 837: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=207, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=207, out_features=492, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=492, out_features=430, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=430, out_features=401, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=401, out_features=253, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=253, out_features=324, bias=True)\n",
       "      (16): ReLU()\n",
       "      (17): Dropout(p=0.5, inplace=False)\n",
       "      (18): Linear(in_features=324, out_features=420, bias=True)\n",
       "      (19): ReLU()\n",
       "      (20): Dropout(p=0.5, inplace=False)\n",
       "      (21): Linear(in_features=420, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [207, 492, 430, 401, 253, 324, 420],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.001264692411450176,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.6925227046012878,\n",
       "  'train_acc': 0.5052083333333334,\n",
       "  'val_loss': 0.6919424533843994,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 838: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=154, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=154, out_features=388, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=388, out_features=40, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=40, out_features=259, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=259, out_features=379, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.5, inplace=False)\n",
       "      (15): Linear(in_features=379, out_features=460, bias=True)\n",
       "      (16): LeakyReLU(negative_slope=0.01)\n",
       "      (17): Dropout(p=0.5, inplace=False)\n",
       "      (18): Linear(in_features=460, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [154, 388, 40, 259, 379, 460],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.00592555914602335,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.7047104835510254,\n",
       "  'train_acc': 0.3645833333333333,\n",
       "  'val_loss': 0.6305810809135437,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 839: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=443, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=443, out_features=71, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=71, out_features=75, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=75, out_features=19, bias=True)\n",
       "      (10): Sigmoid()\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=19, out_features=343, bias=True)\n",
       "      (13): Sigmoid()\n",
       "      (14): Dropout(p=0.2, inplace=False)\n",
       "      (15): Linear(in_features=343, out_features=406, bias=True)\n",
       "      (16): Sigmoid()\n",
       "      (17): Dropout(p=0.2, inplace=False)\n",
       "      (18): Linear(in_features=406, out_features=234, bias=True)\n",
       "      (19): Sigmoid()\n",
       "      (20): Dropout(p=0.2, inplace=False)\n",
       "      (21): Linear(in_features=234, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [443, 71, 75, 19, 343, 406, 234],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0020811104319133716,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.7051184177398682,\n",
       "  'train_acc': 0.4739583333333333,\n",
       "  'val_loss': 0.6982510685920715,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 840: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=68, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=68, out_features=395, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=395, out_features=43, bias=True)\n",
       "      (5): LeakyReLU(negative_slope=0.01)\n",
       "      (6): Linear(in_features=43, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [68, 395, 43],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.00797670835613927,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.7267857193946838,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.7297523021697998,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 841: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=489, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=489, out_features=68, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=68, out_features=344, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=344, out_features=277, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=277, out_features=256, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.1, inplace=False)\n",
       "      (15): Linear(in_features=256, out_features=426, bias=True)\n",
       "      (16): ReLU()\n",
       "      (17): Dropout(p=0.1, inplace=False)\n",
       "      (18): Linear(in_features=426, out_features=139, bias=True)\n",
       "      (19): ReLU()\n",
       "      (20): Dropout(p=0.1, inplace=False)\n",
       "      (21): Linear(in_features=139, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [489, 68, 344, 277, 256, 426, 139],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.008317726028164874,\n",
       "   'batch_size': 256,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.6963193416595459,\n",
       "  'train_acc': 0.3489583333333333,\n",
       "  'val_loss': 0.8855859637260437,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 842: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=428, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=428, out_features=299, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=299, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [428, 299],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.005243296439920592,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.7105345129966736,\n",
       "  'train_acc': 0.4453125,\n",
       "  'val_loss': 0.7084949016571045,\n",
       "  'val_acc': 0.4583333333333333},\n",
       " 843: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=80, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=80, out_features=83, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=83, out_features=252, bias=True)\n",
       "      (5): LeakyReLU(negative_slope=0.01)\n",
       "      (6): Linear(in_features=252, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [80, 83, 252],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.0032940652854026756,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.6752282977104187,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.6711767315864563,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 844: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=197, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=197, out_features=205, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=205, out_features=419, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=419, out_features=210, bias=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01)\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=210, out_features=103, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): Dropout(p=0.1, inplace=False)\n",
       "      (15): Linear(in_features=103, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [197, 205, 419, 210, 103],\n",
       "   'activation_fn': torch.nn.modules.activation.LeakyReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.004096902410067363,\n",
       "   'batch_size': 128,\n",
       "   'random_seed': 1337},\n",
       "  'train_loss': 0.6679129600524902,\n",
       "  'train_acc': 0.6588541666666666,\n",
       "  'val_loss': 0.6669669151306152,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 845: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=234, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=234, out_features=276, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=276, out_features=91, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=91, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [234, 276, 91],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.5,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.005958167543308407,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 42},\n",
       "  'train_loss': 0.7202093005180359,\n",
       "  'train_acc': 0.4817708333333333,\n",
       "  'val_loss': 0.6614850163459778,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 846: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=370, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=370, out_features=431, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=431, out_features=206, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.2, inplace=False)\n",
       "      (9): Linear(in_features=206, out_features=88, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=88, out_features=354, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.2, inplace=False)\n",
       "      (15): Linear(in_features=354, out_features=464, bias=True)\n",
       "      (16): ReLU()\n",
       "      (17): Dropout(p=0.2, inplace=False)\n",
       "      (18): Linear(in_features=464, out_features=372, bias=True)\n",
       "      (19): ReLU()\n",
       "      (20): Dropout(p=0.2, inplace=False)\n",
       "      (21): Linear(in_features=372, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [370, 431, 206, 88, 354, 464, 372],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.2,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.004957642061782862,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.7043010592460632,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.7049385905265808,\n",
       "  'val_acc': 0.3229166666666667},\n",
       " 847: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=456, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=456, out_features=441, bias=True)\n",
       "      (4): Sigmoid()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=441, out_features=45, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=45, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [456, 441, 45],\n",
       "   'activation_fn': torch.nn.modules.activation.Sigmoid,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.009534900749048832,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 13},\n",
       "  'train_loss': 0.6842390894889832,\n",
       "  'train_acc': 0.578125,\n",
       "  'val_loss': 0.7794162631034851,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 848: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=84, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=84, out_features=248, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=248, out_features=478, bias=True)\n",
       "      (5): ReLU()\n",
       "      (6): Linear(in_features=478, out_features=439, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Linear(in_features=439, out_features=440, bias=True)\n",
       "      (9): ReLU()\n",
       "      (10): Linear(in_features=440, out_features=422, bias=True)\n",
       "      (11): ReLU()\n",
       "      (12): Linear(in_features=422, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [84, 248, 478, 439, 440, 422],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0,\n",
       "   'optimizer_type': torch.optim.adam.Adam,\n",
       "   'learning_rate': 0.0040482121622539315,\n",
       "   'batch_size': 1024,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.7032309174537659,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.6261586546897888,\n",
       "  'val_acc': 0.6770833333333334},\n",
       " 849: {'model': DynamicNN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=315, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=315, out_features=440, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=440, out_features=217, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "      (9): Linear(in_features=217, out_features=66, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=66, out_features=261, bias=True)\n",
       "      (13): ReLU()\n",
       "      (14): Dropout(p=0.1, inplace=False)\n",
       "      (15): Linear(in_features=261, out_features=252, bias=True)\n",
       "      (16): ReLU()\n",
       "      (17): Dropout(p=0.1, inplace=False)\n",
       "      (18): Linear(in_features=252, out_features=281, bias=True)\n",
       "      (19): ReLU()\n",
       "      (20): Dropout(p=0.1, inplace=False)\n",
       "      (21): Linear(in_features=281, out_features=2, bias=True)\n",
       "    )\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  ),\n",
       "  'architecture': {'hidden_layers': [315, 440, 217, 66, 261, 252, 281],\n",
       "   'activation_fn': torch.nn.modules.activation.ReLU,\n",
       "   'dropout_rate': 0.1,\n",
       "   'optimizer_type': torch.optim.sgd.SGD,\n",
       "   'learning_rate': 0.00565145902588476,\n",
       "   'batch_size': 512,\n",
       "   'random_seed': 2024},\n",
       "  'train_loss': 0.6969068646430969,\n",
       "  'train_acc': 0.3411458333333333,\n",
       "  'val_loss': 0.6973598599433899,\n",
       "  'val_acc': 0.3229166666666667}}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_gen.generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_INDIVIDUALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-Epoch: 0\n",
      "Mean val_loss: 0.6871410835490507\n",
      "Mean val_acc: 0.5811642156862712\n",
      "Survivor models: 850\n",
      "\n",
      "-Epoch: 1\n",
      "Mean val_loss: 0.6645169093236224\n",
      "Mean val_acc: 0.6160817196864874\n",
      "Survivor models: 723\n",
      "\n",
      "-Epoch: 2\n",
      "Mean val_loss: 0.6535471536279693\n",
      "Mean val_acc: 0.6709857723577191\n",
      "Survivor models: 615\n",
      "\n",
      "-Epoch: 3\n",
      "Mean val_loss: 0.6444827232716416\n",
      "Mean val_acc: 0.6745737731038856\n",
      "Survivor models: 523\n",
      "\n",
      "-Epoch: 4\n",
      "Mean val_loss: 0.6328411146496119\n",
      "Mean val_acc: 0.6757958801498131\n",
      "Survivor models: 445\n",
      "\n",
      "-Epoch: 5\n",
      "Mean val_loss: 0.61924133687661\n",
      "Mean val_acc: 0.6763962181178576\n",
      "Survivor models: 379\n",
      "\n",
      "-Epoch: 6\n",
      "Mean val_loss: 0.6054052180919116\n",
      "Mean val_acc: 0.6767930856553174\n",
      "Survivor models: 323\n",
      "\n",
      "-Epoch: 7\n",
      "Mean val_loss: 0.5886136971820485\n",
      "Mean val_acc: 0.6789015151515164\n",
      "Survivor models: 275\n",
      "\n",
      "-Epoch: 8\n",
      "Mean val_loss: 0.5695161913704668\n",
      "Mean val_acc: 0.6822916666666666\n",
      "Survivor models: 234\n",
      "\n",
      "-Epoch: 9\n",
      "Mean val_loss: 0.5435263008328538\n",
      "Mean val_acc: 0.6876570351758787\n",
      "Survivor models: 199\n",
      "\n",
      "-Epoch: 10\n",
      "Mean val_loss: 0.5143055382896872\n",
      "Mean val_acc: 0.697058823529411\n",
      "Survivor models: 170\n",
      "\n",
      "-Epoch: 11\n",
      "Mean val_loss: 0.4919617928307632\n",
      "Mean val_acc: 0.7134339080459763\n",
      "Survivor models: 145\n",
      "\n",
      "-Epoch: 12\n",
      "Mean val_loss: 0.47073260742810463\n",
      "Mean val_acc: 0.7265624999999998\n",
      "Survivor models: 124\n",
      "\n",
      "-Epoch: 13\n",
      "Mean val_loss: 0.44946118626954423\n",
      "Mean val_acc: 0.7433176100628929\n",
      "Survivor models: 106\n",
      "\n",
      "-Epoch: 14\n",
      "Mean val_loss: 0.43375952787451694\n",
      "Mean val_acc: 0.7627060439560439\n",
      "Survivor models: 91\n",
      "\n",
      "-Epoch: 15\n",
      "Mean val_loss: 0.4281730735913301\n",
      "Mean val_acc: 0.7721688034188037\n",
      "Survivor models: 78\n",
      "\n",
      "-Epoch: 16\n",
      "Mean val_loss: 0.4161374297604632\n",
      "Mean val_acc: 0.7921330845771144\n",
      "Survivor models: 67\n",
      "\n",
      "-Epoch: 17\n",
      "Mean val_loss: 0.40786842086858915\n",
      "Mean val_acc: 0.8022660818713452\n",
      "Survivor models: 57\n",
      "\n",
      "-Epoch: 18\n",
      "Mean val_loss: 0.40285362941878183\n",
      "Mean val_acc: 0.8101615646258503\n",
      "Survivor models: 49\n",
      "\n",
      "-Epoch: 19\n",
      "Mean val_loss: 0.39791486305849894\n",
      "Mean val_acc: 0.8157242063492063\n",
      "Survivor models: 42\n",
      "\n",
      "-Epoch: 20\n",
      "Mean val_loss: 0.39302313493357766\n",
      "Mean val_acc: 0.8177083333333333\n",
      "Survivor models: 36\n"
     ]
    }
   ],
   "source": [
    "number_of_epochs = 20\n",
    "# create a new gen\n",
    "generation = Generation(search_space, N_INDIVIDUALS)\n",
    "for n_epoch in range(number_of_epochs + 1):\n",
    "    print('\\n-Epoch:', n_epoch)\n",
    "    final_gen = run_generation(generation, train_loader, val_loader)\n",
    "    # Extract val_loss values\n",
    "    val_losses = [final_gen.generation[gen]['val_loss'] for gen in final_gen.generation]\n",
    "\n",
    "    # Calculate the mean val_loss\n",
    "    mean_val_loss = sum(val_losses) / len(val_losses)\n",
    "    # Print the mean val_loss\n",
    "    print(\"Mean val_loss:\", mean_val_loss)\n",
    "\n",
    "    # Extract val_Accuracy values\n",
    "    val_accuracies = [final_gen.generation[gen]['val_acc'] for gen in final_gen.generation]\n",
    "\n",
    "    # Calculate the mean val_loss\n",
    "    mean_val_acc = sum(val_accuracies) / len(val_accuracies)\n",
    "    # Print the mean val_loss\n",
    "    print(\"Mean val_acc:\", mean_val_acc)\n",
    "    \n",
    "    print('Survivor models:', len(final_gen.generation))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare versus other models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression, Ridge\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.metrics import accuracy_score, r2_score\n",
    "from sklearn.utils.multiclass import type_of_target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class column is not numeric. Applying LabelEncoder.\n",
      "Data loaded successfully! as <class 'numpy.ndarray'>\n",
      "Training data shape: (384, 6)\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Model",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Accuracy",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "e2855a16-6650-4747-8a04-d2d5641a840d",
       "rows": [
        [
         "0",
         "Random Forest",
         "0.9375"
        ],
        [
         "1",
         "KNN",
         "0.8333333333333334"
        ],
        [
         "2",
         "MY Neural Network",
         "0.8177083333333333"
        ],
        [
         "3",
         "SVM",
         "0.71875"
        ],
        [
         "4",
         "Logistic Regression",
         "0.6354166666666666"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.937500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MY Neural Network</td>\n",
       "      <td>0.817708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.718750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.635417</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Accuracy\n",
       "0        Random Forest  0.937500\n",
       "1                  KNN  0.833333\n",
       "2    MY Neural Network  0.817708\n",
       "3                  SVM  0.718750\n",
       "4  Logistic Regression  0.635417"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load data\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = load_data.load_openml_dataset(\n",
    "    dataset_id=334, scaling=True, random_seed=None, return_as='array'\n",
    ")\n",
    "\n",
    "# Determine if it's a classification or regression problem\n",
    "target_type = type_of_target(y_train)\n",
    "\n",
    "if target_type in ['binary', 'multiclass']:\n",
    "    models = {\n",
    "        \"Logistic Regression\": LogisticRegression(max_iter=500),\n",
    "        \"Random Forest\": RandomForestClassifier(n_estimators=100),\n",
    "        \"SVM\": SVC(),\n",
    "        \"KNN\": KNeighborsClassifier(n_neighbors=5)\n",
    "    }\n",
    "    metric = accuracy_score\n",
    "    metric_name = \"Accuracy\"\n",
    "else:\n",
    "    models = {\n",
    "        \"Ridge Regression\": Ridge(),\n",
    "        \"Random Forest\": RandomForestRegressor(n_estimators=100),\n",
    "        \"SVM\": SVR(),\n",
    "        \"KNN\": KNeighborsRegressor(n_neighbors=5)\n",
    "    }\n",
    "    metric = r2_score\n",
    "    metric_name = \"R² Score\"\n",
    "\n",
    "# Train and evaluate models\n",
    "results = []\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_val)\n",
    "    score = metric(y_val, y_pred)\n",
    "    results.append((name, score))\n",
    "\n",
    "# Sort results\n",
    "results.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Display results\n",
    "results_df = pd.DataFrame(results, columns=[\"Model\", metric_name])\n",
    "# add the neural network\n",
    "results_df.loc[len(results_df)] = ['MY Neural Network', mean_val_acc]\n",
    "results_df = results_df.sort_values('Accuracy', ascending=False).reset_index(drop=True)\n",
    "\n",
    "display(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Model",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Accuracy",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "c333a9a8-9e2b-4727-abf3-576c788820e5",
       "rows": [
        [
         "0",
         "Random Forest",
         "0.9375"
        ],
        [
         "1",
         "KNN",
         "0.8333333333333334"
        ],
        [
         "2",
         "MY Neural Network",
         "0.8177083333333333"
        ],
        [
         "3",
         "SVM",
         "0.71875"
        ],
        [
         "4",
         "Logistic Regression",
         "0.6354166666666666"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.937500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MY Neural Network</td>\n",
       "      <td>0.817708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.718750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.635417</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Accuracy\n",
       "0        Random Forest  0.937500\n",
       "1                  KNN  0.833333\n",
       "2    MY Neural Network  0.817708\n",
       "3                  SVM  0.718750\n",
       "4  Logistic Regression  0.635417"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN Final Accuracy 0.8177083333333333\n"
     ]
    }
   ],
   "source": [
    "print('NN Final Accuracy', mean_val_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AutoML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
